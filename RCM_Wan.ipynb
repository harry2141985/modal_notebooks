{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Clone**"
      ],
      "metadata": {
        "id": "00r2QawKdWf9"
      },
      "id": "00r2QawKdWf9"
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /root\n",
        "!git clone https://huggingface.co/spaces/yujiwang0606/rCM-Wan-720p\n",
        "%cd rCM-Wan-720p"
      ],
      "metadata": {
        "id": "KEwiI_-BdduM"
      },
      "id": "KEwiI_-BdduM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirements**"
      ],
      "metadata": {
        "id": "7PwZlIZldj_N"
      },
      "id": "7PwZlIZldj_N"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Smart Dependency Installer for Modal ===\n",
        "import sys, subprocess\n",
        "\n",
        "# Check Python and Torch versions\n",
        "python_ver = f\"cp{sys.version_info.major}{sys.version_info.minor}\"\n",
        "!pip install torch==2.8.0 torchvision>=0.19.0 --quiet\n",
        "\n",
        "import torch\n",
        "cuda_ver = torch.version.cuda.replace(\".\", \"\")[:3]  # e.g., 121 or 122\n",
        "\n",
        "# Install core dependencies\n",
        "!pip install einops==0.8.1 \\\n",
        "  opencv-python>=4.9.0.80 \\\n",
        "  diffusers>=0.31.0 \\\n",
        "  transformers>=4.49.0 \\\n",
        "  tokenizers>=0.20.3 \\\n",
        "  accelerate>=1.1.1 \\\n",
        "  tqdm \\\n",
        "  imageio \\\n",
        "  easydict \\\n",
        "  ftfy \\\n",
        "  dashscope \\\n",
        "  imageio-ffmpeg \\\n",
        "  \"numpy>=1.23.5,<2\" \\\n",
        "  gradio \\\n",
        "  loguru \\\n",
        "  omegaconf \\\n",
        "  fvcore \\\n",
        "  pynvml \\\n",
        "  spaces -q\n",
        "\n",
        "# Pick FlashAttention wheel based on environment\n",
        "base_url = \"https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.3\"\n",
        "wheel = f\"flash_attn-2.8.3+cu{cuda_ver}torch2.8cxx11abiFALSE-{python_ver}-{python_ver}-linux_x86_64.whl\"\n",
        "\n",
        "print(f\"ðŸ” Installing FlashAttention wheel for CUDA {cuda_ver} and {python_ver}...\")\n",
        "try:\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", f\"{base_url}/{wheel}\"])\n",
        "except subprocess.CalledProcessError:\n",
        "    print(\"âŒ Wheel not found or incompatible. Installing via source instead...\")\n",
        "    !pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "nL4MTUpHd33E"
      },
      "id": "nL4MTUpHd33E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Requirements #2**"
      ],
      "metadata": {
        "id": "FJFG3trQd6i0"
      },
      "id": "FJFG3trQd6i0"
    },
    {
      "cell_type": "code",
      "source": [
        "# === Clean FlashAttention + Modal Environment ===\n",
        "!pip install torch==2.8.0 torchvision>=0.19.0 --quiet\n",
        "!pip install einops==0.8.1 opencv-python>=4.9.0.80 diffusers>=0.31.0 transformers>=4.49.0 tokenizers>=0.20.3 accelerate>=1.1.1 tqdm imageio easydict ftfy dashscope imageio-ffmpeg \"numpy>=1.23.5,<2\" gradio loguru omegaconf fvcore pynvml spaces -q\n",
        "\n",
        "# Install flash-attn from source (auto-compiles for current CUDA/Python)\n",
        "!pip install ninja packaging wheel\n",
        "!pip install flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "pcmbWGWpd_EE"
      },
      "id": "pcmbWGWpd_EE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FFMPEG**"
      ],
      "metadata": {
        "id": "V0TA5t7QeAJM"
      },
      "id": "V0TA5t7QeAJM"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y update\n",
        "!apt-get install -y libglib2.0-0 libgl1\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "eiTq762_eH7U"
      },
      "id": "eiTq762_eH7U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Code**"
      ],
      "metadata": {
        "id": "JuSD3pFYeKaM"
      },
      "id": "JuSD3pFYeKaM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "id": "NMxx74YYeN0E"
      },
      "id": "NMxx74YYeN0E"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}