{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Welcome to Modal notebooks!\n",
        "\n",
        "Write Python code and collaborate in real time. Your code runs in Modal's\n",
        "**serverless cloud**, and anyone in the same workspace can join.\n",
        "\n",
        "This notebook comes with some common Python libraries installed. Run\n",
        "cells with `Shift+Enter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "%cd /root\n",
        "!git clone https://github.com/colinurbs/FramePack-Studio.git\n",
        "%cd FramePack-Studio\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "Cloning into 'FramePack-Studio'...\r\n",
            "remote: Enumerating objects: 3102, done.\u001b[K\r\n",
            "remote: Counting objects:   0% (1/843)\u001b[K\rremote: Counting objects:   1% (9/843)\u001b[K\rremote: Counting objects:   2% (17/843)\u001b[K\rremote: Counting objects:   3% (26/843)\u001b[K\rremote: Counting objects:   4% (34/843)\u001b[K\rremote: Counting objects:   5% (43/843)\u001b[K\rremote: Counting objects:   6% (51/843)\u001b[K\rremote: Counting objects:   7% (60/843)\u001b[K\rremote: Counting objects:   8% (68/843)\u001b[K\rremote: Counting objects:   9% (76/843)\u001b[K\rremote: Counting objects:  10% (85/843)\u001b[K\rremote: Counting objects:  11% (93/843)\u001b[K\rremote: Counting objects:  12% (102/843)\u001b[K\rremote: Counting objects:  13% (110/843)\u001b[K\rremote: Counting objects:  14% (119/843)\u001b[K\rremote: Counting objects:  15% (127/843)\u001b[K\rremote: Counting objects:  16% (135/843)\u001b[K\rremote: Counting objects:  17% (144/843)\u001b[K\rremote: Counting objects:  18% (152/843)\u001b[K\rremote: Counting objects:  19% (161/843)\u001b[K\rremote: Counting objects:  20% (169/843)\u001b[K\rremote: Counting objects:  21% (178/843)\u001b[K\rremote: Counting objects:  22% (186/843)\u001b[K\rremote: Counting objects:  23% (194/843)\u001b[K\rremote: Counting objects:  24% (203/843)\u001b[K\rremote: Counting objects:  25% (211/843)\u001b[K\rremote: Counting objects:  26% (220/843)\u001b[K\rremote: Counting objects:  27% (228/843)\u001b[K\rremote: Counting objects:  28% (237/843)\u001b[K\rremote: Counting objects:  29% (245/843)\u001b[K\rremote: Counting objects:  30% (253/843)\u001b[K\rremote: Counting objects:  31% (262/843)\u001b[K\rremote: Counting objects:  32% (270/843)\u001b[K\rremote: Counting objects:  33% (279/843)\u001b[K\rremote: Counting objects:  34% (287/843)\u001b[K\rremote: Counting objects:  35% (296/843)\u001b[K\rremote: Counting objects:  36% (304/843)\u001b[K\rremote: Counting objects:  37% (312/843)\u001b[K\rremote: Counting objects:  38% (321/843)\u001b[K\rremote: Counting objects:  39% (329/843)\u001b[K\rremote: Counting objects:  40% (338/843)\u001b[K\rremote: Counting objects:  41% (346/843)\u001b[K\rremote: Counting objects:  42% (355/843)\u001b[K\rremote: Counting objects:  43% (363/843)\u001b[K\rremote: Counting objects:  44% (371/843)\u001b[K\rremote: Counting objects:  45% (380/843)\u001b[K\rremote: Counting objects:  46% (388/843)\u001b[K\rremote: Counting objects:  47% (397/843)\u001b[K\rremote: Counting objects:  48% (405/843)\u001b[K\rremote: Counting objects:  49% (414/843)\u001b[K\rremote: Counting objects:  50% (422/843)\u001b[K\rremote: Counting objects:  51% (430/843)\u001b[K\rremote: Counting objects:  52% (439/843)\u001b[K\rremote: Counting objects:  53% (447/843)\u001b[K\rremote: Counting objects:  54% (456/843)\u001b[K\rremote: Counting objects:  55% (464/843)\u001b[K\rremote: Counting objects:  56% (473/843)\u001b[K\rremote: Counting objects:  57% (481/843)\u001b[K\rremote: Counting objects:  58% (489/843)\u001b[K\rremote: Counting objects:  59% (498/843)\u001b[K\rremote: Counting objects:  60% (506/843)\u001b[K\rremote: Counting objects:  61% (515/843)\u001b[K\rremote: Counting objects:  62% (523/843)\u001b[K\rremote: Counting objects:  63% (532/843)\u001b[K\rremote: Counting objects:  64% (540/843)\u001b[K\rremote: Counting objects:  65% (548/843)\u001b[K\rremote: Counting objects:  66% (557/843)\u001b[K\rremote: Counting objects:  67% (565/843)\u001b[K\rremote: Counting objects:  68% (574/843)\u001b[K\rremote: Counting objects:  69% (582/843)\u001b[K\rremote: Counting objects:  70% (591/843)\u001b[K\rremote: Counting objects:  71% (599/843)\u001b[K\rremote: Counting objects:  72% (607/843)\u001b[K\rremote: Counting objects:  73% (616/843)\u001b[K\rremote: Counting objects:  74% (624/843)\u001b[K\rremote: Counting objects:  75% (633/843)\u001b[K\rremote: Counting objects:  76% (641/843)\u001b[K\rremote: Counting objects:  77% (650/843)\u001b[K\rremote: Counting objects:  78% (658/843)\u001b[K\rremote: Counting objects:  79% (666/843)\u001b[K\rremote: Counting objects:  80% (675/843)\u001b[K\rremote: Counting objects:  81% (683/843)\u001b[K\rremote: Counting objects:  82% (692/843)\u001b[K\rremote: Counting objects:  83% (700/843)\u001b[K\rremote: Counting objects:  84% (709/843)\u001b[K\rremote: Counting objects:  85% (717/843)\u001b[K\rremote: Counting objects:  86% (725/843)\u001b[K\rremote: Counting objects:  87% (734/843)\u001b[K\rremote: Counting objects:  88% (742/843)\u001b[K\rremote: Counting objects:  89% (751/843)\u001b[K\rremote: Counting objects:  90% (759/843)\u001b[K\rremote: Counting objects:  91% (768/843)\u001b[K\rremote: Counting objects:  92% (776/843)\u001b[K\rremote: Counting objects:  93% (784/843)\u001b[K\rremote: Counting objects:  94% (793/843)\u001b[K\rremote: Counting objects:  95% (801/843)\u001b[K\rremote: Counting objects:  96% (810/843)\u001b[K\rremote: Counting objects:  97% (818/843)\u001b[K\rremote: Counting objects:  98% (827/843)\u001b[K\rremote: Counting objects:  99% (835/843)\u001b[K\rremote: Counting objects: 100% (843/843)\u001b[K\rremote: Counting objects: 100% (843/843), done.\u001b[K\r\n",
            "remote: Compressing objects:   0% (1/248)\u001b[K\rremote: Compressing objects:   1% (3/248)\u001b[K\rremote: Compressing objects:   2% (5/248)\u001b[K\rremote: Compressing objects:   3% (8/248)\u001b[K\rremote: Compressing objects:   4% (10/248)\u001b[K\rremote: Compressing objects:   5% (13/248)\u001b[K\rremote: Compressing objects:   6% (15/248)\u001b[K\rremote: Compressing objects:   7% (18/248)\u001b[K\rremote: Compressing objects:   8% (20/248)\u001b[K\rremote: Compressing objects:   9% (23/248)\u001b[K\rremote: Compressing objects:  10% (25/248)\u001b[K\rremote: Compressing objects:  11% (28/248)\u001b[K\rremote: Compressing objects:  12% (30/248)\u001b[K\rremote: Compressing objects:  13% (33/248)\u001b[K\rremote: Compressing objects:  14% (35/248)\u001b[K\rremote: Compressing objects:  15% (38/248)\u001b[K\rremote: Compressing objects:  16% (40/248)\u001b[K\rremote: Compressing objects:  17% (43/248)\u001b[K\rremote: Compressing objects:  18% (45/248)\u001b[K\rremote: Compressing objects:  19% (48/248)\u001b[K\rremote: Compressing objects:  20% (50/248)\u001b[K\rremote: Compressing objects:  21% (53/248)\u001b[K\rremote: Compressing objects:  22% (55/248)\u001b[K\rremote: Compressing objects:  23% (58/248)\u001b[K\rremote: Compressing objects:  24% (60/248)\u001b[K\rremote: Compressing objects:  25% (62/248)\u001b[K\rremote: Compressing objects:  26% (65/248)\u001b[K\rremote: Compressing objects:  27% (67/248)\u001b[K\rremote: Compressing objects:  28% (70/248)\u001b[K\rremote: Compressing objects:  29% (72/248)\u001b[K\rremote: Compressing objects:  30% (75/248)\u001b[K\rremote: Compressing objects:  31% (77/248)\u001b[K\rremote: Compressing objects:  32% (80/248)\u001b[K\rremote: Compressing objects:  33% (82/248)\u001b[K\rremote: Compressing objects:  34% (85/248)\u001b[K\rremote: Compressing objects:  35% (87/248)\u001b[K\rremote: Compressing objects:  36% (90/248)\u001b[K\rremote: Compressing objects:  37% (92/248)\u001b[K\rremote: Compressing objects:  38% (95/248)\u001b[K\rremote: Compressing objects:  39% (97/248)\u001b[K\rremote: Compressing objects:  40% (100/248)\u001b[K\rremote: Compressing objects:  41% (102/248)\u001b[K\rremote: Compressing objects:  42% (105/248)\u001b[K\rremote: Compressing objects:  43% (107/248)\u001b[K\rremote: Compressing objects:  44% (110/248)\u001b[K\rremote: Compressing objects:  45% (112/248)\u001b[K\rremote: Compressing objects:  46% (115/248)\u001b[K\rremote: Compressing objects:  47% (117/248)\u001b[K\rremote: Compressing objects:  48% (120/248)\u001b[K\rremote: Compressing objects:  49% (122/248)\u001b[K\rremote: Compressing objects:  50% (124/248)\u001b[K\rremote: Compressing objects:  51% (127/248)\u001b[K\rremote: Compressing objects:  52% (129/248)\u001b[K\rremote: Compressing objects:  53% (132/248)\u001b[K\rremote: Compressing objects:  54% (134/248)\u001b[K\rremote: Compressing objects:  55% (137/248)\u001b[K\rremote: Compressing objects:  56% (139/248)\u001b[K\rremote: Compressing objects:  57% (142/248)\u001b[K\rremote: Compressing objects:  58% (144/248)\u001b[K\rremote: Compressing objects:  59% (147/248)\u001b[K\rremote: Compressing objects:  60% (149/248)\u001b[K\rremote: Compressing objects:  61% (152/248)\u001b[K\rremote: Compressing objects:  62% (154/248)\u001b[K\rremote: Compressing objects:  63% (157/248)\u001b[K\rremote: Compressing objects:  64% (159/248)\u001b[K\rremote: Compressing objects:  65% (162/248)\u001b[K\rremote: Compressing objects:  66% (164/248)\u001b[K\rremote: Compressing objects:  67% (167/248)\u001b[K\rremote: Compressing objects:  68% (169/248)\u001b[K\rremote: Compressing objects:  69% (172/248)\u001b[K\rremote: Compressing objects:  70% (174/248)\u001b[K\rremote: Compressing objects:  71% (177/248)\u001b[K\rremote: Compressing objects:  72% (179/248)\u001b[K\rremote: Compressing objects:  73% (182/248)\u001b[K\rremote: Compressing objects:  74% (184/248)\u001b[K\rremote: Compressing objects:  75% (186/248)\u001b[K\rremote: Compressing objects:  76% (189/248)\u001b[K\rremote: Compressing objects:  77% (191/248)\u001b[K\rremote: Compressing objects:  78% (194/248)\u001b[K\rremote: Compressing objects:  79% (196/248)\u001b[K\rremote: Compressing objects:  80% (199/248)\u001b[K\rremote: Compressing objects:  81% (201/248)\u001b[K\rremote: Compressing objects:  82% (204/248)\u001b[K\rremote: Compressing objects:  83% (206/248)\u001b[K\rremote: Compressing objects:  84% (209/248)\u001b[K\rremote: Compressing objects:  85% (211/248)\u001b[K\rremote: Compressing objects:  86% (214/248)\u001b[K\rremote: Compressing objects:  87% (216/248)\u001b[K\rremote: Compressing objects:  88% (219/248)\u001b[K\rremote: Compressing objects:  89% (221/248)\u001b[K\rremote: Compressing objects:  90% (224/248)\u001b[K\rremote: Compressing objects:  91% (226/248)\u001b[K\rremote: Compressing objects:  92% (229/248)\u001b[K\rremote: Compressing objects:  93% (231/248)\u001b[K\rremote: Compressing objects:  94% (234/248)\u001b[K\rremote: Compressing objects:  95% (236/248)\u001b[K\rremote: Compressing objects:  96% (239/248)\u001b[K\rremote: Compressing objects:  97% (241/248)\u001b[K\rremote: Compressing objects:  98% (244/248)\u001b[K\rremote: Compressing objects:  99% (246/248)\u001b[K\rremote: Compressing objects: 100% (248/248)\u001b[K\rremote: Compressing objects: 100% (248/248), done.\u001b[K\r\n",
            "Receiving objects:   0% (1/3102)\rReceiving objects:   1% (32/3102)\rReceiving objects:   2% (63/3102)\rReceiving objects:   3% (94/3102)\rReceiving objects:   4% (125/3102)\rReceiving objects:   5% (156/3102)\rReceiving objects:   6% (187/3102)\rReceiving objects:   7% (218/3102)\rReceiving objects:   8% (249/3102)\rReceiving objects:   9% (280/3102)\rReceiving objects:  10% (311/3102)\rReceiving objects:  11% (342/3102)\rReceiving objects:  12% (373/3102)\rReceiving objects:  13% (404/3102)\rReceiving objects:  14% (435/3102)\rReceiving objects:  15% (466/3102)\rReceiving objects:  16% (497/3102)\rReceiving objects:  17% (528/3102)\rReceiving objects:  18% (559/3102)\rReceiving objects:  19% (590/3102)\rReceiving objects:  20% (621/3102)\rReceiving objects:  21% (652/3102)\rReceiving objects:  22% (683/3102)\rReceiving objects:  23% (714/3102)\rReceiving objects:  24% (745/3102)\rReceiving objects:  25% (776/3102)\rReceiving objects:  26% (807/3102)\rReceiving objects:  27% (838/3102)\rReceiving objects:  28% (869/3102)\rReceiving objects:  29% (900/3102)\rReceiving objects:  30% (931/3102)\rReceiving objects:  31% (962/3102)\rReceiving objects:  32% (993/3102)\rReceiving objects:  33% (1024/3102)\rReceiving objects:  34% (1055/3102)\rReceiving objects:  35% (1086/3102)\rReceiving objects:  36% (1117/3102)\rReceiving objects:  37% (1148/3102)\rReceiving objects:  38% (1179/3102)\rReceiving objects:  39% (1210/3102)\rReceiving objects:  40% (1241/3102)\rReceiving objects:  41% (1272/3102)\rReceiving objects:  42% (1303/3102)\rReceiving objects:  43% (1334/3102)\rReceiving objects:  44% (1365/3102)\rReceiving objects:  45% (1396/3102)\rReceiving objects:  46% (1427/3102)\rReceiving objects:  47% (1458/3102)\rReceiving objects:  48% (1489/3102)\rReceiving objects:  49% (1520/3102)\rReceiving objects:  50% (1551/3102)\rReceiving objects:  51% (1583/3102)\rReceiving objects:  52% (1614/3102)\rReceiving objects:  53% (1645/3102)\rReceiving objects:  54% (1676/3102)\rReceiving objects:  55% (1707/3102)\rReceiving objects:  56% (1738/3102)\rReceiving objects:  57% (1769/3102)\rReceiving objects:  58% (1800/3102)\rReceiving objects:  59% (1831/3102)\rReceiving objects:  60% (1862/3102)\rReceiving objects:  61% (1893/3102)\rReceiving objects:  62% (1924/3102)\rReceiving objects:  63% (1955/3102)\rReceiving objects:  64% (1986/3102)\rReceiving objects:  65% (2017/3102)\rReceiving objects:  66% (2048/3102)\rReceiving objects:  67% (2079/3102)\rReceiving objects:  68% (2110/3102)\rReceiving objects:  69% (2141/3102)\rReceiving objects:  70% (2172/3102)\rReceiving objects:  71% (2203/3102)\rReceiving objects:  72% (2234/3102)\rReceiving objects:  73% (2265/3102)\rReceiving objects:  74% (2296/3102)\rReceiving objects:  75% (2327/3102)\rReceiving objects:  76% (2358/3102)\rReceiving objects:  77% (2389/3102)\rReceiving objects:  78% (2420/3102)\rReceiving objects:  79% (2451/3102)\rReceiving objects:  80% (2482/3102)\rReceiving objects:  81% (2513/3102)\rReceiving objects:  82% (2544/3102)\rReceiving objects:  83% (2575/3102)\rReceiving objects:  84% (2606/3102)\rReceiving objects:  85% (2637/3102)\rReceiving objects:  86% (2668/3102)\rReceiving objects:  87% (2699/3102)\rReceiving objects:  88% (2730/3102)\rReceiving objects:  89% (2761/3102)\rReceiving objects:  90% (2792/3102)\rReceiving objects:  91% (2823/3102)\rReceiving objects:  92% (2854/3102)\rReceiving objects:  93% (2885/3102)\rReceiving objects:  94% (2916/3102)\rReceiving objects:  95% (2947/3102)\rReceiving objects:  96% (2978/3102)\rReceiving objects:  97% (3009/3102)\rremote: Total 3102 (delta 661), reused 595 (delta 595), pack-reused 2259 (from 2)\u001b[K\r\n",
            "Receiving objects:  98% (3040/3102)\rReceiving objects:  99% (3071/3102)\rReceiving objects: 100% (3102/3102)\rReceiving objects: 100% (3102/3102), 1.49 MiB | 30.52 MiB/s, done.\r\n",
            "Resolving deltas:   0% (0/2074)\rResolving deltas:   1% (22/2074)\rResolving deltas:   2% (42/2074)\rResolving deltas:   3% (63/2074)\rResolving deltas:   4% (83/2074)\rResolving deltas:   5% (104/2074)\rResolving deltas:   6% (125/2074)\rResolving deltas:   7% (146/2074)\rResolving deltas:   8% (166/2074)\rResolving deltas:   9% (187/2074)\rResolving deltas:  10% (208/2074)\rResolving deltas:  11% (229/2074)\rResolving deltas:  12% (250/2074)\rResolving deltas:  13% (270/2074)\rResolving deltas:  14% (291/2074)\rResolving deltas:  15% (312/2074)\rResolving deltas:  16% (332/2074)\rResolving deltas:  17% (354/2074)\rResolving deltas:  18% (374/2074)\rResolving deltas:  19% (395/2074)\rResolving deltas:  20% (415/2074)\rResolving deltas:  21% (438/2074)\rResolving deltas:  22% (457/2074)\rResolving deltas:  23% (478/2074)\rResolving deltas:  24% (498/2074)\rResolving deltas:  25% (519/2074)\rResolving deltas:  26% (542/2074)\rResolving deltas:  27% (560/2074)\rResolving deltas:  28% (582/2074)\rResolving deltas:  29% (602/2074)\rResolving deltas:  30% (623/2074)\rResolving deltas:  31% (643/2074)\rResolving deltas:  32% (664/2074)\rResolving deltas:  33% (689/2074)\rResolving deltas:  34% (706/2074)\rResolving deltas:  35% (726/2074)\rResolving deltas:  36% (747/2074)\rResolving deltas:  37% (768/2074)\rResolving deltas:  38% (790/2074)\rResolving deltas:  39% (809/2074)\rResolving deltas:  40% (830/2074)\rResolving deltas:  41% (851/2074)\rResolving deltas:  42% (873/2074)\rResolving deltas:  43% (892/2074)\rResolving deltas:  44% (913/2074)\rResolving deltas:  45% (934/2074)\rResolving deltas:  46% (955/2074)\rResolving deltas:  47% (975/2074)\rResolving deltas:  48% (996/2074)\rResolving deltas:  49% (1017/2074)\rResolving deltas:  50% (1037/2074)\rResolving deltas:  51% (1058/2074)\rResolving deltas:  52% (1079/2074)\rResolving deltas:  53% (1100/2074)\rResolving deltas:  54% (1120/2074)\rResolving deltas:  55% (1141/2074)\rResolving deltas:  56% (1163/2074)\rResolving deltas:  57% (1183/2074)\rResolving deltas:  58% (1203/2074)\rResolving deltas:  59% (1225/2074)\rResolving deltas:  60% (1245/2074)\rResolving deltas:  61% (1267/2074)\rResolving deltas:  62% (1286/2074)\rResolving deltas:  63% (1307/2074)\rResolving deltas:  64% (1328/2074)\rResolving deltas:  65% (1351/2074)\rResolving deltas:  66% (1370/2074)\rResolving deltas:  67% (1390/2074)\rResolving deltas:  68% (1411/2074)\rResolving deltas:  69% (1433/2074)\rResolving deltas:  70% (1453/2074)\rResolving deltas:  71% (1473/2074)\rResolving deltas:  72% (1497/2074)\rResolving deltas:  73% (1515/2074)\rResolving deltas:  74% (1535/2074)\rResolving deltas:  75% (1557/2074)\rResolving deltas:  76% (1577/2074)\rResolving deltas:  77% (1597/2074)\rResolving deltas:  78% (1619/2074)\rResolving deltas:  79% (1639/2074)\rResolving deltas:  80% (1661/2074)\rResolving deltas:  81% (1682/2074)\rResolving deltas:  82% (1702/2074)\rResolving deltas:  83% (1723/2074)\rResolving deltas:  84% (1744/2074)\rResolving deltas:  85% (1763/2074)\rResolving deltas:  86% (1784/2074)\rResolving deltas:  87% (1805/2074)\rResolving deltas:  88% (1826/2074)\rResolving deltas:  89% (1847/2074)\rResolving deltas:  90% (1867/2074)\rResolving deltas:  91% (1888/2074)\rResolving deltas:  92% (1911/2074)\rResolving deltas:  93% (1929/2074)\rResolving deltas:  94% (1950/2074)\rResolving deltas:  95% (1971/2074)\rResolving deltas:  96% (1993/2074)\rResolving deltas:  97% (2013/2074)\rResolving deltas:  98% (2033/2074)\rResolving deltas:  99% (2054/2074)\rResolving deltas: 100% (2074/2074)\rResolving deltas: 100% (2074/2074), done.\r\n",
            "/root/FramePack-Studio\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu126\r\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/site-packages (2.8.0+cu126)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/site-packages (0.23.0+cu126)\r\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/site-packages (2.8.0+cu126)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from torch) (3.13.1)\r\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/site-packages (from torch) (4.12.2)\r\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch) (70.2.0)\r\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch) (1.13.3)\r\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch) (3.3)\r\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/site-packages (from torch) (3.1.4)\r\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from torch) (2024.6.1)\r\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.80)\r\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/site-packages (from torch) (9.10.2.21)\r\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.4.1)\r\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/site-packages (from torch) (11.3.0.4)\r\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/site-packages (from torch) (10.3.7.77)\r\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/site-packages (from torch) (11.7.1.2)\r\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/site-packages (from torch) (12.5.4.2)\r\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/site-packages (from torch) (0.7.1)\r\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/site-packages (from torch) (2.27.3)\r\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/site-packages (from torch) (12.6.85)\r\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/site-packages (from torch) (1.11.1.6)\r\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/site-packages (from torch) (3.4.0)\r\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/site-packages (from torchvision) (2.1.2)\r\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/site-packages (from torchvision) (11.0.0)\r\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\r\n",
            "Collecting accelerate==1.6.0 (from -r requirements.txt (line 1))\r\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\r\n",
            "Collecting av==12.1.0 (from -r requirements.txt (line 2))\r\n",
            "  Downloading av-12.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\r\n",
            "Collecting decord (from -r requirements.txt (line 3))\r\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\r\n",
            "Collecting diffusers==0.33.1 (from -r requirements.txt (line 4))\r\n",
            "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\r\n",
            "Collecting einops (from -r requirements.txt (line 5))\r\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\r\n",
            "Collecting ffmpeg-python==0.2.0 (from -r requirements.txt (line 6))\r\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
            "Collecting gradio==5.25.2 (from -r requirements.txt (line 7))\r\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\r\n",
            "Collecting imageio-ffmpeg==0.4.8 (from -r requirements.txt (line 8))\r\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl.metadata (1.6 kB)\r\n",
            "Collecting imageio==2.31.1 (from -r requirements.txt (line 9))\r\n",
            "  Downloading imageio-2.31.1-py3-none-any.whl.metadata (4.7 kB)\r\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (3.1.4)\r\n",
            "Collecting numpy==1.26.2 (from -r requirements.txt (line 11))\r\n",
            "  Downloading numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\r\n",
            "Collecting opencv-contrib-python (from -r requirements.txt (line 12))\r\n",
            "  Downloading opencv_contrib_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\r\n",
            "Collecting peft (from -r requirements.txt (line 13))\r\n",
            "  Downloading peft-0.17.0-py3-none-any.whl.metadata (14 kB)\r\n",
            "Collecting pillow==11.1.0 (from -r requirements.txt (line 14))\r\n",
            "  Downloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\r\n",
            "Collecting requests==2.31.0 (from -r requirements.txt (line 15))\r\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (0.6.1)\r\n",
            "Collecting scipy==1.12.0 (from -r requirements.txt (line 17))\r\n",
            "  Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
            "Requirement already satisfied: sentencepiece==0.2.0 in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.2.0)\r\n",
            "Collecting torchsde==0.2.6 (from -r requirements.txt (line 19))\r\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\r\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (4.67.1)\r\n",
            "Collecting timm (from -r requirements.txt (line 21))\r\n",
            "  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\r\n",
            "Collecting transformers==4.46.2 (from -r requirements.txt (line 22))\r\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\r\n",
            "Collecting basicsr (from -r requirements.txt (line 25))\r\n",
            "  Downloading basicsr-1.4.2.tar.gz (172 kB)\r\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25hCollecting devicetorch (from -r requirements.txt (line 27))\r\n",
            "  Downloading devicetorch-0.1.13-py3-none-any.whl.metadata (57 bytes)\r\n",
            "Collecting facexlib>=0.2.5 (from -r requirements.txt (line 28))\r\n",
            "  Downloading facexlib-0.3.0-py3-none-any.whl.metadata (4.6 kB)\r\n",
            "Collecting gfpgan>=1.3.5 (from -r requirements.txt (line 29))\r\n",
            "  Downloading gfpgan-1.3.8-py3-none-any.whl.metadata (12 kB)\r\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (7.0.0)\r\n",
            "Collecting realesrgan (from -r requirements.txt (line 31))\r\n",
            "  Downloading realesrgan-0.3.0-py3-none-any.whl.metadata (17 kB)\r\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (25.0)\r\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (6.0.2)\r\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (2.8.0+cu126)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.12/site-packages (from accelerate==1.6.0->-r requirements.txt (line 1)) (0.34.3)\r\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.12/site-packages (from diffusers==0.33.1->-r requirements.txt (line 4)) (8.7.0)\r\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from diffusers==0.33.1->-r requirements.txt (line 4)) (3.13.1)\r\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/site-packages (from diffusers==0.33.1->-r requirements.txt (line 4)) (2025.7.34)\r\n",
            "Collecting future (from ffmpeg-python==0.2.0->-r requirements.txt (line 6))\r\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\r\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (24.1.0)\r\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (4.10.0)\r\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.116.1)\r\n",
            "Collecting ffmpy (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
            "Collecting gradio-client==1.8.0 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\r\n",
            "Collecting groovy~=0.1 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\r\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.28.1)\r\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (2.1.5)\r\n",
            "Collecting orjson~=3.0 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading orjson-3.11.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\r\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (2.3.1)\r\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (2.11.7)\r\n",
            "Collecting pydub (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
            "Collecting python-multipart>=0.0.18 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\r\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.12.7)\r\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\r\n",
            "Collecting semantic-version~=2.0 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.47.2)\r\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.25.2->-r requirements.txt (line 7))\r\n",
            "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\r\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.16.0)\r\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (4.12.2)\r\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/site-packages (from gradio==5.25.2->-r requirements.txt (line 7)) (0.35.0)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/site-packages (from requests==2.31.0->-r requirements.txt (line 15)) (3.4.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/site-packages (from requests==2.31.0->-r requirements.txt (line 15)) (3.10)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/site-packages (from requests==2.31.0->-r requirements.txt (line 15)) (2.5.0)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/site-packages (from requests==2.31.0->-r requirements.txt (line 15)) (2024.8.30)\r\n",
            "Collecting trampoline>=0.1.2 (from torchsde==0.2.6->-r requirements.txt (line 19))\r\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\r\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.2->-r requirements.txt (line 22))\r\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/site-packages (from gradio-client==1.8.0->gradio==5.25.2->-r requirements.txt (line 7)) (2024.6.1)\r\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/site-packages (from gradio-client==1.8.0->gradio==5.25.2->-r requirements.txt (line 7)) (15.0.1)\r\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\r\n",
            "Collecting opencv-contrib-python (from -r requirements.txt (line 12))\r\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/site-packages (from timm->-r requirements.txt (line 21)) (0.23.0+cu126)\r\n",
            "Collecting addict (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\r\n",
            "Collecting lmdb (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading lmdb-1.7.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\r\n",
            "Collecting opencv-python (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\r\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/site-packages (from basicsr->-r requirements.txt (line 25)) (0.25.2)\r\n",
            "Collecting tb-nightly (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading tb_nightly-2.21.0a20250814-py3-none-any.whl.metadata (1.9 kB)\r\n",
            "Collecting yapf (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\r\n",
            "Collecting filterpy (from facexlib>=0.2.5->-r requirements.txt (line 28))\r\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\r\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
            "\u001b[?25hRequirement already satisfied: numba in /usr/local/lib/python3.12/site-packages (from facexlib>=0.2.5->-r requirements.txt (line 28)) (0.61.2)\r\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio==5.25.2->-r requirements.txt (line 7)) (1.3.1)\r\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/site-packages (from httpx>=0.24.1->gradio==5.25.2->-r requirements.txt (line 7)) (1.0.9)\r\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.25.2->-r requirements.txt (line 7)) (0.16.0)\r\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.1.7)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio==5.25.2->-r requirements.txt (line 7)) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio==5.25.2->-r requirements.txt (line 7)) (2025.2)\r\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio==5.25.2->-r requirements.txt (line 7)) (2025.2)\r\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio==5.25.2->-r requirements.txt (line 7)) (0.7.0)\r\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio==5.25.2->-r requirements.txt (line 7)) (2.33.2)\r\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio==5.25.2->-r requirements.txt (line 7)) (0.4.1)\r\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (70.2.0)\r\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.13.3)\r\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.3)\r\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.80)\r\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (9.10.2.21)\r\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.4.1)\r\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (11.3.0.4)\r\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (10.3.7.77)\r\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (11.7.1.2)\r\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.5.4.2)\r\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (0.7.1)\r\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (2.27.3)\r\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.77)\r\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (12.6.85)\r\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.11.1.6)\r\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/site-packages (from torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (3.4.0)\r\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (8.2.1)\r\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (1.5.4)\r\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (14.1.0)\r\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/site-packages (from filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (3.10.5)\r\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/site-packages (from importlib-metadata->diffusers==0.33.1->-r requirements.txt (line 4)) (3.23.0)\r\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.12/site-packages (from numba->facexlib>=0.2.5->-r requirements.txt (line 28)) (0.44.0)\r\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\r\n",
            "Collecting opencv-python (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
            "INFO: pip is looking at multiple versions of scikit-image to determine which version is compatible with other requirements. This could take a while.\r\n",
            "Collecting scikit-image (from basicsr->-r requirements.txt (line 25))\r\n",
            "  Downloading scikit_image-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n",
            "  Downloading scikit_image-0.25.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n",
            "  Downloading scikit_image-0.24.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n",
            "  Downloading scikit_image-0.23.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n",
            "  Downloading scikit_image-0.23.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\r\n",
            "  Downloading scikit_image-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\r\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/site-packages (from scikit-image->basicsr->-r requirements.txt (line 25)) (2025.6.11)\r\n",
            "Requirement already satisfied: lazy_loader>=0.3 in /usr/local/lib/python3.12/site-packages (from scikit-image->basicsr->-r requirements.txt (line 25)) (0.4)\r\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (2.3.1)\r\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (1.74.0)\r\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (3.8.2)\r\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (5.29.2)\r\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (0.7.2)\r\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/site-packages (from tb-nightly->basicsr->-r requirements.txt (line 25)) (3.1.3)\r\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/site-packages (from yapf->basicsr->-r requirements.txt (line 25)) (4.3.8)\r\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.25.2->-r requirements.txt (line 7)) (1.17.0)\r\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (3.0.0)\r\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (2.19.2)\r\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.6.0->-r requirements.txt (line 1)) (1.3.0)\r\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (1.3.3)\r\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (0.12.1)\r\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (4.59.0)\r\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (1.4.8)\r\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/site-packages (from matplotlib->filterpy->facexlib>=0.2.5->-r requirements.txt (line 28)) (3.2.3)\r\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.25.2->-r requirements.txt (line 7)) (0.1.2)\r\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\r\n",
            "Downloading av-12.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.5 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/35.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m26.7/35.5 MB\u001b[0m \u001b[31m134.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/3.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m189.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\r\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/46.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.3/46.9 MB\u001b[0m \u001b[31m137.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m20.7/46.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/26.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading imageio-2.31.1-py3-none-any.whl (313 kB)\r\n",
            "Downloading numpy-1.26.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.9 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/17.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m137.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\r\n",
            "Downloading scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.8 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/37.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[91m\u2578\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m29.1/37.8 MB\u001b[0m \u001b[31m145.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m37.8/37.8 MB\u001b[0m \u001b[31m146.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\r\n",
            "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/10.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m137.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\r\n",
            "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/13.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\r\n",
            "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/69.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m9.4/69.1 MB\u001b[0m \u001b[31m131.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m14.2/69.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.9/69.1 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m \u001b[32m67.4/69.1 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading peft-0.17.0-py3-none-any.whl (503 kB)\r\n",
            "Downloading timm-1.0.19-py3-none-any.whl (2.5 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m138.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading devicetorch-0.1.13-py3-none-any.whl (1.9 kB)\r\n",
            "Downloading facexlib-0.3.0-py3-none-any.whl (59 kB)\r\n",
            "Downloading gfpgan-1.3.8-py3-none-any.whl (52 kB)\r\n",
            "Downloading realesrgan-0.3.0-py3-none-any.whl (26 kB)\r\n",
            "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\r\n",
            "Downloading orjson-3.11.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\r\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\r\n",
            "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\r\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
            "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\r\n",
            "Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\r\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\r\n",
            "Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\r\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\r\n",
            "Downloading lmdb-1.7.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (302 kB)\r\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/63.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m27.5/63.0 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\u001b[90m\u257a\u001b[0m\u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.6/63.0 MB\u001b[0m \u001b[31m127.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\r\n",
            "Downloading scikit_image-0.22.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.0 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/15.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m15.0/15.0 MB\u001b[0m \u001b[31m143.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading tb_nightly-2.21.0a20250814-py3-none-any.whl (5.5 MB)\r\n",
            "\u001b[?25l   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m0.0/5.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m160.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\r\n",
            "Building wheels for collected packages: basicsr, filterpy\r\n",
            "  Building wheel for basicsr (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\r\n",
            "\u001b[?25h  Created wheel for basicsr: filename=basicsr-1.4.2-py3-none-any.whl size=214818 sha256=cd564109d1a5ea949a6599c254ec55536f8ad81b96931e913cdcdcde39f71d06\r\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1x08013e/wheels/9a/e3/e4/58f29bfabb622dd40b6d9839318ce5bf092062b81ca3aa19ea\r\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
            "\u001b[?25h  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110459 sha256=436d89945ee85167e73bd7661eb819b7227932a6df625e6481abf7dca0ff7858\r\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1x08013e/wheels/77/bf/4c/b0c3f4798a0166668752312a67118b27a3cd341e13ac0ae6ee\r\n",
            "Successfully built basicsr filterpy\r\n",
            "Installing collected packages: trampoline, pydub, lmdb, devicetorch, addict, yapf, tomlkit, semantic-version, requests, python-multipart, pillow, orjson, numpy, imageio-ffmpeg, groovy, future, ffmpy, einops, av, tb-nightly, scipy, opencv-python, opencv-contrib-python, imageio, ffmpeg-python, decord, tokenizers, scikit-image, safehttpx, gradio-client, diffusers, transformers, torchsde, gradio, filterpy, accelerate, timm, peft, facexlib, basicsr, gfpgan, realesrgan\r\n",
            "  Attempting uninstall: requests\r\n",
            "    Found existing installation: requests 2.32.4\r\n",
            "    Uninstalling requests-2.32.4:\r\n",
            "      Successfully uninstalled requests-2.32.4\r\n",
            "  Attempting uninstall: pillow\r\n",
            "    Found existing installation: pillow 11.0.0\r\n",
            "    Uninstalling pillow-11.0.0:\r\n",
            "      Successfully uninstalled pillow-11.0.0\r\n",
            "  Attempting uninstall: numpy\r\n",
            "    Found existing installation: numpy 2.1.2\r\n",
            "    Uninstalling numpy-2.1.2:\r\n",
            "      Successfully uninstalled numpy-2.1.2\r\n",
            "  Attempting uninstall: scipy\r\n",
            "    Found existing installation: scipy 1.16.1\r\n",
            "    Uninstalling scipy-1.16.1:\r\n",
            "      Successfully uninstalled scipy-1.16.1\r\n",
            "  Attempting uninstall: imageio\r\n",
            "    Found existing installation: imageio 2.37.0\r\n",
            "    Uninstalling imageio-2.37.0:\r\n",
            "      Successfully uninstalled imageio-2.37.0\r\n",
            "  Attempting uninstall: tokenizers\r\n",
            "    Found existing installation: tokenizers 0.21.4\r\n",
            "    Uninstalling tokenizers-0.21.4:\r\n",
            "      Successfully uninstalled tokenizers-0.21.4\r\n",
            "  Attempting uninstall: scikit-image\r\n",
            "    Found existing installation: scikit-image 0.25.2\r\n",
            "    Uninstalling scikit-image-0.25.2:\r\n",
            "      Successfully uninstalled scikit-image-0.25.2\r\n",
            "  Attempting uninstall: diffusers\r\n",
            "    Found existing installation: diffusers 0.34.0\r\n",
            "    Uninstalling diffusers-0.34.0:\r\n",
            "      Successfully uninstalled diffusers-0.34.0\r\n",
            "  Attempting uninstall: transformers\r\n",
            "    Found existing installation: transformers 4.55.0\r\n",
            "    Uninstalling transformers-4.55.0:\r\n",
            "      Successfully uninstalled transformers-4.55.0\r\n",
            "  Attempting uninstall: accelerate\r\n",
            "    Found existing installation: accelerate 1.9.0\r\n",
            "    Uninstalling accelerate-1.9.0:\r\n",
            "      Successfully uninstalled accelerate-1.9.0\r\n",
            "Successfully installed accelerate-1.6.0 addict-2.4.0 av-12.1.0 basicsr-1.4.2 decord-0.6.0 devicetorch-0.1.13 diffusers-0.33.1 einops-0.8.1 facexlib-0.3.0 ffmpeg-python-0.2.0 ffmpy-0.6.1 filterpy-1.4.5 future-1.0.0 gfpgan-1.3.8 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 imageio-2.31.1 imageio-ffmpeg-0.4.8 lmdb-1.7.3 numpy-1.26.2 opencv-contrib-python-4.11.0.86 opencv-python-4.11.0.86 orjson-3.11.2 peft-0.17.0 pillow-11.1.0 pydub-0.25.1 python-multipart-0.0.20 realesrgan-0.3.0 requests-2.31.0 safehttpx-0.1.6 scikit-image-0.22.0 scipy-1.12.0 semantic-version-2.10.0 tb-nightly-2.21.0a20250814 timm-1.0.19 tokenizers-0.20.3 tomlkit-0.13.3 torchsde-0.2.6 trampoline-0.1.2 transformers-4.46.2 yapf-0.43.0\r\n",
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y libgl1 libglib2.0-0 libsm6 libxext6 libxrender-dev ffmpeg\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://deb.debian.org/debian bookworm InRelease [151 kB]\r\n",
            "\r0% [Connecting to developer.download.nvidia.com] [1 InRelease 0 B/151 kB 0%]\r                                                                            \r0% [Connecting to developer.download.nvidia.com (23.53.11.143)]\r                                                               \rGet:2 http://deb.debian.org/debian bookworm-updates InRelease [55.4 kB]\r\n",
            "\r                                                               \rGet:3 http://deb.debian.org/debian-security bookworm-security InRelease [48.0 kB]\r\n",
            "\r                                                               \r0% [Waiting for headers]\r                        \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/debian12/x86_64  InRelease [1581 B]\r\n",
            "\r0% [4 InRelease 1581 B/1581 B 100%]\r                                   \r0% [Working]\r0% [Working]\r0% [Working]\r            \rGet:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages.diff/Index [21.8 kB]\r\n",
            "\r0% [5 Packages 21.8 kB/21.8 kB 100%]\r                                    \rIgn:5 http://deb.debian.org/debian bookworm-updates/main amd64 Packages.diff/Index\r\n",
            "\r                                    \r0% [Working]\r            \rGet:6 http://deb.debian.org/debian bookworm-updates/main amd64 Packages [6924 B]\r\n",
            "\r0% [6 Packages 6924 B/6924 B 100%]\r                                  \r0% [Working]\r0% [6 Packages store 0 B]\r                         \r0% [Working]\r0% [Working]\r            \rGet:7 http://deb.debian.org/debian-security bookworm-security/main amd64 Packages [274 kB]\r\n",
            "\r0% [7 Packages 1444 B/274 kB 1%]\r                                \r0% [Working]\r0% [7 Packages store 0 B]\r                         \r0% [Working]\r44% [Working]\r             \rGet:8 https://developer.download.nvidia.com/compute/cuda/repos/debian12/x86_64  Packages [1116 kB]\r\n",
            "\r45% [8 Packages 15.9 kB/1116 kB 1%]\r                                   \r97% [Working]\r97% [8 Packages store 0 B]\r                          \r99% [Working]\r             \rFetched 1675 kB in 1s (1778 kB/s)\r\n",
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... Done\r\r\n",
            "N: Repository 'http://deb.debian.org/debian bookworm InRelease' changed its 'Suite' value from 'stable' to 'oldstable'\r\n",
            "N: Repository 'http://deb.debian.org/debian bookworm-updates InRelease' changed its 'Suite' value from 'stable-updates' to 'oldstable-updates'\r\n",
            "N: Repository 'http://deb.debian.org/debian-security bookworm-security InRelease' changed its 'Suite' value from 'stable-security' to 'oldstable-security'\r\n",
            "\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 96%\r\rReading package lists... 99%\r\rReading package lists... 99%\r\rReading package lists... Done\r\r\n",
            "\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... Done\r\r\n",
            "\rReading state information... 0% \r\rReading state information... 0%\r\rReading state information... Done\r\r\n",
            "libxext6 is already the newest version (2:1.3.4-1+b1).\r\n",
            "libxext6 set to manually installed.\r\n",
            "The following additional packages will be installed:\r\n",
            "  alsa-topology-conf alsa-ucm-conf fontconfig i965-va-driver intel-media-va-driver libaacs0 libasound2\r\n",
            "  libasound2-data libass9 libasyncns0 libavc1394-0 libavcodec59 libavdevice59 libavfilter8 libavformat59\r\n",
            "  libavutil57 libbdplus0 libblas3 libbluray2 libbs2b0 libcaca0 libcairo-gobject2 libcairo2 libcdio-cdda2\r\n",
            "  libcdio-paranoia2 libcdio19 libchromaprint1 libcjson1 libcodec2-1.0 libdatrie1 libdc1394-25 libdecor-0-0\r\n",
            "  libdecor-0-plugin-1-cairo libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2\r\n",
            "  libelf1 libepoxy0 libflac12 libflite1 libfribidi0 libgbm1 libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin\r\n",
            "  libgdk-pixbuf2.0-common libgl1-mesa-dri libglapi-mesa libglib2.0-data libglvnd0 libglx-mesa0 libglx0 libgme0\r\n",
            "  libgraphite2-3 libgsm1 libharfbuzz0b libhwy1 libice6 libiec61883-0 libigdgmm12 libjack-jackd2-0 libjxl0.7\r\n",
            "  liblapack3 liblcms2-2 liblilv-0-0 libllvm15 libmbedcrypto7 libmfx1 libmp3lame0 libmpg123-0 libmysofa1\r\n",
            "  libnorm1 libogg0 libopenal-data libopenal1 libopenjp2-7 libopenmpt0 libopus0 libpango-1.0-0\r\n",
            "  libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0 libpgm-5.3-0 libpixman-1-0 libplacebo208 libpocketsphinx3\r\n",
            "  libpostproc56 libpthread-stubs0-dev libpulse0 libpython3-stdlib libpython3.11-minimal libpython3.11-stdlib\r\n",
            "  librabbitmq4 libraw1394-11 librist4 librsvg2-2 librsvg2-common librubberband2 libsamplerate0 libsdl2-2.0-0\r\n",
            "  libsensors-config libsensors5 libserd-0-0 libshine3 libslang2 libsnappy1v5 libsndfile1 libsndio7.0\r\n",
            "  libsord-0-0 libsoxr0 libspeex1 libsphinxbase3 libsratom-0-0 libsrt1.5-gnutls libssh-gcrypt-4 libswresample4\r\n",
            "  libswscale6 libthai-data libthai0 libtheora0 libtwolame0 libudfread0 libusb-1.0-0 libva-drm2 libva-x11-2\r\n",
            "  libva2 libvdpau-va-gl1 libvdpau1 libvidstab1.1 libvorbis0a libvorbisenc2 libvorbisfile3 libvpx7 libvulkan1\r\n",
            "  libwayland-client0 libwayland-cursor0 libwayland-egl1 libwayland-server0 libwebpmux3 libx11-dev libx11-xcb1\r\n",
            "  libx264-164 libxau-dev libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-render0\r\n",
            "  libxcb-shape0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1-dev libxcursor1 libxdmcp-dev libxfixes3 libxi6\r\n",
            "  libxkbcommon0 libxrandr2 libxrender1 libxshmfence1 libxss1 libxv1 libxvidcore4 libxxf86vm1 libz3-4 libzimg2\r\n",
            "  libzmq5 libzvbi-common libzvbi0 media-types mesa-va-drivers mesa-vdpau-drivers mesa-vulkan-drivers\r\n",
            "  ocl-icd-libopencl1 pocketsphinx-en-us python3 python3-minimal python3.11 python3.11-minimal shared-mime-info\r\n",
            "  va-driver-all vdpau-driver-all x11-common x11proto-dev xdg-user-dirs xkb-data xorg-sgml-doctools xtrans-dev\r\n",
            "Suggested packages:\r\n",
            "  ffmpeg-doc i965-va-driver-shaders libasound2-plugins alsa-utils libcuda1 libnvcuvid1 libnvidia-encode1\r\n",
            "  libbluray-bdj low-memory-monitor jackd2 liblcms2-utils libportaudio2 opus-tools pciutils pulseaudio\r\n",
            "  libraw1394-doc librsvg2-bin xdg-utils lm-sensors serdi sndiod sordi speex libx11-doc libxcb-doc opencl-icd\r\n",
            "  python3-doc python3-tk python3-venv python3.11-venv python3.11-doc binfmt-support nvidia-vdpau-driver\r\n",
            "  nvidia-tesla-440-vdpau-driver nvidia-tesla-418-vdpau-driver nvidia-legacy-390xx-vdpau-driver\r\n",
            "  nvidia-legacy-340xx-vdpau-driver\r\n",
            "The following NEW packages will be installed:\r\n",
            "  alsa-topology-conf alsa-ucm-conf ffmpeg fontconfig i965-va-driver intel-media-va-driver libaacs0 libasound2\r\n",
            "  libasound2-data libass9 libasyncns0 libavc1394-0 libavcodec59 libavdevice59 libavfilter8 libavformat59\r\n",
            "  libavutil57 libbdplus0 libblas3 libbluray2 libbs2b0 libcaca0 libcairo-gobject2 libcairo2 libcdio-cdda2\r\n",
            "  libcdio-paranoia2 libcdio19 libchromaprint1 libcjson1 libcodec2-1.0 libdatrie1 libdc1394-25 libdecor-0-0\r\n",
            "  libdecor-0-plugin-1-cairo libdrm-amdgpu1 libdrm-common libdrm-intel1 libdrm-nouveau2 libdrm-radeon1 libdrm2\r\n",
            "  libelf1 libepoxy0 libflac12 libflite1 libfribidi0 libgbm1 libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin\r\n",
            "  libgdk-pixbuf2.0-common libgl1 libgl1-mesa-dri libglapi-mesa libglib2.0-0 libglib2.0-data libglvnd0\r\n",
            "  libglx-mesa0 libglx0 libgme0 libgraphite2-3 libgsm1 libharfbuzz0b libhwy1 libice6 libiec61883-0 libigdgmm12\r\n",
            "  libjack-jackd2-0 libjxl0.7 liblapack3 liblcms2-2 liblilv-0-0 libllvm15 libmbedcrypto7 libmfx1 libmp3lame0\r\n",
            "  libmpg123-0 libmysofa1 libnorm1 libogg0 libopenal-data libopenal1 libopenjp2-7 libopenmpt0 libopus0\r\n",
            "  libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0 libpciaccess0 libpgm-5.3-0 libpixman-1-0 libplacebo208\r\n",
            "  libpocketsphinx3 libpostproc56 libpthread-stubs0-dev libpulse0 libpython3-stdlib libpython3.11-minimal\r\n",
            "  libpython3.11-stdlib librabbitmq4 libraw1394-11 librist4 librsvg2-2 librsvg2-common librubberband2\r\n",
            "  libsamplerate0 libsdl2-2.0-0 libsensors-config libsensors5 libserd-0-0 libshine3 libslang2 libsm6\r\n",
            "  libsnappy1v5 libsndfile1 libsndio7.0 libsord-0-0 libsoxr0 libspeex1 libsphinxbase3 libsratom-0-0\r\n",
            "  libsrt1.5-gnutls libssh-gcrypt-4 libswresample4 libswscale6 libthai-data libthai0 libtheora0 libtwolame0\r\n",
            "  libudfread0 libusb-1.0-0 libva-drm2 libva-x11-2 libva2 libvdpau-va-gl1 libvdpau1 libvidstab1.1 libvorbis0a\r\n",
            "  libvorbisenc2 libvorbisfile3 libvpx7 libvulkan1 libwayland-client0 libwayland-cursor0 libwayland-egl1\r\n",
            "  libwayland-server0 libwebpmux3 libx11-dev libx11-xcb1 libx264-164 libxau-dev libxcb-dri2-0 libxcb-dri3-0\r\n",
            "  libxcb-glx0 libxcb-present0 libxcb-randr0 libxcb-render0 libxcb-shape0 libxcb-shm0 libxcb-sync1\r\n",
            "  libxcb-xfixes0 libxcb1-dev libxcursor1 libxdmcp-dev libxfixes3 libxi6 libxkbcommon0 libxrandr2 libxrender-dev\r\n",
            "  libxrender1 libxshmfence1 libxss1 libxv1 libxvidcore4 libxxf86vm1 libz3-4 libzimg2 libzmq5 libzvbi-common\r\n",
            "  libzvbi0 media-types mesa-va-drivers mesa-vdpau-drivers mesa-vulkan-drivers ocl-icd-libopencl1\r\n",
            "  pocketsphinx-en-us python3 python3-minimal python3.11 python3.11-minimal shared-mime-info va-driver-all\r\n",
            "  vdpau-driver-all x11-common x11proto-dev xdg-user-dirs xkb-data xorg-sgml-doctools xtrans-dev\r\n",
            "0 upgraded, 197 newly installed, 0 to remove and 53 not upgraded.\r\n",
            "Need to get 159 MB of archives.\r\n",
            "After this operation, 538 MB of additional disk space will be used.\r\n",
            "\r0% [Working]\r            \rGet:1 http://deb.debian.org/debian bookworm/main amd64 libpython3.11-minimal amd64 3.11.2-6+deb12u6 [817 kB]\r\n",
            "\r0% [1 libpython3.11-minimal 21.7 kB/817 kB 3%]\r                                              \r1% [Working]\r            \rGet:2 http://deb.debian.org/debian bookworm/main amd64 python3.11-minimal amd64 3.11.2-6+deb12u6 [2064 kB]\r\n",
            "\r1% [2 python3.11-minimal 0 B/2064 kB 0%]\r                                        \r2% [Waiting for headers]\r                        \rGet:3 http://deb.debian.org/debian bookworm/main amd64 python3-minimal amd64 3.11.2-1+b1 [26.3 kB]\r\n",
            "\r2% [3 python3-minimal 26.3 kB/26.3 kB 100%]\r                                           \r2% [Working]\r            \rGet:4 http://deb.debian.org/debian bookworm/main amd64 media-types all 10.0.0 [26.1 kB]\r\n",
            "\r2% [Working]\r            \rGet:5 http://deb.debian.org/debian bookworm/main amd64 libpython3.11-stdlib amd64 3.11.2-6+deb12u6 [1798 kB]\r\n",
            "\r2% [5 libpython3.11-stdlib 130 kB/1798 kB 7%]\r                                             \r3% [Waiting for headers]\r                        \rGet:6 http://deb.debian.org/debian bookworm/main amd64 python3.11 amd64 3.11.2-6+deb12u6 [573 kB]\r\n",
            "\r3% [6 python3.11 100 kB/573 kB 17%]\r                                   \r3% [Waiting for headers]\r                        \rGet:7 http://deb.debian.org/debian bookworm/main amd64 libpython3-stdlib amd64 3.11.2-1+b1 [9312 B]\r\n",
            "\r3% [Waiting for headers]\r                        \rGet:8 http://deb.debian.org/debian bookworm/main amd64 python3 amd64 3.11.2-1+b1 [26.3 kB]\r\n",
            "\r                        \rGet:9 http://deb.debian.org/debian bookworm/main amd64 alsa-topology-conf all 1.2.5.1-2 [15.2 kB]\r\n",
            "\r4% [9 alsa-topology-conf 15.2 kB/15.2 kB 100%]\r                                              \rGet:10 http://deb.debian.org/debian bookworm/main amd64 libasound2-data all 1.2.8-1 [20.5 kB]\r\n",
            "\r                                              \r4% [10 libasound2-data 20.5 kB/20.5 kB 100%]\r                                            \rGet:11 http://deb.debian.org/debian bookworm/main amd64 libasound2 amd64 1.2.8-1+b1 [362 kB]\r\n",
            "\r                                            \r4% [11 libasound2 130 kB/362 kB 36%]\r                                    \r4% [Working]\r            \rGet:12 http://deb.debian.org/debian bookworm/main amd64 alsa-ucm-conf all 1.2.8-1 [51.7 kB]\r\n",
            "\r4% [12 alsa-ucm-conf 29.7 kB/51.7 kB 58%]\r                                         \r4% [Working]\r            \rGet:13 http://deb.debian.org/debian bookworm/main amd64 libdrm-common all 2.4.114-1 [7112 B]\r\n",
            "\r4% [13 libdrm-common 7112 B/7112 B 100%]\r                                        \r4% [Working]\r            \rGet:14 http://deb.debian.org/debian bookworm/main amd64 libdrm2 amd64 2.4.114-1+b1 [37.5 kB]\r\n",
            "\r4% [14 libdrm2 37.5 kB/37.5 kB 100%]\r                                    \r4% [Waiting for headers]\r                        \rGet:15 http://deb.debian.org/debian bookworm/main amd64 libva2 amd64 2.17.0-1 [69.2 kB]\r\n",
            "\r4% [15 libva2 64.7 kB/69.2 kB 94%]\r                                  \r4% [Working]\r            \rGet:16 http://deb.debian.org/debian bookworm/main amd64 libmfx1 amd64 22.5.4-1 [3219 kB]\r\n",
            "\r5% [16 libmfx1 46.3 kB/3219 kB 1%]\r                                  \r6% [Waiting for headers]\r                        \rGet:17 http://deb.debian.org/debian bookworm/main amd64 libva-drm2 amd64 2.17.0-1 [16.4 kB]\r\n",
            "\r                        \rGet:18 http://deb.debian.org/debian bookworm/main amd64 libx11-xcb1 amd64 2:1.8.4-2+deb12u2 [192 kB]\r\n",
            "\r6% [18 libx11-xcb1 130 kB/192 kB 68%]\r                                     \r7% [Working]\r            \rGet:19 http://deb.debian.org/debian bookworm/main amd64 libxcb-dri3-0 amd64 1.15-1 [107 kB]\r\n",
            "\r7% [19 libxcb-dri3-0 68.1 kB/107 kB 64%]\r                                        \r7% [Waiting for headers]\r                        \rGet:20 http://deb.debian.org/debian bookworm/main amd64 libxfixes3 amd64 1:6.0.0-2 [22.7 kB]\r\n",
            "\r7% [20 libxfixes3 22.7 kB/22.7 kB 100%]\r                                       \r7% [Working]\r            \rGet:21 http://deb.debian.org/debian bookworm/main amd64 libva-x11-2 amd64 2.17.0-1 [21.0 kB]\r\n",
            "\r7% [Working]\r            \rGet:22 http://deb.debian.org/debian bookworm/main amd64 libvdpau1 amd64 1.5-2 [26.1 kB]\r\n",
            "\r            \rGet:23 http://deb.debian.org/debian bookworm/main amd64 ocl-icd-libopencl1 amd64 2.3.1-1 [43.0 kB]\r\n",
            "\r7% [23 ocl-icd-libopencl1 43.0 kB/43.0 kB 100%]\r                                               \r7% [Working]\r            \rGet:24 http://deb.debian.org/debian bookworm/main amd64 libavutil57 amd64 7:5.1.6-0+deb12u1 [365 kB]\r\n",
            "\r7% [24 libavutil57 128 kB/365 kB 35%]\r                                     \r7% [Working]\r            \rGet:25 http://deb.debian.org/debian bookworm/main amd64 libpixman-1-0 amd64 0.42.2-1 [546 kB]\r\n",
            "\r7% [25 libpixman-1-0 91.9 kB/546 kB 17%]\r                                        \rGet:26 http://deb.debian.org/debian bookworm/main amd64 libxcb-render0 amd64 1.15-1 [115 kB]\r\n",
            "\r8% [26 libxcb-render0 69.8 kB/115 kB 61%]\r                                         \r8% [Working]\r            \rGet:27 http://deb.debian.org/debian bookworm/main amd64 libxcb-shm0 amd64 1.15-1 [105 kB]\r\n",
            "\r8% [Working]\r            \rGet:28 http://deb.debian.org/debian bookworm/main amd64 libxrender1 amd64 1:0.9.10-1.1 [33.2 kB]\r\n",
            "\r8% [Working]\r            \rGet:29 http://deb.debian.org/debian bookworm/main amd64 libcairo2 amd64 1.16.0-7 [575 kB]\r\n",
            "\r8% [29 libcairo2 64.7 kB/575 kB 11%]\r                                    \r9% [Waiting for headers]\r                        \rGet:30 http://deb.debian.org/debian bookworm/main amd64 libcodec2-1.0 amd64 1.0.5-1 [8171 kB]\r\n",
            "\r9% [30 libcodec2-1.0 79.0 kB/8171 kB 1%]\r                                        \r13% [Waiting for headers]\r                         \rGet:31 http://deb.debian.org/debian bookworm/main amd64 libglib2.0-0 amd64 2.74.6-2+deb12u6 [1400 kB]\r\n",
            "\r13% [31 libglib2.0-0 42.0 kB/1400 kB 3%]\r                                        \r14% [Waiting for headers]\r                         \rGet:32 http://deb.debian.org/debian bookworm/main amd64 libgsm1 amd64 1.0.22-1 [30.9 kB]\r\n",
            "\r                         \r14% [Working]\r             \rGet:33 http://deb.debian.org/debian bookworm/main amd64 libhwy1 amd64 1.0.3-3+deb12u1 [348 kB]\r\n",
            "\r14% [33 libhwy1 119 kB/348 kB 34%]\r                                  \r14% [Waiting for headers]\r                         \rGet:34 http://deb.debian.org/debian bookworm/main amd64 liblcms2-2 amd64 2.14-2 [154 kB]\r\n",
            "\r14% [34 liblcms2-2 32.4 kB/154 kB 21%]\r                                      \r14% [Waiting for headers]\r                         \rGet:35 http://deb.debian.org/debian-security bookworm-security/main amd64 libjxl0.7 amd64 0.7.0-10+deb12u1 [1046 kB]\r\n",
            "\r14% [35 libjxl0.7 205 kB/1046 kB 20%]\r                                     \r15% [Waiting for headers]\r                         \rGet:36 http://deb.debian.org/debian bookworm/main amd64 libmp3lame0 amd64 3.100-6 [365 kB]\r\n",
            "\r15% [36 libmp3lame0 79.7 kB/365 kB 22%]\r                                       \r15% [Waiting for headers]\r                         \rGet:37 http://deb.debian.org/debian bookworm/main amd64 libopenjp2-7 amd64 2.5.0-2+deb12u1 [189 kB]\r\n",
            "\r15% [37 libopenjp2-7 134 kB/189 kB 71%]\r                                       \r15% [Working]\r             \rGet:38 http://deb.debian.org/debian bookworm/main amd64 libopus0 amd64 1.3.1-3 [195 kB]\r\n",
            "\r15% [38 libopus0 9219 B/195 kB 5%]\r                                  \r16% [Working]\r             \rGet:39 http://deb.debian.org/debian bookworm/main amd64 libcairo-gobject2 amd64 1.16.0-7 [112 kB]\r\n",
            "\r16% [39 libcairo-gobject2 75.3 kB/112 kB 67%]\r                                             \r16% [Waiting for headers]\r                         \rGet:40 http://deb.debian.org/debian-security bookworm-security/main amd64 libgdk-pixbuf2.0-common all 2.42.10+dfsg-1+deb12u2 [306 kB]\r\n",
            "\r16% [40 libgdk-pixbuf2.0-common 93.6 kB/306 kB 31%]\r                                                   \r16% [Working]\r             \rGet:41 http://deb.debian.org/debian bookworm/main amd64 shared-mime-info amd64 2.2-1 [729 kB]\r\n",
            "\r16% [41 shared-mime-info 48.6 kB/729 kB 7%]\r                                           \r16% [Waiting for headers]\r                         \rGet:42 http://deb.debian.org/debian-security bookworm-security/main amd64 libgdk-pixbuf-2.0-0 amd64 2.42.10+dfsg-1+deb12u2 [138 kB]\r\n",
            "\r16% [42 libgdk-pixbuf-2.0-0 138 kB/138 kB 100%]\r                                               \r17% [Working]\r             \rGet:43 http://deb.debian.org/debian bookworm/main amd64 fontconfig amd64 2.14.1-4 [449 kB]\r\n",
            "\r17% [43 fontconfig 64.6 kB/449 kB 14%]\r                                      \r17% [Working]\r             \rGet:44 http://deb.debian.org/debian bookworm/main amd64 libfribidi0 amd64 1.0.8-2.1 [65.0 kB]\r\n",
            "\r17% [44 libfribidi0 40.0 kB/65.0 kB 62%]\r                                        \r17% [Working]\r             \rGet:45 http://deb.debian.org/debian bookworm/main amd64 libgraphite2-3 amd64 1.3.14-1 [81.2 kB]\r\n",
            "\r17% [45 libgraphite2-3 73.1 kB/81.2 kB 90%]\r                                           \r17% [Working]\r             \rGet:46 http://deb.debian.org/debian bookworm/main amd64 libharfbuzz0b amd64 6.0.0+dfsg-3 [1945 kB]\r\n",
            "\r17% [46 libharfbuzz0b 23.2 kB/1945 kB 1%]\r                                         \r18% [Working]\r             \rGet:47 http://deb.debian.org/debian bookworm/main amd64 libthai-data all 0.1.29-1 [176 kB]\r\n",
            "\r18% [47 libthai-data 109 kB/176 kB 62%]\r                                       \r18% [Waiting for headers]\r                         \rGet:48 http://deb.debian.org/debian bookworm/main amd64 libdatrie1 amd64 0.2.13-2+b1 [43.3 kB]\r\n",
            "\r18% [48 libdatrie1 43.3 kB/43.3 kB 100%]\r                                        \r19% [Working]\r             \rGet:49 http://deb.debian.org/debian bookworm/main amd64 libthai0 amd64 0.1.29-1 [57.5 kB]\r\n",
            "\r19% [49 libthai0 57.5 kB/57.5 kB 100%]\r                                      \r19% [Working]\r             \rGet:50 http://deb.debian.org/debian bookworm/main amd64 libpango-1.0-0 amd64 1.50.12+ds-1 [212 kB]\r\n",
            "\r19% [50 libpango-1.0-0 59.0 kB/212 kB 28%]\r                                          \r19% [Waiting for headers]\r                         \rGet:51 http://deb.debian.org/debian bookworm/main amd64 libpangoft2-1.0-0 amd64 1.50.12+ds-1 [47.4 kB]\r\n",
            "\r19% [51 libpangoft2-1.0-0 47.4 kB/47.4 kB 100%]\r                                               \r19% [Working]\r             \rGet:52 http://deb.debian.org/debian bookworm/main amd64 libpangocairo-1.0-0 amd64 1.50.12+ds-1 [34.2 kB]\r\n",
            "\r19% [52 libpangocairo-1.0-0 34.2 kB/34.2 kB 100%]\r                                                 \r19% [Working]\r             \rGet:53 http://deb.debian.org/debian bookworm/main amd64 librsvg2-2 amd64 2.54.7+dfsg-1~deb12u1 [2620 kB]\r\n",
            "\r19% [53 librsvg2-2 25.2 kB/2620 kB 1%]\r                                      \r21% [Working]\r             \rGet:54 http://deb.debian.org/debian bookworm/main amd64 libshine3 amd64 3.1.1-2 [23.6 kB]\r\n",
            "\r21% [Waiting for headers]\r                         \rGet:55 http://deb.debian.org/debian bookworm/main amd64 libsnappy1v5 amd64 1.1.9-3 [26.0 kB]\r\n",
            "\r                         \r21% [Working]\r             \rGet:56 http://deb.debian.org/debian bookworm/main amd64 libspeex1 amd64 1.2.1-2 [54.6 kB]\r\n",
            "\r21% [56 libspeex1 54.6 kB/54.6 kB 100%]\r                                       \r21% [Working]\r             \rGet:57 http://deb.debian.org/debian bookworm/main amd64 libsoxr0 amd64 0.1.3-4 [77.8 kB]\r\n",
            "\r21% [57 libsoxr0 50.0 kB/77.8 kB 64%]\r                                     \r21% [Working]\r             \rGet:58 http://deb.debian.org/debian bookworm/main amd64 libswresample4 amd64 7:5.1.6-0+deb12u1 [99.3 kB]\r\n",
            "\r21% [58 libswresample4 51.6 kB/99.3 kB 52%]\r                                           \r21% [Working]\r             \rGet:59 http://deb.debian.org/debian bookworm/main amd64 libogg0 amd64 1.3.5-3 [23.4 kB]\r\n",
            "\r21% [59 libogg0 16.9 kB/23.4 kB 72%]\r                                    \r21% [Working]\r             \rGet:60 http://deb.debian.org/debian bookworm/main amd64 libtheora0 amd64 1.1.1+dfsg.1-16.1+b1 [154 kB]\r\n",
            "\r21% [60 libtheora0 43.5 kB/154 kB 28%]\r                                      \r22% [Waiting for headers]\r                         \rGet:61 http://deb.debian.org/debian bookworm/main amd64 libtwolame0 amd64 0.4.0-2 [51.1 kB]\r\n",
            "\r22% [61 libtwolame0 34.6 kB/51.1 kB 68%]\r                                        \r22% [Working]\r             \rGet:62 http://deb.debian.org/debian bookworm/main amd64 libvorbis0a amd64 1.3.7-1 [93.0 kB]\r\n",
            "\r22% [62 libvorbis0a 48.2 kB/93.0 kB 52%]\r                                        \r22% [Working]\r             \rGet:63 http://deb.debian.org/debian bookworm/main amd64 libvorbisenc2 amd64 1.3.7-1 [80.6 kB]\r\n",
            "\r22% [63 libvorbisenc2 19.9 kB/80.6 kB 25%]\r                                          \r22% [Working]\r             \rGet:64 http://deb.debian.org/debian-security bookworm-security/main amd64 libvpx7 amd64 1.12.0-1+deb12u4 [1003 kB]\r\n",
            "\r22% [64 libvpx7 3948 B/1003 kB 0%]\r                                  \r23% [Working]\r             \rGet:65 http://deb.debian.org/debian bookworm/main amd64 libwebpmux3 amd64 1.2.4-0.2+deb12u1 [109 kB]\r\n",
            "\r23% [65 libwebpmux3 64.5 kB/109 kB 59%]\r                                       \r23% [Working]\r             \rGet:66 http://deb.debian.org/debian bookworm/main amd64 libx264-164 amd64 2:0.164.3095+gitbaee400-3 [547 kB]\r\n",
            "\r23% [66 libx264-164 19.6 kB/547 kB 4%]\r                                      \r23% [Waiting for headers]\r                         \rGet:67 http://deb.debian.org/debian bookworm/main amd64 libxvidcore4 amd64 2:1.3.7-1 [242 kB]\r\n",
            "\r23% [67 libxvidcore4 61.5 kB/242 kB 25%]\r                                        \r23% [Working]\r             \rGet:68 http://deb.debian.org/debian bookworm/main amd64 libzvbi-common all 0.2.41-1 [69.7 kB]\r\n",
            "\r23% [68 libzvbi-common 69.7 kB/69.7 kB 100%]\r                                            \r23% [Working]\r             \rGet:69 http://deb.debian.org/debian bookworm/main amd64 libzvbi0 amd64 0.2.41-1 [274 kB]\r\n",
            "\r23% [69 libzvbi0 44.9 kB/274 kB 16%]\r                                    \r24% [Working]\r             \rGet:70 http://deb.debian.org/debian bookworm/main amd64 libavcodec59 amd64 7:5.1.6-0+deb12u1 [5222 kB]\r\n",
            "\r24% [70 libavcodec59 31.5 kB/5222 kB 1%]\r                                        \r26% [Waiting for headers]\r                         \rGet:71 http://deb.debian.org/debian bookworm/main amd64 libraw1394-11 amd64 2.1.2-2 [41.1 kB]\r\n",
            "\r27% [Waiting for headers]\r                         \rGet:72 http://deb.debian.org/debian bookworm/main amd64 libavc1394-0 amd64 0.5.4-5 [19.9 kB]\r\n",
            "\r                         \rGet:73 http://deb.debian.org/debian bookworm/main amd64 libass9 amd64 1:0.17.1-1 [107 kB]\r\n",
            "\r27% [73 libass9 107 kB/107 kB 100%]\r                                   \rGet:74 http://deb.debian.org/debian bookworm/main amd64 libudfread0 amd64 1.1.2-1 [16.5 kB]\r\n",
            "\r27% [74 libudfread0 16.5 kB/16.5 kB 100%]\r                                         \rGet:75 http://deb.debian.org/debian bookworm/main amd64 libbluray2 amd64 1:1.3.4-1 [138 kB]\r\n",
            "\r                                         \r27% [75 libbluray2 138 kB/138 kB 100%]\r                                      \r27% [Waiting for headers]\r                         \rGet:76 http://deb.debian.org/debian bookworm/main amd64 libchromaprint1 amd64 1.5.1-2+b1 [41.0 kB]\r\n",
            "\r                         \r27% [Working]\r             \rGet:77 http://deb.debian.org/debian bookworm/main amd64 libgme0 amd64 0.6.3-6 [130 kB]\r\n",
            "\r27% [77 libgme0 64.7 kB/130 kB 50%]\r                                   \r27% [Waiting for headers]\r                         \rGet:78 http://deb.debian.org/debian bookworm/main amd64 libmpg123-0 amd64 1.31.2-1+deb12u1 [147 kB]\r\n",
            "\r28% [Waiting for headers]\r                         \rGet:79 http://deb.debian.org/debian bookworm/main amd64 libvorbisfile3 amd64 1.3.7-1 [26.1 kB]\r\n",
            "\r                         \r28% [Working]\r             \rGet:80 http://deb.debian.org/debian bookworm/main amd64 libopenmpt0 amd64 0.6.9-1 [693 kB]\r\n",
            "\r28% [80 libopenmpt0 64.7 kB/693 kB 9%]\r                                      \r28% [Waiting for headers]\r                         \rGet:81 http://deb.debian.org/debian bookworm/main amd64 librabbitmq4 amd64 0.11.0-1+deb12u1 [41.4 kB]\r\n",
            "\r                         \rGet:82 http://deb.debian.org/debian bookworm/main amd64 libcjson1 amd64 1.7.15-1+deb12u2 [22.9 kB]\r\n",
            "\r28% [82 libcjson1 22.9 kB/22.9 kB 100%]\r                                       \rGet:83 http://deb.debian.org/debian bookworm/main amd64 libmbedcrypto7 amd64 2.28.3-1 [277 kB]\r\n",
            "\r28% [83 libmbedcrypto7 191 kB/277 kB 69%]\r                                         \r29% [Waiting for headers]\r                         \rGet:84 http://deb.debian.org/debian bookworm/main amd64 librist4 amd64 0.2.7+dfsg-1 [73.9 kB]\r\n",
            "\r29% [84 librist4 48.9 kB/73.9 kB 66%]\r                                     \r29% [Working]\r             \rGet:85 http://deb.debian.org/debian bookworm/main amd64 libsrt1.5-gnutls amd64 1.5.1-1+deb12u1 [313 kB]\r\n",
            "\r29% [85 libsrt1.5-gnutls 39.7 kB/313 kB 13%]\r                                            \r29% [Waiting for headers]\r                         \rGet:86 http://deb.debian.org/debian bookworm/main amd64 libssh-gcrypt-4 amd64 0.10.6-0+deb12u1 [219 kB]\r\n",
            "\r29% [86 libssh-gcrypt-4 53.4 kB/219 kB 24%]\r                                           \r29% [Waiting for headers]\r                         \rGet:87 http://deb.debian.org/debian bookworm/main amd64 libnorm1 amd64 1.5.9+dfsg-2 [221 kB]\r\n",
            "\r29% [87 libnorm1 90.5 kB/221 kB 41%]\r                                    \r29% [Waiting for headers]\r                         \rGet:88 http://deb.debian.org/debian bookworm/main amd64 libpgm-5.3-0 amd64 5.3.128~dfsg-2 [161 kB]\r\n",
            "\r29% [88 libpgm-5.3-0 131 kB/161 kB 81%]\r                                       \r30% [Waiting for headers]\r                         \rGet:89 http://deb.debian.org/debian bookworm/main amd64 libzmq5 amd64 4.3.4-6 [273 kB]\r\n",
            "\r                         \rGet:90 http://deb.debian.org/debian bookworm/main amd64 libavformat59 amd64 7:5.1.6-0+deb12u1 [1104 kB]\r\n",
            "\r30% [90 libavformat59 154 kB/1104 kB 14%]\r                                         \r31% [Waiting for headers]\r                         \rGet:91 http://deb.debian.org/debian bookworm/main amd64 libbs2b0 amd64 3.1.0+dfsg-7 [11.5 kB]\r\n",
            "\r31% [Waiting for headers]\r                         \rGet:92 http://deb.debian.org/debian bookworm/main amd64 libflite1 amd64 2.2-5 [12.8 MB]\r\n",
            "\r31% [92 libflite1 85.2 kB/12.8 MB 1%]\r                                     \r37% [Waiting for headers]\r                         \rGet:93 http://deb.debian.org/debian bookworm/main amd64 libserd-0-0 amd64 0.30.16-1 [47.5 kB]\r\n",
            "\r                         \rGet:94 http://deb.debian.org/debian bookworm/main amd64 libsord-0-0 amd64 0.16.14+git221008-1 [20.8 kB]\r\n",
            "\r37% [94 libsord-0-0 20.8 kB/20.8 kB 100%]\r                                         \rGet:95 http://deb.debian.org/debian bookworm/main amd64 libsratom-0-0 amd64 0.6.14-1 [17.7 kB]\r\n",
            "\r37% [95 libsratom-0-0 17.7 kB/17.7 kB 100%]\r                                           \rGet:96 http://deb.debian.org/debian bookworm/main amd64 liblilv-0-0 amd64 0.24.14-1 [49.4 kB]\r\n",
            "\r                                           \rGet:97 http://deb.debian.org/debian bookworm/main amd64 libmysofa1 amd64 1.3.1~dfsg0-1 [1158 kB]\r\n",
            "\r                                           \r38% [97 libmysofa1 196 kB/1158 kB 17%]\r                                      \r38% [Working]\r             \rGet:98 http://deb.debian.org/debian bookworm/main amd64 libepoxy0 amd64 1.5.10-1 [189 kB]\r\n",
            "\r38% [98 libepoxy0 85.7 kB/189 kB 45%]\r                                     \r39% [Waiting for headers]\r                         \rGet:99 http://deb.debian.org/debian bookworm/main amd64 libvulkan1 amd64 1.3.239.0-1 [116 kB]\r\n",
            "\r39% [99 libvulkan1 60.0 kB/116 kB 52%]\r                                      \r39% [Waiting for headers]\r                         \rGet:100 http://deb.debian.org/debian bookworm/main amd64 libplacebo208 amd64 4.208.0-3 [2239 kB]\r\n",
            "\r39% [100 libplacebo208 106 kB/2239 kB 5%]\r                                         \r40% [Working]\r             \rGet:101 http://deb.debian.org/debian bookworm/main amd64 libblas3 amd64 3.11.0-2 [149 kB]\r\n",
            "\r40% [101 libblas3 95.1 kB/149 kB 64%]\r                                     \r40% [Working]\r             \rGet:102 http://deb.debian.org/debian bookworm/main amd64 liblapack3 amd64 3.11.0-2 [2323 kB]\r\n",
            "\r40% [102 liblapack3 44.5 kB/2323 kB 2%]\r                                       \r41% [Waiting for headers]\r                         \rGet:103 http://deb.debian.org/debian bookworm/main amd64 libasyncns0 amd64 0.8-6+b3 [12.9 kB]\r\n",
            "\r                         \rGet:104 http://deb.debian.org/debian bookworm/main amd64 libflac12 amd64 1.4.2+ds-2 [198 kB]\r\n",
            "\r42% [104 libflac12 198 kB/198 kB 100%]\r                                      \rGet:105 http://deb.debian.org/debian bookworm/main amd64 libsndfile1 amd64 1.2.0-1 [196 kB]\r\n",
            "\r42% [105 libsndfile1 128 kB/196 kB 65%]\r                                       \r42% [Working]\r             \rGet:106 http://deb.debian.org/debian bookworm/main amd64 libpulse0 amd64 16.1+dfsg1-2+b1 [274 kB]\r\n",
            "\r42% [106 libpulse0 63.4 kB/274 kB 23%]\r                                      \r42% [Waiting for headers]\r                         \rGet:107 http://deb.debian.org/debian bookworm/main amd64 libsphinxbase3 amd64 0.8+5prealpha+1-16 [118 kB]\r\n",
            "\r42% [107 libsphinxbase3 49.1 kB/118 kB 41%]\r                                           \r42% [Working]\r             \rGet:108 http://deb.debian.org/debian bookworm/main amd64 libpocketsphinx3 amd64 0.8+5prealpha+1-15 [125 kB]\r\n",
            "\r42% [108 libpocketsphinx3 60.7 kB/125 kB 48%]\r                                             \r42% [Working]\r             \rGet:109 http://deb.debian.org/debian bookworm/main amd64 libpostproc56 amd64 7:5.1.6-0+deb12u1 [95.9 kB]\r\n",
            "\r42% [109 libpostproc56 65.6 kB/95.9 kB 68%]\r                                           \r43% [Working]\r             \rGet:110 http://deb.debian.org/debian bookworm/main amd64 librubberband2 amd64 3.1.2+dfsg0-1 [137 kB]\r\n",
            "\r43% [110 librubberband2 34.4 kB/137 kB 25%]\r                                           \r43% [Waiting for headers]\r                         \rGet:111 http://deb.debian.org/debian bookworm/main amd64 libswscale6 amd64 7:5.1.6-0+deb12u1 [217 kB]\r\n",
            "\r43% [111 libswscale6 27.6 kB/217 kB 13%]\r                                        \r43% [Working]\r             \rGet:112 http://deb.debian.org/debian bookworm/main amd64 libvidstab1.1 amd64 1.1.0-2+b1 [37.8 kB]\r\n",
            "\r43% [112 libvidstab1.1 37.8 kB/37.8 kB 100%]\r                                            \r43% [Working]\r             \rGet:113 http://deb.debian.org/debian bookworm/main amd64 libzimg2 amd64 3.0.4+ds1-1 [227 kB]\r\n",
            "\r43% [113 libzimg2 98.8 kB/227 kB 44%]\r                                     \r43% [Waiting for headers]\r                         \rGet:114 http://deb.debian.org/debian bookworm/main amd64 libavfilter8 amd64 7:5.1.6-0+deb12u1 [3706 kB]\r\n",
            "\r43% [114 libavfilter8 2007 B/3706 kB 0%]\r                                        \r45% [Waiting for headers]\r                         \rGet:115 http://deb.debian.org/debian bookworm/main amd64 libslang2 amd64 2.3.3-3 [554 kB]\r\n",
            "\r45% [115 libslang2 96.7 kB/554 kB 17%]\r                                      \r46% [Waiting for headers]\r                         \rGet:116 http://deb.debian.org/debian bookworm/main amd64 libcaca0 amd64 0.99.beta20-3 [205 kB]\r\n",
            "\r46% [116 libcaca0 1984 B/205 kB 1%]\r                                   \r46% [Working]\r             \rGet:117 http://deb.debian.org/debian bookworm/main amd64 libcdio19 amd64 2.1.0-4 [203 kB]\r\n",
            "\r46% [117 libcdio19 56.7 kB/203 kB 28%]\r                                      \r46% [Waiting for headers]\r                         \rGet:118 http://deb.debian.org/debian bookworm/main amd64 libcdio-cdda2 amd64 10.2+2.0.1-1 [20.9 kB]\r\n",
            "\r                         \r46% [Working]\r             \rGet:119 http://deb.debian.org/debian bookworm/main amd64 libcdio-paranoia2 amd64 10.2+2.0.1-1 [20.4 kB]\r\n",
            "\r46% [119 libcdio-paranoia2 20.4 kB/20.4 kB 100%]\r                                                \r46% [Working]\r             \rGet:120 http://deb.debian.org/debian bookworm/main amd64 libusb-1.0-0 amd64 2:1.0.26-1 [62.6 kB]\r\n",
            "\r46% [120 libusb-1.0-0 62.6 kB/62.6 kB 100%]\r                                           \r46% [Working]\r             \rGet:121 http://deb.debian.org/debian bookworm/main amd64 libdc1394-25 amd64 2.2.6-4 [109 kB]\r\n",
            "\r46% [121 libdc1394-25 64.7 kB/109 kB 59%]\r                                         \r47% [Working]\r             \rGet:122 http://deb.debian.org/debian bookworm/main amd64 libglvnd0 amd64 1.6.0-1 [51.8 kB]\r\n",
            "\r47% [122 libglvnd0 30.6 kB/51.8 kB 59%]\r                                       \r47% [Working]\r             \rGet:123 http://deb.debian.org/debian bookworm/main amd64 libglapi-mesa amd64 22.3.6-1+deb12u1 [35.7 kB]\r\n",
            "\r47% [123 libglapi-mesa 32.9 kB/35.7 kB 92%]\r                                           \r47% [Working]\r             \rGet:124 http://deb.debian.org/debian bookworm/main amd64 libxcb-dri2-0 amd64 1.15-1 [107 kB]\r\n",
            "\r47% [124 libxcb-dri2-0 107 kB/107 kB 100%]\r                                          \r47% [Working]\r             \rGet:125 http://deb.debian.org/debian bookworm/main amd64 libxcb-glx0 amd64 1.15-1 [122 kB]\r\n",
            "\r47% [125 libxcb-glx0 30.3 kB/122 kB 25%]\r                                        \r47% [Waiting for headers]\r                         \rGet:126 http://deb.debian.org/debian bookworm/main amd64 libxcb-present0 amd64 1.15-1 [105 kB]\r\n",
            "\r47% [126 libxcb-present0 93.1 kB/105 kB 88%]\r                                            \r47% [Working]\r             \rGet:127 http://deb.debian.org/debian bookworm/main amd64 libxcb-randr0 amd64 1.15-1 [117 kB]\r\n",
            "\r47% [127 libxcb-randr0 63.0 kB/117 kB 54%]\r                                          \r47% [Working]\r             \rGet:128 http://deb.debian.org/debian bookworm/main amd64 libxcb-sync1 amd64 1.15-1 [109 kB]\r\n",
            "\r47% [128 libxcb-sync1 11.0 kB/109 kB 10%]\r                                         \r48% [Waiting for headers]\r                         \rGet:129 http://deb.debian.org/debian bookworm/main amd64 libxcb-xfixes0 amd64 1.15-1 [109 kB]\r\n",
            "\r48% [129 libxcb-xfixes0 21.9 kB/109 kB 20%]\r                                           \r48% [Waiting for headers]\r                         \rGet:130 http://deb.debian.org/debian bookworm/main amd64 libxshmfence1 amd64 1.3-1 [8820 B]\r\n",
            "\r48% [130 libxshmfence1 8820 B/8820 B 100%]\r                                          \r48% [Working]\r             \rGet:131 http://deb.debian.org/debian bookworm/main amd64 libxxf86vm1 amd64 1:1.1.4-1+b2 [20.8 kB]\r\n",
            "\r48% [Waiting for headers]\r                         \rGet:132 http://deb.debian.org/debian bookworm/main amd64 libdrm-amdgpu1 amd64 2.4.114-1+b1 [20.9 kB]\r\n",
            "\r                         \rGet:133 http://deb.debian.org/debian bookworm/main amd64 libpciaccess0 amd64 0.17-2 [51.4 kB]\r\n",
            "\r48% [133 libpciaccess0 51.4 kB/51.4 kB 100%]\r                                            \rGet:134 http://deb.debian.org/debian bookworm/main amd64 libdrm-intel1 amd64 2.4.114-1+b1 [64.0 kB]\r\n",
            "\r48% [134 libdrm-intel1 64.0 kB/64.0 kB 100%]\r                                            \r48% [Working]\r             \rGet:135 http://deb.debian.org/debian bookworm/main amd64 libdrm-nouveau2 amd64 2.4.114-1+b1 [19.1 kB]\r\n",
            "\r48% [135 libdrm-nouveau2 19.1 kB/19.1 kB 100%]\r                                              \r48% [Waiting for headers]\r                         \rGet:136 http://deb.debian.org/debian bookworm/main amd64 libdrm-radeon1 amd64 2.4.114-1+b1 [21.8 kB]\r\n",
            "\r49% [Waiting for headers]\r                         \rGet:137 http://deb.debian.org/debian bookworm/main amd64 libelf1 amd64 0.188-2.1 [174 kB]\r\n",
            "\r49% [137 libelf1 64.7 kB/174 kB 37%]\r                                    \r49% [Waiting for headers]\r                         \rGet:138 http://deb.debian.org/debian bookworm/main amd64 libz3-4 amd64 4.8.12-3.1 [7216 kB]\r\n",
            "\r49% [138 libz3-4 86.7 kB/7216 kB 1%]\r                                    \r53% [Working]\r             \rGet:139 http://deb.debian.org/debian bookworm/main amd64 libllvm15 amd64 1:15.0.6-4+b1 [23.1 MB]\r\n",
            "\r53% [139 libllvm15 51.1 kB/23.1 MB 0%]\r                                      \r64% [Waiting for headers]\r                         \rGet:140 http://deb.debian.org/debian bookworm/main amd64 libsensors-config all 1:3.6.0-7.1 [14.3 kB]\r\n",
            "\r                         \rGet:141 http://deb.debian.org/debian bookworm/main amd64 libsensors5 amd64 1:3.6.0-7.1 [34.2 kB]\r\n",
            "\r64% [141 libsensors5 34.2 kB/34.2 kB 100%]\r                                          \rGet:142 http://deb.debian.org/debian bookworm/main amd64 libgl1-mesa-dri amd64 22.3.6-1+deb12u1 [7239 kB]\r\n",
            "\r65% [142 libgl1-mesa-dri 130 kB/7239 kB 2%]\r                                           \r68% [Waiting for headers]\r                         \rGet:143 http://deb.debian.org/debian bookworm/main amd64 libglx-mesa0 amd64 22.3.6-1+deb12u1 [147 kB]\r\n",
            "\r68% [143 libglx-mesa0 34.0 kB/147 kB 23%]\r                                         \r68% [Working]\r             \rGet:144 http://deb.debian.org/debian bookworm/main amd64 libglx0 amd64 1.6.0-1 [34.4 kB]\r\n",
            "\r68% [144 libglx0 34.4 kB/34.4 kB 100%]\r                                      \r69% [Working]\r             \rGet:145 http://deb.debian.org/debian bookworm/main amd64 libgl1 amd64 1.6.0-1 [88.4 kB]\r\n",
            "\r69% [145 libgl1 47.2 kB/88.4 kB 53%]\r                                    \r69% [Working]\r             \rGet:146 http://deb.debian.org/debian bookworm/main amd64 libiec61883-0 amd64 1.2.0-6+b1 [30.5 kB]\r\n",
            "\r69% [146 libiec61883-0 23.4 kB/30.5 kB 77%]\r                                           \r69% [Working]\r             \rGet:147 http://deb.debian.org/debian bookworm/main amd64 libsamplerate0 amd64 0.2.2-3 [952 kB]\r\n",
            "\r69% [147 libsamplerate0 57.6 kB/952 kB 6%]\r                                          \r69% [Working]\r             \rGet:148 http://deb.debian.org/debian bookworm/main amd64 libjack-jackd2-0 amd64 1.9.21~dfsg-3 [281 kB]\r\n",
            "\r69% [148 libjack-jackd2-0 42.2 kB/281 kB 15%]\r                                             \r70% [Working]\r             \rGet:149 http://deb.debian.org/debian bookworm/main amd64 libopenal-data all 1:1.19.1-2 [170 kB]\r\n",
            "\r70% [149 libopenal-data 22.0 kB/170 kB 13%]\r                                           \r70% [Waiting for headers]\r                         \rGet:150 http://deb.debian.org/debian bookworm/main amd64 libsndio7.0 amd64 1.9.0-0.3+b2 [27.3 kB]\r\n",
            "\r                         \r70% [Working]\r             \rGet:151 http://deb.debian.org/debian bookworm/main amd64 libopenal1 amd64 1:1.19.1-2 [501 kB]\r\n",
            "\r70% [151 libopenal1 84.9 kB/501 kB 17%]\r                                       \r70% [Waiting for headers]\r                         \rGet:152 http://deb.debian.org/debian bookworm/main amd64 libwayland-client0 amd64 1.21.0-1 [28.3 kB]\r\n",
            "\r                         \r70% [Working]\r             \rGet:153 http://deb.debian.org/debian bookworm/main amd64 libdecor-0-0 amd64 0.1.1-2 [14.6 kB]\r\n",
            "\r             \rGet:154 http://deb.debian.org/debian bookworm/main amd64 libwayland-server0 amd64 1.21.0-1 [35.9 kB]\r\n",
            "\r71% [154 libwayland-server0 35.9 kB/35.9 kB 100%]\r                                                 \r71% [Waiting for headers]\r                         \rGet:155 http://deb.debian.org/debian bookworm/main amd64 libgbm1 amd64 22.3.6-1+deb12u1 [38.0 kB]\r\n",
            "\r71% [155 libgbm1 38.0 kB/38.0 kB 100%]\r                                      \r71% [Working]\r             \rGet:156 http://deb.debian.org/debian bookworm/main amd64 libwayland-cursor0 amd64 1.21.0-1 [14.4 kB]\r\n",
            "\r71% [156 libwayland-cursor0 14.4 kB/14.4 kB 100%]\r                                                 \r71% [Working]\r             \rGet:157 http://deb.debian.org/debian bookworm/main amd64 libwayland-egl1 amd64 1.21.0-1 [8640 B]\r\n",
            "\r71% [Working]\r             \rGet:158 http://deb.debian.org/debian bookworm/main amd64 libxcursor1 amd64 1:1.2.1-1 [40.9 kB]\r\n",
            "\r71% [Working]\r             \rGet:159 http://deb.debian.org/debian bookworm/main amd64 libxi6 amd64 2:1.8-1+b1 [84.2 kB]\r\n",
            "\r71% [159 libxi6 64.7 kB/84.2 kB 77%]\r                                    \r71% [Working]\r             \rGet:160 http://deb.debian.org/debian bookworm/main amd64 xkb-data all 2.35.1-1 [764 kB]\r\n",
            "\r71% [160 xkb-data 45.2 kB/764 kB 6%]\r                                    \r72% [Waiting for headers]\r                         \rGet:161 http://deb.debian.org/debian bookworm/main amd64 libxkbcommon0 amd64 1.5.0-1 [106 kB]\r\n",
            "\r72% [161 libxkbcommon0 1711 B/106 kB 2%]\r                                        \r72% [Waiting for headers]\r                         \rGet:162 http://deb.debian.org/debian bookworm/main amd64 libxrandr2 amd64 2:1.5.2-2+b1 [39.2 kB]\r\n",
            "\r72% [Waiting for headers]\r                         \rGet:163 http://deb.debian.org/debian bookworm/main amd64 x11-common all 1:7.7+23 [252 kB]\r\n",
            "\r72% [163 x11-common 51.3 kB/252 kB 20%]\r                                       \r72% [Waiting for headers]\r                         \rGet:164 http://deb.debian.org/debian bookworm/main amd64 libxss1 amd64 1:1.2.3-1 [17.8 kB]\r\n",
            "\r                         \r72% [Working]\r             \rGet:165 http://deb.debian.org/debian bookworm/main amd64 libsdl2-2.0-0 amd64 2.26.5+dfsg-1 [629 kB]\r\n",
            "\r72% [165 libsdl2-2.0-0 130 kB/629 kB 21%]\r                                         \r73% [Waiting for headers]\r                         \rGet:166 http://deb.debian.org/debian bookworm/main amd64 libxcb-shape0 amd64 1.15-1 [106 kB]\r\n",
            "\r73% [166 libxcb-shape0 53.9 kB/106 kB 51%]\r                                          \r73% [Working]\r             \rGet:167 http://deb.debian.org/debian bookworm/main amd64 libxv1 amd64 2:1.0.11-1.1 [24.8 kB]\r\n",
            "\r73% [167 libxv1 24.8 kB/24.8 kB 100%]\r                                     \r73% [Waiting for headers]\r                         \rGet:168 http://deb.debian.org/debian bookworm/main amd64 libavdevice59 amd64 7:5.1.6-0+deb12u1 [116 kB]\r\n",
            "\r73% [168 libavdevice59 52.7 kB/116 kB 45%]\r                                          \r73% [Waiting for headers]\r                         \rGet:169 http://deb.debian.org/debian bookworm/main amd64 ffmpeg amd64 7:5.1.6-0+deb12u1 [1816 kB]\r\n",
            "\r73% [169 ffmpeg 78.8 kB/1816 kB 4%]\r                                   \r74% [Waiting for headers]\r                         \rGet:170 http://deb.debian.org/debian bookworm/main amd64 i965-va-driver amd64 2.4.1+dfsg1-1 [309 kB]\r\n",
            "\r74% [170 i965-va-driver 30.9 kB/309 kB 10%]\r                                           \r74% [Waiting for headers]\r                         \rGet:171 http://deb.debian.org/debian bookworm/main amd64 libigdgmm12 amd64 22.3.3+ds1-1 [139 kB]\r\n",
            "\r75% [171 libigdgmm12 103 kB/139 kB 74%]\r                                       \r75% [Working]\r             \rGet:172 http://deb.debian.org/debian bookworm/main amd64 intel-media-va-driver amd64 23.1.1+dfsg1-1 [2882 kB]\r\n",
            "\r75% [172 intel-media-va-driver 27.8 kB/2882 kB 1%]\r                                                  \rGet:173 http://deb.debian.org/debian bookworm/main amd64 libaacs0 amd64 0.11.1-2 [57.1 kB]\r\n",
            "\r                                                  \rGet:174 http://deb.debian.org/debian bookworm/main amd64 libbdplus0 amd64 0.2.0-3 [52.6 kB]\r\n",
            "\r                                                  \r76% [Waiting for headers]\r                         \rGet:175 http://deb.debian.org/debian bookworm/main amd64 libdecor-0-plugin-1-cairo amd64 0.1.1-2 [20.1 kB]\r\n",
            "\r                         \rGet:176 http://deb.debian.org/debian-security bookworm-security/main amd64 libgdk-pixbuf2.0-bin amd64 2.42.10+dfsg-1+deb12u2 [17.8 kB]\r\n",
            "\r                         \rGet:177 http://deb.debian.org/debian bookworm/main amd64 libglib2.0-data all 2.74.6-2+deb12u6 [1210 kB]\r\n",
            "\r77% [177 libglib2.0-data 196 kB/1210 kB 16%]\r                                            \r77% [Waiting for headers]\r                         \rGet:178 http://deb.debian.org/debian bookworm/main amd64 libice6 amd64 2:1.0.10-1 [58.5 kB]\r\n",
            "\r77% [178 libice6 58.5 kB/58.5 kB 100%]\r                                      \r77% [Working]\r             \rGet:179 http://deb.debian.org/debian bookworm/main amd64 libpthread-stubs0-dev amd64 0.4-1 [5344 B]\r\n",
            "\r78% [Waiting for headers]\r                         \rGet:180 http://deb.debian.org/debian bookworm/main amd64 librsvg2-common amd64 2.54.7+dfsg-1~deb12u1 [21.4 kB]\r\n",
            "\r                         \rGet:181 http://deb.debian.org/debian bookworm/main amd64 libsm6 amd64 2:1.2.3-1 [35.1 kB]\r\n",
            "\r78% [181 libsm6 35.1 kB/35.1 kB 100%]\r                                     \r78% [Working]\r             \rGet:182 http://deb.debian.org/debian bookworm/main amd64 libvdpau-va-gl1 amd64 0.4.2-1+b1 [71.3 kB]\r\n",
            "\r78% [182 libvdpau-va-gl1 50.5 kB/71.3 kB 71%]\r                                             \r78% [Working]\r             \rGet:183 http://deb.debian.org/debian bookworm/main amd64 xorg-sgml-doctools all 1:1.11-1.1 [22.1 kB]\r\n",
            "\r78% [Working]\r             \rGet:184 http://deb.debian.org/debian bookworm/main amd64 x11proto-dev all 2022.1-1 [599 kB]\r\n",
            "\r78% [184 x11proto-dev 64.7 kB/599 kB 11%]\r                                         \r78% [Waiting for headers]\r                         \rGet:185 http://deb.debian.org/debian bookworm/main amd64 libxau-dev amd64 1:1.0.9-1 [22.9 kB]\r\n",
            "\r                         \rGet:186 http://deb.debian.org/debian bookworm/main amd64 libxdmcp-dev amd64 1:1.1.2-3 [42.2 kB]\r\n",
            "\r79% [186 libxdmcp-dev 42.2 kB/42.2 kB 100%]\r                                           \r79% [Waiting for headers]\r                         \rGet:187 http://deb.debian.org/debian bookworm/main amd64 xtrans-dev all 1.4.0-1 [98.7 kB]\r\n",
            "\r79% [187 xtrans-dev 64.7 kB/98.7 kB 65%]\r                                        \r79% [Working]\r             \rGet:188 http://deb.debian.org/debian bookworm/main amd64 libxcb1-dev amd64 1.15-1 [181 kB]\r\n",
            "\r79% [188 libxcb1-dev 30.6 kB/181 kB 17%]\r                                        \r79% [Waiting for headers]\r                         \rGet:189 http://deb.debian.org/debian bookworm/main amd64 libx11-dev amd64 2:1.8.4-2+deb12u2 [837 kB]\r\n",
            "\r79% [189 libx11-dev 45.6 kB/837 kB 5%]\r                                      \r80% [Waiting for headers]\r                         \rGet:190 http://deb.debian.org/debian bookworm/main amd64 libxrender-dev amd64 1:0.9.10-1.1 [41.1 kB]\r\n",
            "\r                         \r80% [Working]\r             \rGet:191 http://deb.debian.org/debian bookworm/main amd64 mesa-va-drivers amd64 22.3.6-1+deb12u1 [3299 kB]\r\n",
            "\r80% [191 mesa-va-drivers 64.7 kB/3299 kB 2%]\r                                            \r81% [Working]\r             \rGet:192 http://deb.debian.org/debian bookworm/main amd64 mesa-vdpau-drivers amd64 22.3.6-1+deb12u1 [3181 kB]\r\n",
            "\r81% [192 mesa-vdpau-drivers 42.0 kB/3181 kB 1%]\r                                               \r83% [Waiting for headers]\r                         \rGet:193 http://deb.debian.org/debian bookworm/main amd64 mesa-vulkan-drivers amd64 22.3.6-1+deb12u1 [8000 kB]\r\n",
            "\r83% [193 mesa-vulkan-drivers 35.2 kB/8000 kB 0%]\r                                                \r87% [Working]\r             \rGet:194 http://deb.debian.org/debian bookworm/main amd64 pocketsphinx-en-us all 0.8+5prealpha+1-15 [24.3 MB]\r\n",
            "\r87% [194 pocketsphinx-en-us 66.1 kB/24.3 MB 0%]\r                                               \r100% [Waiting for headers]\r                          \rGet:195 http://deb.debian.org/debian bookworm/main amd64 va-driver-all amd64 2.17.0-1 [12.8 kB]\r\n",
            "\r100% [Waiting for headers]\r                          \rGet:196 http://deb.debian.org/debian bookworm/main amd64 vdpau-driver-all amd64 1.5-2 [4348 B]\r\n",
            "\r                          \rGet:197 http://deb.debian.org/debian bookworm/main amd64 xdg-user-dirs amd64 0.18-1 [54.4 kB]\r\n",
            "\r100% [197 xdg-user-dirs 54.4 kB/54.4 kB 100%]\r                                             \r100% [Working]\r              \rFetched 159 MB in 1s (145 MB/s)\r\n",
            "debconf: delaying package configuration, since apt-utils is not installed\r\n",
            "Selecting previously unselected package libpython3.11-minimal:amd64.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 29739 files and directories currently installed.)\r\n",
            "Preparing to unpack .../libpython3.11-minimal_3.11.2-6+deb12u6_amd64.deb ...\r\n",
            "Unpacking libpython3.11-minimal:amd64 (3.11.2-6+deb12u6) ...\r\n",
            "Selecting previously unselected package python3.11-minimal.\r\n",
            "Preparing to unpack .../python3.11-minimal_3.11.2-6+deb12u6_amd64.deb ...\r\n",
            "Unpacking python3.11-minimal (3.11.2-6+deb12u6) ...\r\n",
            "Setting up libpython3.11-minimal:amd64 (3.11.2-6+deb12u6) ...\r\n",
            "Setting up python3.11-minimal (3.11.2-6+deb12u6) ...\r\n",
            "Selecting previously unselected package python3-minimal.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 30045 files and directories currently installed.)\r\n",
            "Preparing to unpack .../python3-minimal_3.11.2-1+b1_amd64.deb ...\r\n",
            "Unpacking python3-minimal (3.11.2-1+b1) ...\r\n",
            "Selecting previously unselected package media-types.\r\n",
            "Preparing to unpack .../media-types_10.0.0_all.deb ...\r\n",
            "Unpacking media-types (10.0.0) ...\r\n",
            "Selecting previously unselected package libpython3.11-stdlib:amd64.\r\n",
            "Preparing to unpack .../libpython3.11-stdlib_3.11.2-6+deb12u6_amd64.deb ...\r\n",
            "Unpacking libpython3.11-stdlib:amd64 (3.11.2-6+deb12u6) ...\r\n",
            "Selecting previously unselected package python3.11.\r\n",
            "Preparing to unpack .../python3.11_3.11.2-6+deb12u6_amd64.deb ...\r\n",
            "Unpacking python3.11 (3.11.2-6+deb12u6) ...\r\n",
            "Selecting previously unselected package libpython3-stdlib:amd64.\r\n",
            "Preparing to unpack .../libpython3-stdlib_3.11.2-1+b1_amd64.deb ...\r\n",
            "Unpacking libpython3-stdlib:amd64 (3.11.2-1+b1) ...\r\n",
            "Setting up python3-minimal (3.11.2-1+b1) ...\r\n",
            "Selecting previously unselected package python3.\r\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 30454 files and directories currently installed.)\r\n",
            "Preparing to unpack .../000-python3_3.11.2-1+b1_amd64.deb ...\r\n",
            "Unpacking python3 (3.11.2-1+b1) ...\r\n",
            "Selecting previously unselected package alsa-topology-conf.\r\n",
            "Preparing to unpack .../001-alsa-topology-conf_1.2.5.1-2_all.deb ...\r\n",
            "Unpacking alsa-topology-conf (1.2.5.1-2) ...\r\n",
            "Selecting previously unselected package libasound2-data.\r\n",
            "Preparing to unpack .../002-libasound2-data_1.2.8-1_all.deb ...\r\n",
            "Unpacking libasound2-data (1.2.8-1) ...\r\n",
            "Selecting previously unselected package libasound2:amd64.\r\n",
            "Preparing to unpack .../003-libasound2_1.2.8-1+b1_amd64.deb ...\r\n",
            "Unpacking libasound2:amd64 (1.2.8-1+b1) ...\r\n",
            "Selecting previously unselected package alsa-ucm-conf.\r\n",
            "Preparing to unpack .../004-alsa-ucm-conf_1.2.8-1_all.deb ...\r\n",
            "Unpacking alsa-ucm-conf (1.2.8-1) ...\r\n",
            "Selecting previously unselected package libdrm-common.\r\n",
            "Preparing to unpack .../005-libdrm-common_2.4.114-1_all.deb ...\r\n",
            "Unpacking libdrm-common (2.4.114-1) ...\r\n",
            "Selecting previously unselected package libdrm2:amd64.\r\n",
            "Preparing to unpack .../006-libdrm2_2.4.114-1+b1_amd64.deb ...\r\n",
            "Unpacking libdrm2:amd64 (2.4.114-1+b1) ...\r\n",
            "Selecting previously unselected package libva2:amd64.\r\n",
            "Preparing to unpack .../007-libva2_2.17.0-1_amd64.deb ...\r\n",
            "Unpacking libva2:amd64 (2.17.0-1) ...\r\n",
            "Selecting previously unselected package libmfx1:amd64.\r\n",
            "Preparing to unpack .../008-libmfx1_22.5.4-1_amd64.deb ...\r\n",
            "Unpacking libmfx1:amd64 (22.5.4-1) ...\r\n",
            "Selecting previously unselected package libva-drm2:amd64.\r\n",
            "Preparing to unpack .../009-libva-drm2_2.17.0-1_amd64.deb ...\r\n",
            "Unpacking libva-drm2:amd64 (2.17.0-1) ...\r\n",
            "Selecting previously unselected package libx11-xcb1:amd64.\r\n",
            "Preparing to unpack .../010-libx11-xcb1_2%3a1.8.4-2+deb12u2_amd64.deb ...\r\n",
            "Unpacking libx11-xcb1:amd64 (2:1.8.4-2+deb12u2) ...\r\n",
            "Selecting previously unselected package libxcb-dri3-0:amd64.\r\n",
            "Preparing to unpack .../011-libxcb-dri3-0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-dri3-0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxfixes3:amd64.\r\n",
            "Preparing to unpack .../012-libxfixes3_1%3a6.0.0-2_amd64.deb ...\r\n",
            "Unpacking libxfixes3:amd64 (1:6.0.0-2) ...\r\n",
            "Selecting previously unselected package libva-x11-2:amd64.\r\n",
            "Preparing to unpack .../013-libva-x11-2_2.17.0-1_amd64.deb ...\r\n",
            "Unpacking libva-x11-2:amd64 (2.17.0-1) ...\r\n",
            "Selecting previously unselected package libvdpau1:amd64.\r\n",
            "Preparing to unpack .../014-libvdpau1_1.5-2_amd64.deb ...\r\n",
            "Unpacking libvdpau1:amd64 (1.5-2) ...\r\n",
            "Selecting previously unselected package ocl-icd-libopencl1:amd64.\r\n",
            "Preparing to unpack .../015-ocl-icd-libopencl1_2.3.1-1_amd64.deb ...\r\n",
            "Unpacking ocl-icd-libopencl1:amd64 (2.3.1-1) ...\r\n",
            "Selecting previously unselected package libavutil57:amd64.\r\n",
            "Preparing to unpack .../016-libavutil57_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libavutil57:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libpixman-1-0:amd64.\r\n",
            "Preparing to unpack .../017-libpixman-1-0_0.42.2-1_amd64.deb ...\r\n",
            "Unpacking libpixman-1-0:amd64 (0.42.2-1) ...\r\n",
            "Selecting previously unselected package libxcb-render0:amd64.\r\n",
            "Preparing to unpack .../018-libxcb-render0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-render0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-shm0:amd64.\r\n",
            "Preparing to unpack .../019-libxcb-shm0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-shm0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxrender1:amd64.\r\n",
            "Preparing to unpack .../020-libxrender1_1%3a0.9.10-1.1_amd64.deb ...\r\n",
            "Unpacking libxrender1:amd64 (1:0.9.10-1.1) ...\r\n",
            "Selecting previously unselected package libcairo2:amd64.\r\n",
            "Preparing to unpack .../021-libcairo2_1.16.0-7_amd64.deb ...\r\n",
            "Unpacking libcairo2:amd64 (1.16.0-7) ...\r\n",
            "Selecting previously unselected package libcodec2-1.0:amd64.\r\n",
            "Preparing to unpack .../022-libcodec2-1.0_1.0.5-1_amd64.deb ...\r\n",
            "Unpacking libcodec2-1.0:amd64 (1.0.5-1) ...\r\n",
            "Selecting previously unselected package libglib2.0-0:amd64.\r\n",
            "Preparing to unpack .../023-libglib2.0-0_2.74.6-2+deb12u6_amd64.deb ...\r\n",
            "Unpacking libglib2.0-0:amd64 (2.74.6-2+deb12u6) ...\r\n",
            "Selecting previously unselected package libgsm1:amd64.\r\n",
            "Preparing to unpack .../024-libgsm1_1.0.22-1_amd64.deb ...\r\n",
            "Unpacking libgsm1:amd64 (1.0.22-1) ...\r\n",
            "Selecting previously unselected package libhwy1:amd64.\r\n",
            "Preparing to unpack .../025-libhwy1_1.0.3-3+deb12u1_amd64.deb ...\r\n",
            "Unpacking libhwy1:amd64 (1.0.3-3+deb12u1) ...\r\n",
            "Selecting previously unselected package liblcms2-2:amd64.\r\n",
            "Preparing to unpack .../026-liblcms2-2_2.14-2_amd64.deb ...\r\n",
            "Unpacking liblcms2-2:amd64 (2.14-2) ...\r\n",
            "Selecting previously unselected package libjxl0.7:amd64.\r\n",
            "Preparing to unpack .../027-libjxl0.7_0.7.0-10+deb12u1_amd64.deb ...\r\n",
            "Unpacking libjxl0.7:amd64 (0.7.0-10+deb12u1) ...\r\n",
            "Selecting previously unselected package libmp3lame0:amd64.\r\n",
            "Preparing to unpack .../028-libmp3lame0_3.100-6_amd64.deb ...\r\n",
            "Unpacking libmp3lame0:amd64 (3.100-6) ...\r\n",
            "Selecting previously unselected package libopenjp2-7:amd64.\r\n",
            "Preparing to unpack .../029-libopenjp2-7_2.5.0-2+deb12u1_amd64.deb ...\r\n",
            "Unpacking libopenjp2-7:amd64 (2.5.0-2+deb12u1) ...\r\n",
            "Selecting previously unselected package libopus0:amd64.\r\n",
            "Preparing to unpack .../030-libopus0_1.3.1-3_amd64.deb ...\r\n",
            "Unpacking libopus0:amd64 (1.3.1-3) ...\r\n",
            "Selecting previously unselected package libcairo-gobject2:amd64.\r\n",
            "Preparing to unpack .../031-libcairo-gobject2_1.16.0-7_amd64.deb ...\r\n",
            "Unpacking libcairo-gobject2:amd64 (1.16.0-7) ...\r\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-common.\r\n",
            "Preparing to unpack .../032-libgdk-pixbuf2.0-common_2.42.10+dfsg-1+deb12u2_all.deb ...\r\n",
            "Unpacking libgdk-pixbuf2.0-common (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Selecting previously unselected package shared-mime-info.\r\n",
            "Preparing to unpack .../033-shared-mime-info_2.2-1_amd64.deb ...\r\n",
            "Unpacking shared-mime-info (2.2-1) ...\r\n",
            "Selecting previously unselected package libgdk-pixbuf-2.0-0:amd64.\r\n",
            "Preparing to unpack .../034-libgdk-pixbuf-2.0-0_2.42.10+dfsg-1+deb12u2_amd64.deb ...\r\n",
            "Unpacking libgdk-pixbuf-2.0-0:amd64 (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Selecting previously unselected package fontconfig.\r\n",
            "Preparing to unpack .../035-fontconfig_2.14.1-4_amd64.deb ...\r\n",
            "Unpacking fontconfig (2.14.1-4) ...\r\n",
            "Selecting previously unselected package libfribidi0:amd64.\r\n",
            "Preparing to unpack .../036-libfribidi0_1.0.8-2.1_amd64.deb ...\r\n",
            "Unpacking libfribidi0:amd64 (1.0.8-2.1) ...\r\n",
            "Selecting previously unselected package libgraphite2-3:amd64.\r\n",
            "Preparing to unpack .../037-libgraphite2-3_1.3.14-1_amd64.deb ...\r\n",
            "Unpacking libgraphite2-3:amd64 (1.3.14-1) ...\r\n",
            "Selecting previously unselected package libharfbuzz0b:amd64.\r\n",
            "Preparing to unpack .../038-libharfbuzz0b_6.0.0+dfsg-3_amd64.deb ...\r\n",
            "Unpacking libharfbuzz0b:amd64 (6.0.0+dfsg-3) ...\r\n",
            "Selecting previously unselected package libthai-data.\r\n",
            "Preparing to unpack .../039-libthai-data_0.1.29-1_all.deb ...\r\n",
            "Unpacking libthai-data (0.1.29-1) ...\r\n",
            "Selecting previously unselected package libdatrie1:amd64.\r\n",
            "Preparing to unpack .../040-libdatrie1_0.2.13-2+b1_amd64.deb ...\r\n",
            "Unpacking libdatrie1:amd64 (0.2.13-2+b1) ...\r\n",
            "Selecting previously unselected package libthai0:amd64.\r\n",
            "Preparing to unpack .../041-libthai0_0.1.29-1_amd64.deb ...\r\n",
            "Unpacking libthai0:amd64 (0.1.29-1) ...\r\n",
            "Selecting previously unselected package libpango-1.0-0:amd64.\r\n",
            "Preparing to unpack .../042-libpango-1.0-0_1.50.12+ds-1_amd64.deb ...\r\n",
            "Unpacking libpango-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Selecting previously unselected package libpangoft2-1.0-0:amd64.\r\n",
            "Preparing to unpack .../043-libpangoft2-1.0-0_1.50.12+ds-1_amd64.deb ...\r\n",
            "Unpacking libpangoft2-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Selecting previously unselected package libpangocairo-1.0-0:amd64.\r\n",
            "Preparing to unpack .../044-libpangocairo-1.0-0_1.50.12+ds-1_amd64.deb ...\r\n",
            "Unpacking libpangocairo-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Selecting previously unselected package librsvg2-2:amd64.\r\n",
            "Preparing to unpack .../045-librsvg2-2_2.54.7+dfsg-1~deb12u1_amd64.deb ...\r\n",
            "Unpacking librsvg2-2:amd64 (2.54.7+dfsg-1~deb12u1) ...\r\n",
            "Selecting previously unselected package libshine3:amd64.\r\n",
            "Preparing to unpack .../046-libshine3_3.1.1-2_amd64.deb ...\r\n",
            "Unpacking libshine3:amd64 (3.1.1-2) ...\r\n",
            "Selecting previously unselected package libsnappy1v5:amd64.\r\n",
            "Preparing to unpack .../047-libsnappy1v5_1.1.9-3_amd64.deb ...\r\n",
            "Unpacking libsnappy1v5:amd64 (1.1.9-3) ...\r\n",
            "Selecting previously unselected package libspeex1:amd64.\r\n",
            "Preparing to unpack .../048-libspeex1_1.2.1-2_amd64.deb ...\r\n",
            "Unpacking libspeex1:amd64 (1.2.1-2) ...\r\n",
            "Selecting previously unselected package libsoxr0:amd64.\r\n",
            "Preparing to unpack .../049-libsoxr0_0.1.3-4_amd64.deb ...\r\n",
            "Unpacking libsoxr0:amd64 (0.1.3-4) ...\r\n",
            "Selecting previously unselected package libswresample4:amd64.\r\n",
            "Preparing to unpack .../050-libswresample4_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libswresample4:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libogg0:amd64.\r\n",
            "Preparing to unpack .../051-libogg0_1.3.5-3_amd64.deb ...\r\n",
            "Unpacking libogg0:amd64 (1.3.5-3) ...\r\n",
            "Selecting previously unselected package libtheora0:amd64.\r\n",
            "Preparing to unpack .../052-libtheora0_1.1.1+dfsg.1-16.1+b1_amd64.deb ...\r\n",
            "Unpacking libtheora0:amd64 (1.1.1+dfsg.1-16.1+b1) ...\r\n",
            "Selecting previously unselected package libtwolame0:amd64.\r\n",
            "Preparing to unpack .../053-libtwolame0_0.4.0-2_amd64.deb ...\r\n",
            "Unpacking libtwolame0:amd64 (0.4.0-2) ...\r\n",
            "Selecting previously unselected package libvorbis0a:amd64.\r\n",
            "Preparing to unpack .../054-libvorbis0a_1.3.7-1_amd64.deb ...\r\n",
            "Unpacking libvorbis0a:amd64 (1.3.7-1) ...\r\n",
            "Selecting previously unselected package libvorbisenc2:amd64.\r\n",
            "Preparing to unpack .../055-libvorbisenc2_1.3.7-1_amd64.deb ...\r\n",
            "Unpacking libvorbisenc2:amd64 (1.3.7-1) ...\r\n",
            "Selecting previously unselected package libvpx7:amd64.\r\n",
            "Preparing to unpack .../056-libvpx7_1.12.0-1+deb12u4_amd64.deb ...\r\n",
            "Unpacking libvpx7:amd64 (1.12.0-1+deb12u4) ...\r\n",
            "Selecting previously unselected package libwebpmux3:amd64.\r\n",
            "Preparing to unpack .../057-libwebpmux3_1.2.4-0.2+deb12u1_amd64.deb ...\r\n",
            "Unpacking libwebpmux3:amd64 (1.2.4-0.2+deb12u1) ...\r\n",
            "Selecting previously unselected package libx264-164:amd64.\r\n",
            "Preparing to unpack .../058-libx264-164_2%3a0.164.3095+gitbaee400-3_amd64.deb ...\r\n",
            "Unpacking libx264-164:amd64 (2:0.164.3095+gitbaee400-3) ...\r\n",
            "Selecting previously unselected package libxvidcore4:amd64.\r\n",
            "Preparing to unpack .../059-libxvidcore4_2%3a1.3.7-1_amd64.deb ...\r\n",
            "Unpacking libxvidcore4:amd64 (2:1.3.7-1) ...\r\n",
            "Selecting previously unselected package libzvbi-common.\r\n",
            "Preparing to unpack .../060-libzvbi-common_0.2.41-1_all.deb ...\r\n",
            "Unpacking libzvbi-common (0.2.41-1) ...\r\n",
            "Selecting previously unselected package libzvbi0:amd64.\r\n",
            "Preparing to unpack .../061-libzvbi0_0.2.41-1_amd64.deb ...\r\n",
            "Unpacking libzvbi0:amd64 (0.2.41-1) ...\r\n",
            "Selecting previously unselected package libavcodec59:amd64.\r\n",
            "Preparing to unpack .../062-libavcodec59_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libavcodec59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libraw1394-11:amd64.\r\n",
            "Preparing to unpack .../063-libraw1394-11_2.1.2-2_amd64.deb ...\r\n",
            "Unpacking libraw1394-11:amd64 (2.1.2-2) ...\r\n",
            "Selecting previously unselected package libavc1394-0:amd64.\r\n",
            "Preparing to unpack .../064-libavc1394-0_0.5.4-5_amd64.deb ...\r\n",
            "Unpacking libavc1394-0:amd64 (0.5.4-5) ...\r\n",
            "Selecting previously unselected package libass9:amd64.\r\n",
            "Preparing to unpack .../065-libass9_1%3a0.17.1-1_amd64.deb ...\r\n",
            "Unpacking libass9:amd64 (1:0.17.1-1) ...\r\n",
            "Selecting previously unselected package libudfread0:amd64.\r\n",
            "Preparing to unpack .../066-libudfread0_1.1.2-1_amd64.deb ...\r\n",
            "Unpacking libudfread0:amd64 (1.1.2-1) ...\r\n",
            "Selecting previously unselected package libbluray2:amd64.\r\n",
            "Preparing to unpack .../067-libbluray2_1%3a1.3.4-1_amd64.deb ...\r\n",
            "Unpacking libbluray2:amd64 (1:1.3.4-1) ...\r\n",
            "Selecting previously unselected package libchromaprint1:amd64.\r\n",
            "Preparing to unpack .../068-libchromaprint1_1.5.1-2+b1_amd64.deb ...\r\n",
            "Unpacking libchromaprint1:amd64 (1.5.1-2+b1) ...\r\n",
            "Selecting previously unselected package libgme0:amd64.\r\n",
            "Preparing to unpack .../069-libgme0_0.6.3-6_amd64.deb ...\r\n",
            "Unpacking libgme0:amd64 (0.6.3-6) ...\r\n",
            "Selecting previously unselected package libmpg123-0:amd64.\r\n",
            "Preparing to unpack .../070-libmpg123-0_1.31.2-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libmpg123-0:amd64 (1.31.2-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libvorbisfile3:amd64.\r\n",
            "Preparing to unpack .../071-libvorbisfile3_1.3.7-1_amd64.deb ...\r\n",
            "Unpacking libvorbisfile3:amd64 (1.3.7-1) ...\r\n",
            "Selecting previously unselected package libopenmpt0:amd64.\r\n",
            "Preparing to unpack .../072-libopenmpt0_0.6.9-1_amd64.deb ...\r\n",
            "Unpacking libopenmpt0:amd64 (0.6.9-1) ...\r\n",
            "Selecting previously unselected package librabbitmq4:amd64.\r\n",
            "Preparing to unpack .../073-librabbitmq4_0.11.0-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking librabbitmq4:amd64 (0.11.0-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libcjson1:amd64.\r\n",
            "Preparing to unpack .../074-libcjson1_1.7.15-1+deb12u2_amd64.deb ...\r\n",
            "Unpacking libcjson1:amd64 (1.7.15-1+deb12u2) ...\r\n",
            "Selecting previously unselected package libmbedcrypto7:amd64.\r\n",
            "Preparing to unpack .../075-libmbedcrypto7_2.28.3-1_amd64.deb ...\r\n",
            "Unpacking libmbedcrypto7:amd64 (2.28.3-1) ...\r\n",
            "Selecting previously unselected package librist4:amd64.\r\n",
            "Preparing to unpack .../076-librist4_0.2.7+dfsg-1_amd64.deb ...\r\n",
            "Unpacking librist4:amd64 (0.2.7+dfsg-1) ...\r\n",
            "Selecting previously unselected package libsrt1.5-gnutls:amd64.\r\n",
            "Preparing to unpack .../077-libsrt1.5-gnutls_1.5.1-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libsrt1.5-gnutls:amd64 (1.5.1-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libssh-gcrypt-4:amd64.\r\n",
            "Preparing to unpack .../078-libssh-gcrypt-4_0.10.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libssh-gcrypt-4:amd64 (0.10.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libnorm1:amd64.\r\n",
            "Preparing to unpack .../079-libnorm1_1.5.9+dfsg-2_amd64.deb ...\r\n",
            "Unpacking libnorm1:amd64 (1.5.9+dfsg-2) ...\r\n",
            "Selecting previously unselected package libpgm-5.3-0:amd64.\r\n",
            "Preparing to unpack .../080-libpgm-5.3-0_5.3.128~dfsg-2_amd64.deb ...\r\n",
            "Unpacking libpgm-5.3-0:amd64 (5.3.128~dfsg-2) ...\r\n",
            "Selecting previously unselected package libzmq5:amd64.\r\n",
            "Preparing to unpack .../081-libzmq5_4.3.4-6_amd64.deb ...\r\n",
            "Unpacking libzmq5:amd64 (4.3.4-6) ...\r\n",
            "Selecting previously unselected package libavformat59:amd64.\r\n",
            "Preparing to unpack .../082-libavformat59_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libavformat59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libbs2b0:amd64.\r\n",
            "Preparing to unpack .../083-libbs2b0_3.1.0+dfsg-7_amd64.deb ...\r\n",
            "Unpacking libbs2b0:amd64 (3.1.0+dfsg-7) ...\r\n",
            "Selecting previously unselected package libflite1:amd64.\r\n",
            "Preparing to unpack .../084-libflite1_2.2-5_amd64.deb ...\r\n",
            "Unpacking libflite1:amd64 (2.2-5) ...\r\n",
            "Selecting previously unselected package libserd-0-0:amd64.\r\n",
            "Preparing to unpack .../085-libserd-0-0_0.30.16-1_amd64.deb ...\r\n",
            "Unpacking libserd-0-0:amd64 (0.30.16-1) ...\r\n",
            "Selecting previously unselected package libsord-0-0:amd64.\r\n",
            "Preparing to unpack .../086-libsord-0-0_0.16.14+git221008-1_amd64.deb ...\r\n",
            "Unpacking libsord-0-0:amd64 (0.16.14+git221008-1) ...\r\n",
            "Selecting previously unselected package libsratom-0-0:amd64.\r\n",
            "Preparing to unpack .../087-libsratom-0-0_0.6.14-1_amd64.deb ...\r\n",
            "Unpacking libsratom-0-0:amd64 (0.6.14-1) ...\r\n",
            "Selecting previously unselected package liblilv-0-0:amd64.\r\n",
            "Preparing to unpack .../088-liblilv-0-0_0.24.14-1_amd64.deb ...\r\n",
            "Unpacking liblilv-0-0:amd64 (0.24.14-1) ...\r\n",
            "Selecting previously unselected package libmysofa1:amd64.\r\n",
            "Preparing to unpack .../089-libmysofa1_1.3.1~dfsg0-1_amd64.deb ...\r\n",
            "Unpacking libmysofa1:amd64 (1.3.1~dfsg0-1) ...\r\n",
            "Selecting previously unselected package libepoxy0:amd64.\r\n",
            "Preparing to unpack .../090-libepoxy0_1.5.10-1_amd64.deb ...\r\n",
            "Unpacking libepoxy0:amd64 (1.5.10-1) ...\r\n",
            "Selecting previously unselected package libvulkan1:amd64.\r\n",
            "Preparing to unpack .../091-libvulkan1_1.3.239.0-1_amd64.deb ...\r\n",
            "Unpacking libvulkan1:amd64 (1.3.239.0-1) ...\r\n",
            "Selecting previously unselected package libplacebo208:amd64.\r\n",
            "Preparing to unpack .../092-libplacebo208_4.208.0-3_amd64.deb ...\r\n",
            "Unpacking libplacebo208:amd64 (4.208.0-3) ...\r\n",
            "Selecting previously unselected package libblas3:amd64.\r\n",
            "Preparing to unpack .../093-libblas3_3.11.0-2_amd64.deb ...\r\n",
            "Unpacking libblas3:amd64 (3.11.0-2) ...\r\n",
            "Selecting previously unselected package liblapack3:amd64.\r\n",
            "Preparing to unpack .../094-liblapack3_3.11.0-2_amd64.deb ...\r\n",
            "Unpacking liblapack3:amd64 (3.11.0-2) ...\r\n",
            "Selecting previously unselected package libasyncns0:amd64.\r\n",
            "Preparing to unpack .../095-libasyncns0_0.8-6+b3_amd64.deb ...\r\n",
            "Unpacking libasyncns0:amd64 (0.8-6+b3) ...\r\n",
            "Selecting previously unselected package libflac12:amd64.\r\n",
            "Preparing to unpack .../096-libflac12_1.4.2+ds-2_amd64.deb ...\r\n",
            "Unpacking libflac12:amd64 (1.4.2+ds-2) ...\r\n",
            "Selecting previously unselected package libsndfile1:amd64.\r\n",
            "Preparing to unpack .../097-libsndfile1_1.2.0-1_amd64.deb ...\r\n",
            "Unpacking libsndfile1:amd64 (1.2.0-1) ...\r\n",
            "Selecting previously unselected package libpulse0:amd64.\r\n",
            "Preparing to unpack .../098-libpulse0_16.1+dfsg1-2+b1_amd64.deb ...\r\n",
            "Unpacking libpulse0:amd64 (16.1+dfsg1-2+b1) ...\r\n",
            "Selecting previously unselected package libsphinxbase3:amd64.\r\n",
            "Preparing to unpack .../099-libsphinxbase3_0.8+5prealpha+1-16_amd64.deb ...\r\n",
            "Unpacking libsphinxbase3:amd64 (0.8+5prealpha+1-16) ...\r\n",
            "Selecting previously unselected package libpocketsphinx3:amd64.\r\n",
            "Preparing to unpack .../100-libpocketsphinx3_0.8+5prealpha+1-15_amd64.deb ...\r\n",
            "Unpacking libpocketsphinx3:amd64 (0.8+5prealpha+1-15) ...\r\n",
            "Selecting previously unselected package libpostproc56:amd64.\r\n",
            "Preparing to unpack .../101-libpostproc56_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libpostproc56:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package librubberband2:amd64.\r\n",
            "Preparing to unpack .../102-librubberband2_3.1.2+dfsg0-1_amd64.deb ...\r\n",
            "Unpacking librubberband2:amd64 (3.1.2+dfsg0-1) ...\r\n",
            "Selecting previously unselected package libswscale6:amd64.\r\n",
            "Preparing to unpack .../103-libswscale6_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libswscale6:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libvidstab1.1:amd64.\r\n",
            "Preparing to unpack .../104-libvidstab1.1_1.1.0-2+b1_amd64.deb ...\r\n",
            "Unpacking libvidstab1.1:amd64 (1.1.0-2+b1) ...\r\n",
            "Selecting previously unselected package libzimg2:amd64.\r\n",
            "Preparing to unpack .../105-libzimg2_3.0.4+ds1-1_amd64.deb ...\r\n",
            "Unpacking libzimg2:amd64 (3.0.4+ds1-1) ...\r\n",
            "Selecting previously unselected package libavfilter8:amd64.\r\n",
            "Preparing to unpack .../106-libavfilter8_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libavfilter8:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package libslang2:amd64.\r\n",
            "Preparing to unpack .../107-libslang2_2.3.3-3_amd64.deb ...\r\n",
            "Unpacking libslang2:amd64 (2.3.3-3) ...\r\n",
            "Selecting previously unselected package libcaca0:amd64.\r\n",
            "Preparing to unpack .../108-libcaca0_0.99.beta20-3_amd64.deb ...\r\n",
            "Unpacking libcaca0:amd64 (0.99.beta20-3) ...\r\n",
            "Selecting previously unselected package libcdio19:amd64.\r\n",
            "Preparing to unpack .../109-libcdio19_2.1.0-4_amd64.deb ...\r\n",
            "Unpacking libcdio19:amd64 (2.1.0-4) ...\r\n",
            "Selecting previously unselected package libcdio-cdda2:amd64.\r\n",
            "Preparing to unpack .../110-libcdio-cdda2_10.2+2.0.1-1_amd64.deb ...\r\n",
            "Unpacking libcdio-cdda2:amd64 (10.2+2.0.1-1) ...\r\n",
            "Selecting previously unselected package libcdio-paranoia2:amd64.\r\n",
            "Preparing to unpack .../111-libcdio-paranoia2_10.2+2.0.1-1_amd64.deb ...\r\n",
            "Unpacking libcdio-paranoia2:amd64 (10.2+2.0.1-1) ...\r\n",
            "Selecting previously unselected package libusb-1.0-0:amd64.\r\n",
            "Preparing to unpack .../112-libusb-1.0-0_2%3a1.0.26-1_amd64.deb ...\r\n",
            "Unpacking libusb-1.0-0:amd64 (2:1.0.26-1) ...\r\n",
            "Selecting previously unselected package libdc1394-25:amd64.\r\n",
            "Preparing to unpack .../113-libdc1394-25_2.2.6-4_amd64.deb ...\r\n",
            "Unpacking libdc1394-25:amd64 (2.2.6-4) ...\r\n",
            "Selecting previously unselected package libglvnd0:amd64.\r\n",
            "Preparing to unpack .../114-libglvnd0_1.6.0-1_amd64.deb ...\r\n",
            "Unpacking libglvnd0:amd64 (1.6.0-1) ...\r\n",
            "Selecting previously unselected package libglapi-mesa:amd64.\r\n",
            "Preparing to unpack .../115-libglapi-mesa_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libglapi-mesa:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libxcb-dri2-0:amd64.\r\n",
            "Preparing to unpack .../116-libxcb-dri2-0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-dri2-0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-glx0:amd64.\r\n",
            "Preparing to unpack .../117-libxcb-glx0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-glx0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-present0:amd64.\r\n",
            "Preparing to unpack .../118-libxcb-present0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-present0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-randr0:amd64.\r\n",
            "Preparing to unpack .../119-libxcb-randr0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-randr0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-sync1:amd64.\r\n",
            "Preparing to unpack .../120-libxcb-sync1_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-sync1:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxcb-xfixes0:amd64.\r\n",
            "Preparing to unpack .../121-libxcb-xfixes0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-xfixes0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxshmfence1:amd64.\r\n",
            "Preparing to unpack .../122-libxshmfence1_1.3-1_amd64.deb ...\r\n",
            "Unpacking libxshmfence1:amd64 (1.3-1) ...\r\n",
            "Selecting previously unselected package libxxf86vm1:amd64.\r\n",
            "Preparing to unpack .../123-libxxf86vm1_1%3a1.1.4-1+b2_amd64.deb ...\r\n",
            "Unpacking libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\r\n",
            "Selecting previously unselected package libdrm-amdgpu1:amd64.\r\n",
            "Preparing to unpack .../124-libdrm-amdgpu1_2.4.114-1+b1_amd64.deb ...\r\n",
            "Unpacking libdrm-amdgpu1:amd64 (2.4.114-1+b1) ...\r\n",
            "Selecting previously unselected package libpciaccess0:amd64.\r\n",
            "Preparing to unpack .../125-libpciaccess0_0.17-2_amd64.deb ...\r\n",
            "Unpacking libpciaccess0:amd64 (0.17-2) ...\r\n",
            "Selecting previously unselected package libdrm-intel1:amd64.\r\n",
            "Preparing to unpack .../126-libdrm-intel1_2.4.114-1+b1_amd64.deb ...\r\n",
            "Unpacking libdrm-intel1:amd64 (2.4.114-1+b1) ...\r\n",
            "Selecting previously unselected package libdrm-nouveau2:amd64.\r\n",
            "Preparing to unpack .../127-libdrm-nouveau2_2.4.114-1+b1_amd64.deb ...\r\n",
            "Unpacking libdrm-nouveau2:amd64 (2.4.114-1+b1) ...\r\n",
            "Selecting previously unselected package libdrm-radeon1:amd64.\r\n",
            "Preparing to unpack .../128-libdrm-radeon1_2.4.114-1+b1_amd64.deb ...\r\n",
            "Unpacking libdrm-radeon1:amd64 (2.4.114-1+b1) ...\r\n",
            "Selecting previously unselected package libelf1:amd64.\r\n",
            "Preparing to unpack .../129-libelf1_0.188-2.1_amd64.deb ...\r\n",
            "Unpacking libelf1:amd64 (0.188-2.1) ...\r\n",
            "Selecting previously unselected package libz3-4:amd64.\r\n",
            "Preparing to unpack .../130-libz3-4_4.8.12-3.1_amd64.deb ...\r\n",
            "Unpacking libz3-4:amd64 (4.8.12-3.1) ...\r\n",
            "Selecting previously unselected package libllvm15:amd64.\r\n",
            "Preparing to unpack .../131-libllvm15_1%3a15.0.6-4+b1_amd64.deb ...\r\n",
            "Unpacking libllvm15:amd64 (1:15.0.6-4+b1) ...\r\n",
            "Selecting previously unselected package libsensors-config.\r\n",
            "Preparing to unpack .../132-libsensors-config_1%3a3.6.0-7.1_all.deb ...\r\n",
            "Unpacking libsensors-config (1:3.6.0-7.1) ...\r\n",
            "Selecting previously unselected package libsensors5:amd64.\r\n",
            "Preparing to unpack .../133-libsensors5_1%3a3.6.0-7.1_amd64.deb ...\r\n",
            "Unpacking libsensors5:amd64 (1:3.6.0-7.1) ...\r\n",
            "Selecting previously unselected package libgl1-mesa-dri:amd64.\r\n",
            "Preparing to unpack .../134-libgl1-mesa-dri_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libgl1-mesa-dri:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libglx-mesa0:amd64.\r\n",
            "Preparing to unpack .../135-libglx-mesa0_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libglx-mesa0:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libglx0:amd64.\r\n",
            "Preparing to unpack .../136-libglx0_1.6.0-1_amd64.deb ...\r\n",
            "Unpacking libglx0:amd64 (1.6.0-1) ...\r\n",
            "Selecting previously unselected package libgl1:amd64.\r\n",
            "Preparing to unpack .../137-libgl1_1.6.0-1_amd64.deb ...\r\n",
            "Unpacking libgl1:amd64 (1.6.0-1) ...\r\n",
            "Selecting previously unselected package libiec61883-0:amd64.\r\n",
            "Preparing to unpack .../138-libiec61883-0_1.2.0-6+b1_amd64.deb ...\r\n",
            "Unpacking libiec61883-0:amd64 (1.2.0-6+b1) ...\r\n",
            "Selecting previously unselected package libsamplerate0:amd64.\r\n",
            "Preparing to unpack .../139-libsamplerate0_0.2.2-3_amd64.deb ...\r\n",
            "Unpacking libsamplerate0:amd64 (0.2.2-3) ...\r\n",
            "Selecting previously unselected package libjack-jackd2-0:amd64.\r\n",
            "Preparing to unpack .../140-libjack-jackd2-0_1.9.21~dfsg-3_amd64.deb ...\r\n",
            "Unpacking libjack-jackd2-0:amd64 (1.9.21~dfsg-3) ...\r\n",
            "Selecting previously unselected package libopenal-data.\r\n",
            "Preparing to unpack .../141-libopenal-data_1%3a1.19.1-2_all.deb ...\r\n",
            "Unpacking libopenal-data (1:1.19.1-2) ...\r\n",
            "Selecting previously unselected package libsndio7.0:amd64.\r\n",
            "Preparing to unpack .../142-libsndio7.0_1.9.0-0.3+b2_amd64.deb ...\r\n",
            "Unpacking libsndio7.0:amd64 (1.9.0-0.3+b2) ...\r\n",
            "Selecting previously unselected package libopenal1:amd64.\r\n",
            "Preparing to unpack .../143-libopenal1_1%3a1.19.1-2_amd64.deb ...\r\n",
            "Unpacking libopenal1:amd64 (1:1.19.1-2) ...\r\n",
            "Selecting previously unselected package libwayland-client0:amd64.\r\n",
            "Preparing to unpack .../144-libwayland-client0_1.21.0-1_amd64.deb ...\r\n",
            "Unpacking libwayland-client0:amd64 (1.21.0-1) ...\r\n",
            "Selecting previously unselected package libdecor-0-0:amd64.\r\n",
            "Preparing to unpack .../145-libdecor-0-0_0.1.1-2_amd64.deb ...\r\n",
            "Unpacking libdecor-0-0:amd64 (0.1.1-2) ...\r\n",
            "Selecting previously unselected package libwayland-server0:amd64.\r\n",
            "Preparing to unpack .../146-libwayland-server0_1.21.0-1_amd64.deb ...\r\n",
            "Unpacking libwayland-server0:amd64 (1.21.0-1) ...\r\n",
            "Selecting previously unselected package libgbm1:amd64.\r\n",
            "Preparing to unpack .../147-libgbm1_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking libgbm1:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package libwayland-cursor0:amd64.\r\n",
            "Preparing to unpack .../148-libwayland-cursor0_1.21.0-1_amd64.deb ...\r\n",
            "Unpacking libwayland-cursor0:amd64 (1.21.0-1) ...\r\n",
            "Selecting previously unselected package libwayland-egl1:amd64.\r\n",
            "Preparing to unpack .../149-libwayland-egl1_1.21.0-1_amd64.deb ...\r\n",
            "Unpacking libwayland-egl1:amd64 (1.21.0-1) ...\r\n",
            "Selecting previously unselected package libxcursor1:amd64.\r\n",
            "Preparing to unpack .../150-libxcursor1_1%3a1.2.1-1_amd64.deb ...\r\n",
            "Unpacking libxcursor1:amd64 (1:1.2.1-1) ...\r\n",
            "Selecting previously unselected package libxi6:amd64.\r\n",
            "Preparing to unpack .../151-libxi6_2%3a1.8-1+b1_amd64.deb ...\r\n",
            "Unpacking libxi6:amd64 (2:1.8-1+b1) ...\r\n",
            "Selecting previously unselected package xkb-data.\r\n",
            "Preparing to unpack .../152-xkb-data_2.35.1-1_all.deb ...\r\n",
            "Unpacking xkb-data (2.35.1-1) ...\r\n",
            "Selecting previously unselected package libxkbcommon0:amd64.\r\n",
            "Preparing to unpack .../153-libxkbcommon0_1.5.0-1_amd64.deb ...\r\n",
            "Unpacking libxkbcommon0:amd64 (1.5.0-1) ...\r\n",
            "Selecting previously unselected package libxrandr2:amd64.\r\n",
            "Preparing to unpack .../154-libxrandr2_2%3a1.5.2-2+b1_amd64.deb ...\r\n",
            "Unpacking libxrandr2:amd64 (2:1.5.2-2+b1) ...\r\n",
            "Selecting previously unselected package x11-common.\r\n",
            "Preparing to unpack .../155-x11-common_1%3a7.7+23_all.deb ...\r\n",
            "Unpacking x11-common (1:7.7+23) ...\r\n",
            "Selecting previously unselected package libxss1:amd64.\r\n",
            "Preparing to unpack .../156-libxss1_1%3a1.2.3-1_amd64.deb ...\r\n",
            "Unpacking libxss1:amd64 (1:1.2.3-1) ...\r\n",
            "Selecting previously unselected package libsdl2-2.0-0:amd64.\r\n",
            "Preparing to unpack .../157-libsdl2-2.0-0_2.26.5+dfsg-1_amd64.deb ...\r\n",
            "Unpacking libsdl2-2.0-0:amd64 (2.26.5+dfsg-1) ...\r\n",
            "Selecting previously unselected package libxcb-shape0:amd64.\r\n",
            "Preparing to unpack .../158-libxcb-shape0_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb-shape0:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libxv1:amd64.\r\n",
            "Preparing to unpack .../159-libxv1_2%3a1.0.11-1.1_amd64.deb ...\r\n",
            "Unpacking libxv1:amd64 (2:1.0.11-1.1) ...\r\n",
            "Selecting previously unselected package libavdevice59:amd64.\r\n",
            "Preparing to unpack .../160-libavdevice59_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking libavdevice59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package ffmpeg.\r\n",
            "Preparing to unpack .../161-ffmpeg_7%3a5.1.6-0+deb12u1_amd64.deb ...\r\n",
            "Unpacking ffmpeg (7:5.1.6-0+deb12u1) ...\r\n",
            "Selecting previously unselected package i965-va-driver:amd64.\r\n",
            "Preparing to unpack .../162-i965-va-driver_2.4.1+dfsg1-1_amd64.deb ...\r\n",
            "Unpacking i965-va-driver:amd64 (2.4.1+dfsg1-1) ...\r\n",
            "Selecting previously unselected package libigdgmm12:amd64.\r\n",
            "Preparing to unpack .../163-libigdgmm12_22.3.3+ds1-1_amd64.deb ...\r\n",
            "Unpacking libigdgmm12:amd64 (22.3.3+ds1-1) ...\r\n",
            "Selecting previously unselected package intel-media-va-driver:amd64.\r\n",
            "Preparing to unpack .../164-intel-media-va-driver_23.1.1+dfsg1-1_amd64.deb ...\r\n",
            "Unpacking intel-media-va-driver:amd64 (23.1.1+dfsg1-1) ...\r\n",
            "Selecting previously unselected package libaacs0:amd64.\r\n",
            "Preparing to unpack .../165-libaacs0_0.11.1-2_amd64.deb ...\r\n",
            "Unpacking libaacs0:amd64 (0.11.1-2) ...\r\n",
            "Selecting previously unselected package libbdplus0:amd64.\r\n",
            "Preparing to unpack .../166-libbdplus0_0.2.0-3_amd64.deb ...\r\n",
            "Unpacking libbdplus0:amd64 (0.2.0-3) ...\r\n",
            "Selecting previously unselected package libdecor-0-plugin-1-cairo:amd64.\r\n",
            "Preparing to unpack .../167-libdecor-0-plugin-1-cairo_0.1.1-2_amd64.deb ...\r\n",
            "Unpacking libdecor-0-plugin-1-cairo:amd64 (0.1.1-2) ...\r\n",
            "Selecting previously unselected package libgdk-pixbuf2.0-bin.\r\n",
            "Preparing to unpack .../168-libgdk-pixbuf2.0-bin_2.42.10+dfsg-1+deb12u2_amd64.deb ...\r\n",
            "Unpacking libgdk-pixbuf2.0-bin (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Selecting previously unselected package libglib2.0-data.\r\n",
            "Preparing to unpack .../169-libglib2.0-data_2.74.6-2+deb12u6_all.deb ...\r\n",
            "Unpacking libglib2.0-data (2.74.6-2+deb12u6) ...\r\n",
            "Selecting previously unselected package libice6:amd64.\r\n",
            "Preparing to unpack .../170-libice6_2%3a1.0.10-1_amd64.deb ...\r\n",
            "Unpacking libice6:amd64 (2:1.0.10-1) ...\r\n",
            "Selecting previously unselected package libpthread-stubs0-dev:amd64.\r\n",
            "Preparing to unpack .../171-libpthread-stubs0-dev_0.4-1_amd64.deb ...\r\n",
            "Unpacking libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
            "Selecting previously unselected package librsvg2-common:amd64.\r\n",
            "Preparing to unpack .../172-librsvg2-common_2.54.7+dfsg-1~deb12u1_amd64.deb ...\r\n",
            "Unpacking librsvg2-common:amd64 (2.54.7+dfsg-1~deb12u1) ...\r\n",
            "Selecting previously unselected package libsm6:amd64.\r\n",
            "Preparing to unpack .../173-libsm6_2%3a1.2.3-1_amd64.deb ...\r\n",
            "Unpacking libsm6:amd64 (2:1.2.3-1) ...\r\n",
            "Selecting previously unselected package libvdpau-va-gl1:amd64.\r\n",
            "Preparing to unpack .../174-libvdpau-va-gl1_0.4.2-1+b1_amd64.deb ...\r\n",
            "Unpacking libvdpau-va-gl1:amd64 (0.4.2-1+b1) ...\r\n",
            "Selecting previously unselected package xorg-sgml-doctools.\r\n",
            "Preparing to unpack .../175-xorg-sgml-doctools_1%3a1.11-1.1_all.deb ...\r\n",
            "Unpacking xorg-sgml-doctools (1:1.11-1.1) ...\r\n",
            "Selecting previously unselected package x11proto-dev.\r\n",
            "Preparing to unpack .../176-x11proto-dev_2022.1-1_all.deb ...\r\n",
            "Unpacking x11proto-dev (2022.1-1) ...\r\n",
            "Selecting previously unselected package libxau-dev:amd64.\r\n",
            "Preparing to unpack .../177-libxau-dev_1%3a1.0.9-1_amd64.deb ...\r\n",
            "Unpacking libxau-dev:amd64 (1:1.0.9-1) ...\r\n",
            "Selecting previously unselected package libxdmcp-dev:amd64.\r\n",
            "Preparing to unpack .../178-libxdmcp-dev_1%3a1.1.2-3_amd64.deb ...\r\n",
            "Unpacking libxdmcp-dev:amd64 (1:1.1.2-3) ...\r\n",
            "Selecting previously unselected package xtrans-dev.\r\n",
            "Preparing to unpack .../179-xtrans-dev_1.4.0-1_all.deb ...\r\n",
            "Unpacking xtrans-dev (1.4.0-1) ...\r\n",
            "Selecting previously unselected package libxcb1-dev:amd64.\r\n",
            "Preparing to unpack .../180-libxcb1-dev_1.15-1_amd64.deb ...\r\n",
            "Unpacking libxcb1-dev:amd64 (1.15-1) ...\r\n",
            "Selecting previously unselected package libx11-dev:amd64.\r\n",
            "Preparing to unpack .../181-libx11-dev_2%3a1.8.4-2+deb12u2_amd64.deb ...\r\n",
            "Unpacking libx11-dev:amd64 (2:1.8.4-2+deb12u2) ...\r\n",
            "Selecting previously unselected package libxrender-dev:amd64.\r\n",
            "Preparing to unpack .../182-libxrender-dev_1%3a0.9.10-1.1_amd64.deb ...\r\n",
            "Unpacking libxrender-dev:amd64 (1:0.9.10-1.1) ...\r\n",
            "Selecting previously unselected package mesa-va-drivers:amd64.\r\n",
            "Preparing to unpack .../183-mesa-va-drivers_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking mesa-va-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package mesa-vdpau-drivers:amd64.\r\n",
            "Preparing to unpack .../184-mesa-vdpau-drivers_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking mesa-vdpau-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\r\n",
            "Preparing to unpack .../185-mesa-vulkan-drivers_22.3.6-1+deb12u1_amd64.deb ...\r\n",
            "Unpacking mesa-vulkan-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Selecting previously unselected package pocketsphinx-en-us.\r\n",
            "Preparing to unpack .../186-pocketsphinx-en-us_0.8+5prealpha+1-15_all.deb ...\r\n",
            "Unpacking pocketsphinx-en-us (0.8+5prealpha+1-15) ...\r\n",
            "Selecting previously unselected package va-driver-all:amd64.\r\n",
            "Preparing to unpack .../187-va-driver-all_2.17.0-1_amd64.deb ...\r\n",
            "Unpacking va-driver-all:amd64 (2.17.0-1) ...\r\n",
            "Selecting previously unselected package vdpau-driver-all:amd64.\r\n",
            "Preparing to unpack .../188-vdpau-driver-all_1.5-2_amd64.deb ...\r\n",
            "Unpacking vdpau-driver-all:amd64 (1.5-2) ...\r\n",
            "Selecting previously unselected package xdg-user-dirs.\r\n",
            "Preparing to unpack .../189-xdg-user-dirs_0.18-1_amd64.deb ...\r\n",
            "Unpacking xdg-user-dirs (0.18-1) ...\r\n",
            "Setting up libgme0:amd64 (0.6.3-6) ...\r\n",
            "Setting up libssh-gcrypt-4:amd64 (0.10.6-0+deb12u1) ...\r\n",
            "Setting up media-types (10.0.0) ...\r\n",
            "Setting up libgraphite2-3:amd64 (1.3.14-1) ...\r\n",
            "Setting up libxcb-dri3-0:amd64 (1.15-1) ...\r\n",
            "Setting up liblcms2-2:amd64 (2.14-2) ...\r\n",
            "Setting up libpixman-1-0:amd64 (0.42.2-1) ...\r\n",
            "Setting up libudfread0:amd64 (1.1.2-1) ...\r\n",
            "Setting up libwayland-server0:amd64 (1.21.0-1) ...\r\n",
            "Setting up libx11-xcb1:amd64 (2:1.8.4-2+deb12u2) ...\r\n",
            "Setting up libpciaccess0:amd64 (0.17-2) ...\r\n",
            "Setting up fontconfig (2.14.1-4) ...\r\n",
            "Regenerating fonts cache... done.\r\n",
            "Setting up librabbitmq4:amd64 (0.11.0-1+deb12u1) ...\r\n",
            "Setting up libraw1394-11:amd64 (2.1.2-2) ...\r\n",
            "Setting up libcodec2-1.0:amd64 (1.0.5-1) ...\r\n",
            "Setting up libmpg123-0:amd64 (1.31.2-1+deb12u1) ...\r\n",
            "Setting up libxcb-xfixes0:amd64 (1.15-1) ...\r\n",
            "Setting up libogg0:amd64 (1.3.5-3) ...\r\n",
            "Setting up libspeex1:amd64 (1.2.1-2) ...\r\n",
            "Setting up libshine3:amd64 (3.1.1-2) ...\r\n",
            "Setting up libxi6:amd64 (2:1.8-1+b1) ...\r\n",
            "Setting up libx264-164:amd64 (2:0.164.3095+gitbaee400-3) ...\r\n",
            "Setting up libtwolame0:amd64 (0.4.0-2) ...\r\n",
            "Setting up libxrender1:amd64 (1:0.9.10-1.1) ...\r\n",
            "Setting up libdatrie1:amd64 (0.2.13-2+b1) ...\r\n",
            "Setting up xdg-user-dirs (0.18-1) ...\r\n",
            "Setting up libgsm1:amd64 (1.0.22-1) ...\r\n",
            "Setting up libxcb-render0:amd64 (1.15-1) ...\r\n",
            "Setting up libsoxr0:amd64 (0.1.3-4) ...\r\n",
            "Setting up libglib2.0-0:amd64 (2.74.6-2+deb12u6) ...\r\n",
            "No schema files found: doing nothing.\r\n",
            "Setting up libglvnd0:amd64 (1.6.0-1) ...\r\n",
            "Setting up libpgm-5.3-0:amd64 (5.3.128~dfsg-2) ...\r\n",
            "Setting up libxcb-glx0:amd64 (1.15-1) ...\r\n",
            "Setting up libpython3.11-stdlib:amd64 (3.11.2-6+deb12u6) ...\r\n",
            "Setting up libgdk-pixbuf2.0-common (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Setting up libnorm1:amd64 (1.5.9+dfsg-2) ...\r\n",
            "Setting up libmysofa1:amd64 (1.3.1~dfsg0-1) ...\r\n",
            "Setting up libxcb-shape0:amd64 (1.15-1) ...\r\n",
            "Setting up x11-common (1:7.7+23) ...\r\n",
            "invoke-rc.d: could not determine current runlevel\r\n",
            "invoke-rc.d: policy-rc.d denied execution of restart.\r\n",
            "Setting up libsensors-config (1:3.6.0-7.1) ...\r\n",
            "Setting up xkb-data (2.35.1-1) ...\r\n",
            "Setting up libhwy1:amd64 (1.0.3-3+deb12u1) ...\r\n",
            "Setting up libxcb-shm0:amd64 (1.15-1) ...\r\n",
            "Setting up libigdgmm12:amd64 (22.3.3+ds1-1) ...\r\n",
            "Setting up libcdio19:amd64 (2.1.0-4) ...\r\n",
            "Setting up libcjson1:amd64 (1.7.15-1+deb12u2) ...\r\n",
            "Setting up libxvidcore4:amd64 (2:1.3.7-1) ...\r\n",
            "Setting up libpthread-stubs0-dev:amd64 (0.4-1) ...\r\n",
            "Setting up libcairo2:amd64 (1.16.0-7) ...\r\n",
            "Setting up libxxf86vm1:amd64 (1:1.1.4-1+b2) ...\r\n",
            "Setting up libsnappy1v5:amd64 (1.1.9-3) ...\r\n",
            "Setting up libxcb-present0:amd64 (1.15-1) ...\r\n",
            "Setting up libasound2-data (1.2.8-1) ...\r\n",
            "Setting up xtrans-dev (1.4.0-1) ...\r\n",
            "Setting up libz3-4:amd64 (4.8.12-3.1) ...\r\n",
            "Setting up libblas3:amd64 (3.11.0-2) ...\r\n",
            "update-alternatives: using /usr/lib/x86_64-linux-gnu/blas/libblas.so.3 to provide /usr/lib/x86_64-linux-gnu/libblas.so.3 (libblas.so.3-x86_64-linux-gnu) in auto mode\r\n",
            "Setting up libglib2.0-data (2.74.6-2+deb12u6) ...\r\n",
            "Setting up libflac12:amd64 (1.4.2+ds-2) ...\r\n",
            "Setting up libslang2:amd64 (2.3.3-3) ...\r\n",
            "Setting up libva2:amd64 (2.17.0-1) ...\r\n",
            "Setting up libmbedcrypto7:amd64 (2.28.3-1) ...\r\n",
            "Setting up libepoxy0:amd64 (1.5.10-1) ...\r\n",
            "Setting up libxfixes3:amd64 (1:6.0.0-2) ...\r\n",
            "Setting up libxcb-sync1:amd64 (1.15-1) ...\r\n",
            "Setting up libfribidi0:amd64 (1.0.8-2.1) ...\r\n",
            "Setting up libopus0:amd64 (1.3.1-3) ...\r\n",
            "Setting up shared-mime-info (2.2-1) ...\r\n",
            "Setting up intel-media-va-driver:amd64 (23.1.1+dfsg1-1) ...\r\n",
            "Setting up libxv1:amd64 (2:1.0.11-1.1) ...\r\n",
            "Setting up libvorbis0a:amd64 (1.3.7-1) ...\r\n",
            "Setting up libxrandr2:amd64 (2:1.5.2-2+b1) ...\r\n",
            "Setting up libsensors5:amd64 (1:3.6.0-7.1) ...\r\n",
            "Setting up libaacs0:amd64 (0.11.1-2) ...\r\n",
            "Setting up libjxl0.7:amd64 (0.7.0-10+deb12u1) ...\r\n",
            "Setting up pocketsphinx-en-us (0.8+5prealpha+1-15) ...\r\n",
            "Setting up libglapi-mesa:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libvulkan1:amd64 (1.3.239.0-1) ...\r\n",
            "Setting up librubberband2:amd64 (3.1.2+dfsg0-1) ...\r\n",
            "Setting up libxcb-dri2-0:amd64 (1.15-1) ...\r\n",
            "Setting up libbdplus0:amd64 (0.2.0-3) ...\r\n",
            "Setting up libvidstab1.1:amd64 (1.1.0-2+b1) ...\r\n",
            "Setting up libsrt1.5-gnutls:amd64 (1.5.1-1+deb12u1) ...\r\n",
            "Setting up alsa-topology-conf (1.2.5.1-2) ...\r\n",
            "Setting up ocl-icd-libopencl1:amd64 (2.3.1-1) ...\r\n",
            "Setting up libasyncns0:amd64 (0.8-6+b3) ...\r\n",
            "Setting up libxshmfence1:amd64 (1.3-1) ...\r\n",
            "Setting up libvdpau1:amd64 (1.5-2) ...\r\n",
            "Setting up libbs2b0:amd64 (3.1.0+dfsg-7) ...\r\n",
            "Setting up libxcb-randr0:amd64 (1.15-1) ...\r\n",
            "Setting up libllvm15:amd64 (1:15.0.6-4+b1) ...\r\n",
            "Setting up libtheora0:amd64 (1.1.1+dfsg.1-16.1+b1) ...\r\n",
            "Setting up libasound2:amd64 (1.2.8-1+b1) ...\r\n",
            "Setting up libzimg2:amd64 (3.0.4+ds1-1) ...\r\n",
            "Setting up libopenjp2-7:amd64 (2.5.0-2+deb12u1) ...\r\n",
            "Setting up libharfbuzz0b:amd64 (6.0.0+dfsg-3) ...\r\n",
            "Setting up libopenal-data (1:1.19.1-2) ...\r\n",
            "Setting up libthai-data (0.1.29-1) ...\r\n",
            "Setting up xorg-sgml-doctools (1:1.11-1.1) ...\r\n",
            "Setting up libgdk-pixbuf-2.0-0:amd64 (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Setting up libvpx7:amd64 (1.12.0-1+deb12u4) ...\r\n",
            "Setting up libcairo-gobject2:amd64 (1.16.0-7) ...\r\n",
            "Setting up libwayland-egl1:amd64 (1.21.0-1) ...\r\n",
            "Setting up libxss1:amd64 (1:1.2.3-1) ...\r\n",
            "Setting up libusb-1.0-0:amd64 (2:1.0.26-1) ...\r\n",
            "Setting up libmfx1:amd64 (22.5.4-1) ...\r\n",
            "Setting up libbluray2:amd64 (1:1.3.4-1) ...\r\n",
            "Setting up libsamplerate0:amd64 (0.2.2-3) ...\r\n",
            "Setting up libwebpmux3:amd64 (1.2.4-0.2+deb12u1) ...\r\n",
            "Setting up libdrm-common (2.4.114-1) ...\r\n",
            "Setting up libelf1:amd64 (0.188-2.1) ...\r\n",
            "Setting up libzvbi-common (0.2.41-1) ...\r\n",
            "Setting up libmp3lame0:amd64 (3.100-6) ...\r\n",
            "Setting up libvorbisenc2:amd64 (1.3.7-1) ...\r\n",
            "Setting up libpython3-stdlib:amd64 (3.11.2-1+b1) ...\r\n",
            "Setting up libiec61883-0:amd64 (1.2.0-6+b1) ...\r\n",
            "Setting up libserd-0-0:amd64 (0.30.16-1) ...\r\n",
            "Setting up libxkbcommon0:amd64 (1.5.0-1) ...\r\n",
            "Setting up libwayland-client0:amd64 (1.21.0-1) ...\r\n",
            "Setting up x11proto-dev (2022.1-1) ...\r\n",
            "Setting up libavc1394-0:amd64 (0.5.4-5) ...\r\n",
            "Setting up libzvbi0:amd64 (0.2.41-1) ...\r\n",
            "Setting up python3.11 (3.11.2-6+deb12u6) ...\r\n",
            "Setting up libice6:amd64 (2:1.0.10-1) ...\r\n",
            "Setting up liblapack3:amd64 (3.11.0-2) ...\r\n",
            "update-alternatives: using /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3 to provide /usr/lib/x86_64-linux-gnu/liblapack.so.3 (liblapack.so.3-x86_64-linux-gnu) in auto mode\r\n",
            "Setting up libplacebo208:amd64 (4.208.0-3) ...\r\n",
            "Setting up libzmq5:amd64 (4.3.4-6) ...\r\n",
            "Setting up libxau-dev:amd64 (1:1.0.9-1) ...\r\n",
            "Setting up libcaca0:amd64 (0.99.beta20-3) ...\r\n",
            "Setting up alsa-ucm-conf (1.2.8-1) ...\r\n",
            "Setting up libcdio-cdda2:amd64 (10.2+2.0.1-1) ...\r\n",
            "Setting up libcdio-paranoia2:amd64 (10.2+2.0.1-1) ...\r\n",
            "Setting up libxcursor1:amd64 (1:1.2.1-1) ...\r\n",
            "Setting up python3 (3.11.2-1+b1) ...\r\n",
            "running python rtupdate hooks for python3.11...\r\n",
            "running python post-rtupdate hooks for python3.11...\r\n",
            "Setting up librist4:amd64 (0.2.7+dfsg-1) ...\r\n",
            "Setting up libthai0:amd64 (0.1.29-1) ...\r\n",
            "Setting up libvorbisfile3:amd64 (1.3.7-1) ...\r\n",
            "Setting up libxdmcp-dev:amd64 (1:1.1.2-3) ...\r\n",
            "Setting up libass9:amd64 (1:0.17.1-1) ...\r\n",
            "Setting up libdc1394-25:amd64 (2.2.6-4) ...\r\n",
            "Setting up libsndio7.0:amd64 (1.9.0-0.3+b2) ...\r\n",
            "Setting up libjack-jackd2-0:amd64 (1.9.21~dfsg-3) ...\r\n",
            "Setting up libdrm2:amd64 (2.4.114-1+b1) ...\r\n",
            "Setting up libflite1:amd64 (2.2-5) ...\r\n",
            "Setting up libva-drm2:amd64 (2.17.0-1) ...\r\n",
            "Setting up libgdk-pixbuf2.0-bin (2.42.10+dfsg-1+deb12u2) ...\r\n",
            "Setting up libsord-0-0:amd64 (0.16.14+git221008-1) ...\r\n",
            "Setting up libwayland-cursor0:amd64 (1.21.0-1) ...\r\n",
            "Setting up libsratom-0-0:amd64 (0.6.14-1) ...\r\n",
            "Setting up libdecor-0-0:amd64 (0.1.1-2) ...\r\n",
            "Setting up libsndfile1:amd64 (1.2.0-1) ...\r\n",
            "Setting up libva-x11-2:amd64 (2.17.0-1) ...\r\n",
            "Setting up libsm6:amd64 (2:1.2.3-1) ...\r\n",
            "Setting up liblilv-0-0:amd64 (0.24.14-1) ...\r\n",
            "Setting up libopenmpt0:amd64 (0.6.9-1) ...\r\n",
            "Setting up libdrm-amdgpu1:amd64 (2.4.114-1+b1) ...\r\n",
            "Setting up mesa-vulkan-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libdrm-nouveau2:amd64 (2.4.114-1+b1) ...\r\n",
            "Setting up libxcb1-dev:amd64 (1.15-1) ...\r\n",
            "Setting up libgbm1:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libpulse0:amd64 (16.1+dfsg1-2+b1) ...\r\n",
            "Setting up libdrm-radeon1:amd64 (2.4.114-1+b1) ...\r\n",
            "Setting up libpango-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Setting up libdrm-intel1:amd64 (2.4.114-1+b1) ...\r\n",
            "Setting up libgl1-mesa-dri:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libx11-dev:amd64 (2:1.8.4-2+deb12u2) ...\r\n",
            "Setting up libopenal1:amd64 (1:1.19.1-2) ...\r\n",
            "Setting up libavutil57:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libswresample4:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libpostproc56:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up mesa-va-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libpangoft2-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Setting up libsdl2-2.0-0:amd64 (2.26.5+dfsg-1) ...\r\n",
            "Setting up libswscale6:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libxrender-dev:amd64 (1:0.9.10-1.1) ...\r\n",
            "Setting up i965-va-driver:amd64 (2.4.1+dfsg1-1) ...\r\n",
            "Setting up libpangocairo-1.0-0:amd64 (1.50.12+ds-1) ...\r\n",
            "Setting up mesa-vdpau-drivers:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libglx-mesa0:amd64 (22.3.6-1+deb12u1) ...\r\n",
            "Setting up libglx0:amd64 (1.6.0-1) ...\r\n",
            "Setting up libsphinxbase3:amd64 (0.8+5prealpha+1-16) ...\r\n",
            "Setting up librsvg2-2:amd64 (2.54.7+dfsg-1~deb12u1) ...\r\n",
            "Setting up libpocketsphinx3:amd64 (0.8+5prealpha+1-15) ...\r\n",
            "Setting up libgl1:amd64 (1.6.0-1) ...\r\n",
            "Setting up va-driver-all:amd64 (2.17.0-1) ...\r\n",
            "Setting up libdecor-0-plugin-1-cairo:amd64 (0.1.1-2) ...\r\n",
            "Setting up librsvg2-common:amd64 (2.54.7+dfsg-1~deb12u1) ...\r\n",
            "Setting up libavcodec59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libvdpau-va-gl1:amd64 (0.4.2-1+b1) ...\r\n",
            "Setting up libchromaprint1:amd64 (1.5.1-2+b1) ...\r\n",
            "Setting up libavformat59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libavfilter8:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up libavdevice59:amd64 (7:5.1.6-0+deb12u1) ...\r\n",
            "Setting up vdpau-driver-all:amd64 (1.5-2) ...\r\n",
            "Setting up ffmpeg (7:5.1.6-0+deb12u1) ...\r\n",
            "Processing triggers for systemd (252.38-1~deb12u1) ...\r\n",
            "Processing triggers for libc-bin (2.36-9+deb12u9) ...\r\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.10+dfsg-1+deb12u2) ...\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": false,
        "scrolled": true
      },
      "source": [
        "!python studio.py --share"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\r\n",
            "\r\n",
            "--- Attention Configuration ---\r\n",
            "\u26a0\ufe0f  No attention library found. Using native PyTorch Scaled Dot Product Attention.\r\n",
            "   - For better performance, consider installing one of:\r\n",
            "     SAGE Attention (highest performance), Flash Attention (high performance), or xFormers.\r\n",
            "-------------------------------\r\n",
            "\r\n",
            "Bundled FFmpeg not found in '/root/FramePack-Studio/modules/toolbox/bin'. Running one-time setup...\r\n",
            "FFmpeg not found. Downloading and setting up for linux...\r\n",
            "\rffmpeg.tar.xz:   0%|                               | 0.00/39.9M [00:00<?, ?iB/s]\rffmpeg.tar.xz:   0%|                       | 94.0k/39.9M [00:00<01:02, 670kiB/s]\rffmpeg.tar.xz:   1%|\u258e                      | 492k/39.9M [00:00<00:17, 2.37MiB/s]\rffmpeg.tar.xz:   4%|\u2589                     | 1.74M/39.9M [00:00<00:05, 6.87MiB/s]\rffmpeg.tar.xz:  10%|\u2588\u2588\u258f                   | 3.99M/39.9M [00:00<00:02, 13.1MiB/s]\rffmpeg.tar.xz:  15%|\u2588\u2588\u2588\u258d                  | 6.17M/39.9M [00:00<00:02, 16.5MiB/s]\rffmpeg.tar.xz:  21%|\u2588\u2588\u2588\u2588\u258b                 | 8.42M/39.9M [00:00<00:01, 18.8MiB/s]\rffmpeg.tar.xz:  27%|\u2588\u2588\u2588\u2588\u2588\u258a                | 10.7M/39.9M [00:00<00:01, 20.3MiB/s]\rffmpeg.tar.xz:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f              | 13.0M/39.9M [00:00<00:01, 21.6MiB/s]\rffmpeg.tar.xz:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b             | 15.7M/39.9M [00:00<00:01, 23.7MiB/s]\rffmpeg.tar.xz:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d           | 18.9M/39.9M [00:01<00:00, 26.6MiB/s]\rffmpeg.tar.xz:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588          | 22.0M/39.9M [00:01<00:00, 28.4MiB/s]\rffmpeg.tar.xz:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b        | 25.0M/39.9M [00:01<00:00, 29.4MiB/s]\rffmpeg.tar.xz:  70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e      | 27.8M/39.9M [00:01<00:00, 29.2MiB/s]\rffmpeg.tar.xz:  77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 30.7M/39.9M [00:01<00:00, 29.7MiB/s]\rffmpeg.tar.xz:  85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 33.9M/39.9M [00:01<00:00, 30.9MiB/s]\rffmpeg.tar.xz:  92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 36.9M/39.9M [00:01<00:00, 31.0MiB/s]\rffmpeg.tar.xz: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 39.9M/39.9M [00:01<00:00, 24.0MiB/s]\r\n",
            "Download complete. Installing...\r\n",
            "\u2705 FFmpeg setup complete. Binaries are in: /root/FramePack-Studio/modules/toolbox/bin\r\n",
            "Namespace(share=True, server='0.0.0.0', port=None, inbrowser=False, lora=None, offline=False)\r\n",
            "Free VRAM 43.9700927734375 GB\r\n",
            "High-VRAM Mode: False\r\n",
            "\rconfig.json:   0%|                                    | 0.00/766 [00:00<?, ?B/s]\rconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 766/766 [00:00<00:00, 5.38MB/s]\r\n",
            "\rmodel.safetensors.index.json: 0.00B [00:00, ?B/s]\rmodel.safetensors.index.json: 22.2kB [00:00, 76.0MB/s]\r\n",
            "\rDownloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   0%|  | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   0%| | 590k/4.98G [00:00<2:15:25, \u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   0%| | 2.00M/4.98G [00:01<49:23, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   0%| | 4.33M/4.98G [00:02<32:25, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   1%| | 71.3M/4.98G [00:05<04:44, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   3%| | 138M/4.98G [00:06<02:53, 27\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   4%| | 205M/4.98G [00:06<01:48, 44\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   5%| | 273M/4.98G [00:07<01:09, 68\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   7%| | 340M/4.98G [00:07<00:51, 90\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):   8%| | 410M/4.98G [00:07<00:35, 12\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  10%| | 477M/4.98G [00:07<00:27, 16\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  11%| | 544M/4.98G [00:07<00:20, 21\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  12%| | 611M/4.98G [00:07<00:17, 25\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  14%|\u258f| 676M/4.98G [00:09<00:38, 11\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  15%|\u258f| 743M/4.98G [00:09<00:28, 14\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  16%|\u258f| 810M/4.98G [00:09<00:22, 18\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  18%|\u258f| 877M/4.98G [00:09<00:18, 22\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  19%|\u258f| 944M/4.98G [00:10<00:25, 15\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  20%|\u258f| 1.01G/4.98G [00:11<00:31, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  22%|\u258f| 1.08G/4.98G [00:11<00:25, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  23%|\u258f| 1.14G/4.98G [00:11<00:23, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  24%|\u258f| 1.21G/4.98G [00:11<00:17, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  26%|\u258e| 1.28G/4.98G [00:12<00:24, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  27%|\u258e| 1.34G/4.98G [00:13<00:27, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  28%|\u258e| 1.41G/4.98G [00:13<00:20, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  30%|\u258e| 1.48G/4.98G [00:13<00:18, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  31%|\u258e| 1.56G/4.98G [00:14<00:19, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  33%|\u258e| 1.63G/4.98G [00:14<00:15, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  34%|\u258e| 1.69G/4.98G [00:14<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  35%|\u258e| 1.76G/4.98G [00:14<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  37%|\u258e| 1.83G/4.98G [00:14<00:10, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  38%|\u258d| 1.90G/4.98G [00:14<00:10, 3\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  39%|\u258d| 1.96G/4.98G [00:15<00:11, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  41%|\u258d| 2.03G/4.98G [00:16<00:18, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  42%|\u258d| 2.10G/4.98G [00:16<00:15, 1\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  43%|\u258d| 2.16G/4.98G [00:16<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  45%|\u258d| 2.23G/4.98G [00:16<00:10, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  46%|\u258d| 2.30G/4.98G [00:16<00:08, 3\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  48%|\u258d| 2.37G/4.98G [00:17<00:09, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  49%|\u258d| 2.43G/4.98G [00:17<00:09, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  50%|\u258c| 2.50G/4.98G [00:17<00:08, 2\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  51%|\u258c| 2.56G/4.98G [00:17<00:07, 3\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  53%|\u258c| 2.63G/4.98G [00:17<00:06, 3\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  54%|\u258c| 2.70G/4.98G [00:17<00:05, 4\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  57%|\u258c| 2.83G/4.98G [00:18<00:04, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  60%|\u258c| 2.97G/4.98G [00:18<00:03, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  61%|\u258c| 3.03G/4.98G [00:18<00:03, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  64%|\u258b| 3.17G/4.98G [00:18<00:02, 6\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  66%|\u258b| 3.30G/4.98G [00:18<00:02, 6\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  68%|\u258b| 3.37G/4.98G [00:18<00:02, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  70%|\u258b| 3.50G/4.98G [00:19<00:02, 6\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  72%|\u258b| 3.57G/4.98G [00:19<00:02, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  73%|\u258b| 3.64G/4.98G [00:19<00:02, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  76%|\u258a| 3.77G/4.98G [00:19<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  78%|\u258a| 3.90G/4.98G [00:19<00:01, 7\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  81%|\u258a| 4.04G/4.98G [00:20<00:01, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  82%|\u258a| 4.11G/4.98G [00:20<00:01, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  87%|\u258a| 4.31G/4.98G [00:20<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  91%|\u2589| 4.51G/4.98G [00:20<00:00, 8\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  93%|\u2589| 4.64G/4.98G [00:21<00:00, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026):  96%|\u2589| 4.78G/4.98G [00:21<00:00, 5\u001b[A\r\n",
            "\rtext_encoder/model-00001-of-00004.safete(\u2026): 100%|\u2588| 4.98G/4.98G [00:21<00:00, 6\u001b[A\rtext_encoder/model-00001-of-00004.safete(\u2026): 100%|\u2588| 4.98G/4.98G [00:21<00:00, 2\r\n",
            "\rDownloading shards:  25%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e                  | 1/4 [00:21<01:04, 21.62s/it]\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   0%|  | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   0%| | 846k/5.00G [00:01<1:44:58, \u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   0%| | 2.45M/5.00G [00:02<1:06:16,\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   0%| | 4.97M/5.00G [00:02<37:52, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   1%| | 72.0M/5.00G [00:03<02:46, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   3%| | 139M/5.00G [00:05<02:02, 39\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   4%| | 206M/5.00G [00:05<01:30, 53\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   5%| | 273M/5.00G [00:05<00:57, 82\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   7%| | 340M/5.00G [00:06<00:50, 92\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   8%| | 407M/5.00G [00:07<00:51, 89\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):   9%| | 474M/5.00G [00:07<00:37, 12\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  11%| | 541M/5.00G [00:08<00:42, 10\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  12%| | 607M/5.00G [00:08<00:33, 13\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  13%|\u258f| 674M/5.00G [00:08<00:24, 17\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  15%|\u258f| 741M/5.00G [00:08<00:19, 22\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  16%|\u258f| 808M/5.00G [00:08<00:15, 27\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  18%|\u258f| 875M/5.00G [00:09<00:24, 16\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  20%|\u258f| 1.01G/5.00G [00:09<00:18, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  22%|\u258f| 1.08G/5.00G [00:10<00:15, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  23%|\u258f| 1.14G/5.00G [00:10<00:15, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  24%|\u258f| 1.21G/5.00G [00:10<00:13, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  26%|\u258e| 1.28G/5.00G [00:11<00:17, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  27%|\u258e| 1.35G/5.00G [00:11<00:18, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  28%|\u258e| 1.41G/5.00G [00:12<00:23, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  30%|\u258e| 1.48G/5.00G [00:12<00:21, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  32%|\u258e| 1.62G/5.00G [00:13<00:18, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  35%|\u258e| 1.75G/5.00G [00:13<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  36%|\u258e| 1.82G/5.00G [00:13<00:11, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  38%|\u258d| 1.88G/5.00G [00:14<00:15, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  39%|\u258d| 1.95G/5.00G [00:14<00:13, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  41%|\u258d| 2.06G/5.00G [00:15<00:16, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  42%|\u258d| 2.12G/5.00G [00:15<00:13, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  45%|\u258d| 2.26G/5.00G [00:15<00:10, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  46%|\u258d| 2.32G/5.00G [00:15<00:10, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  48%|\u258d| 2.39G/5.00G [00:16<00:09, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  49%|\u258d| 2.46G/5.00G [00:16<00:12, 1\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  52%|\u258c| 2.59G/5.00G [00:16<00:08, 2\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  53%|\u258c| 2.66G/5.00G [00:16<00:07, 3\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  55%|\u258c| 2.73G/5.00G [00:17<00:06, 3\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  57%|\u258c| 2.86G/5.00G [00:17<00:05, 4\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  59%|\u258c| 2.93G/5.00G [00:17<00:04, 4\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  60%|\u258c| 2.99G/5.00G [00:17<00:05, 3\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  61%|\u258c| 3.06G/5.00G [00:17<00:04, 4\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  64%|\u258b| 3.20G/5.00G [00:18<00:03, 4\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  67%|\u258b| 3.33G/5.00G [00:18<00:02, 5\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  69%|\u258b| 3.46G/5.00G [00:18<00:02, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  72%|\u258b| 3.60G/5.00G [00:18<00:02, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  75%|\u258b| 3.73G/5.00G [00:18<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  76%|\u258a| 3.80G/5.00G [00:18<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  79%|\u258a| 3.93G/5.00G [00:19<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  81%|\u258a| 4.07G/5.00G [00:19<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  84%|\u258a| 4.20G/5.00G [00:19<00:01, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  87%|\u258a| 4.34G/5.00G [00:19<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  89%|\u2589| 4.47G/5.00G [00:19<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  92%|\u2589| 4.60G/5.00G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  95%|\u2589| 4.74G/5.00G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026):  97%|\u2589| 4.87G/5.00G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00002-of-00004.safete(\u2026): 100%|\u2588| 5.00G/5.00G [00:20<00:00, 7\u001b[A\rtext_encoder/model-00002-of-00004.safete(\u2026): 100%|\u2588| 5.00G/5.00G [00:20<00:00, 2\r\n",
            "\rDownloading shards:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c            | 2/4 [00:42<00:42, 21.00s/it]\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   0%|  | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   0%| | 691k/4.92G [00:00<1:48:51, \u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   0%| | 2.23M/4.92G [00:01<43:53, 1\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   1%| | 69.2M/4.92G [00:04<04:51, 1\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   3%| | 136M/4.92G [00:04<02:06, 37\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   4%| | 206M/4.92G [00:07<02:27, 31\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   6%| | 273M/4.92G [00:07<01:38, 46\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   7%| | 340M/4.92G [00:08<01:11, 64\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):   8%| | 407M/4.92G [00:08<00:52, 85\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  10%| | 474M/4.92G [00:09<00:47, 94\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  11%| | 541M/4.92G [00:09<00:46, 94\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  12%| | 608M/4.92G [00:09<00:34, 12\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  14%|\u258f| 675M/4.92G [00:09<00:25, 16\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  15%|\u258f| 742M/4.92G [00:10<00:20, 19\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  16%|\u258f| 809M/4.92G [00:10<00:18, 22\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  19%|\u258f| 943M/4.92G [00:10<00:12, 33\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  22%|\u258f| 1.08G/4.92G [00:10<00:09, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  23%|\u258f| 1.14G/4.92G [00:10<00:08, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  25%|\u258f| 1.21G/4.92G [00:11<00:08, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  26%|\u258e| 1.28G/4.92G [00:11<00:07, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  27%|\u258e| 1.34G/4.92G [00:11<00:07, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  30%|\u258e| 1.48G/4.92G [00:11<00:05, 6\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  33%|\u258e| 1.61G/4.92G [00:11<00:05, 5\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  34%|\u258e| 1.68G/4.92G [00:12<00:17, 1\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  36%|\u258e| 1.75G/4.92G [00:13<00:14, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  38%|\u258d| 1.88G/4.92G [00:13<00:11, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  40%|\u258d| 1.95G/4.92G [00:13<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  41%|\u258d| 2.01G/4.92G [00:14<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  42%|\u258d| 2.08G/4.92G [00:14<00:13, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  44%|\u258d| 2.15G/4.92G [00:14<00:14, 1\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  45%|\u258d| 2.22G/4.92G [00:15<00:12, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  46%|\u258d| 2.28G/4.92G [00:15<00:10, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  48%|\u258d| 2.35G/4.92G [00:15<00:08, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  50%|\u258c| 2.48G/4.92G [00:15<00:07, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  52%|\u258c| 2.57G/4.92G [00:16<00:07, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  54%|\u258c| 2.64G/4.92G [00:16<00:06, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  55%|\u258c| 2.70G/4.92G [00:16<00:06, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  56%|\u258c| 2.77G/4.92G [00:16<00:07, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  58%|\u258c| 2.84G/4.92G [00:16<00:06, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  59%|\u258c| 2.90G/4.92G [00:17<00:07, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  60%|\u258c| 2.97G/4.92G [00:17<00:05, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  62%|\u258c| 3.04G/4.92G [00:17<00:05, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  63%|\u258b| 3.11G/4.92G [00:17<00:07, 2\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  66%|\u258b| 3.24G/4.92G [00:18<00:04, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  69%|\u258b| 3.37G/4.92G [00:18<00:04, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  70%|\u258b| 3.44G/4.92G [00:18<00:03, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  71%|\u258b| 3.51G/4.92G [00:18<00:03, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  73%|\u258b| 3.58G/4.92G [00:18<00:03, 4\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  74%|\u258b| 3.64G/4.92G [00:19<00:03, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  75%|\u258a| 3.71G/4.92G [00:19<00:03, 3\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  78%|\u258a| 3.84G/4.92G [00:19<00:02, 5\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  81%|\u258a| 3.98G/4.92G [00:19<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  84%|\u258a| 4.11G/4.92G [00:19<00:01, 6\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  86%|\u258a| 4.25G/4.92G [00:20<00:01, 5\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  89%|\u2589| 4.38G/4.92G [00:20<00:00, 6\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  92%|\u2589| 4.51G/4.92G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  95%|\u2589| 4.65G/4.92G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026):  97%|\u2589| 4.78G/4.92G [00:20<00:00, 7\u001b[A\r\n",
            "\rtext_encoder/model-00003-of-00004.safete(\u2026): 100%|\u2588| 4.92G/4.92G [00:20<00:00, 8\u001b[A\rtext_encoder/model-00003-of-00004.safete(\u2026): 100%|\u2588| 4.92G/4.92G [00:20<00:00, 2\r\n",
            "\rDownloading shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a      | 3/4 [01:03<00:20, 20.92s/it]\r\n",
            "\rtext_encoder/model-00004-of-00004.safete(\u2026):   0%|   | 0.00/117M [00:00<?, ?B/s]\u001b[A\r\n",
            "\rtext_encoder/model-00004-of-00004.safete(\u2026):  43%|\u258d| 50.4M/117M [00:00<00:01, 63\u001b[A\r\n",
            "\rtext_encoder/model-00004-of-00004.safete(\u2026): 100%|\u2588| 117M/117M [00:00<00:00, 142\u001b[A\rtext_encoder/model-00004-of-00004.safete(\u2026): 100%|\u2588| 117M/117M [00:00<00:00, 122\r\n",
            "\rDownloading shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [01:04<00:00, 13.06s/it]\rDownloading shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [01:04<00:00, 16.00s/it]\r\n",
            "\rLoading checkpoint shards:   0%|                          | 0/4 [00:00<?, ?it/s]\rLoading checkpoint shards:  25%|\u2588\u2588\u2588\u2588\u258c             | 1/4 [00:00<00:00,  4.55it/s]\rLoading checkpoint shards:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 2/4 [00:00<00:00,  4.38it/s]\rLoading checkpoint shards:  75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c    | 3/4 [00:00<00:00,  4.35it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00,  4.42it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00<00:00,  4.41it/s]\r\n",
            "\rconfig.json:   0%|                                    | 0.00/646 [00:00<?, ?B/s]\rconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 646/646 [00:00<00:00, 7.36MB/s]\r\n",
            "\rtext_encoder_2/model.safetensors:   0%|              | 0.00/246M [00:00<?, ?B/s]\rtext_encoder_2/model.safetensors:  18%|\u2589    | 45.0M/246M [00:01<00:05, 34.5MB/s]\rtext_encoder_2/model.safetensors:  46%|\u2588\u2588\u258b   | 112M/246M [00:01<00:01, 86.1MB/s]\rtext_encoder_2/model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 246M/246M [00:01<00:00, 206MB/s]\rtext_encoder_2/model.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 246M/246M [00:01<00:00, 143MB/s]\r\n",
            "\rtokenizer_config.json: 0.00B [00:00, ?B/s]\rtokenizer_config.json: 51.7kB [00:00, 111MB/s]\r\n",
            "\rtokenizer/tokenizer.json:   0%|                     | 0.00/17.2M [00:00<?, ?B/s]\rtokenizer/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17.2M/17.2M [00:00<00:00, 117MB/s]\rtokenizer/tokenizer.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17.2M/17.2M [00:00<00:00, 116MB/s]\r\n",
            "\rspecial_tokens_map.json:   0%|                        | 0.00/577 [00:00<?, ?B/s]\rspecial_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 577/577 [00:00<00:00, 3.59MB/s]\r\n",
            "\rtokenizer_config.json:   0%|                          | 0.00/736 [00:00<?, ?B/s]\rtokenizer_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 736/736 [00:00<00:00, 7.82MB/s]\r\n",
            "\rvocab.json: 0.00B [00:00, ?B/s]\rvocab.json: 1.06MB [00:00, 168MB/s]\r\n",
            "\rmerges.txt: 0.00B [00:00, ?B/s]\rmerges.txt: 525kB [00:00, 136MB/s]\r\n",
            "\rspecial_tokens_map.json:   0%|                        | 0.00/588 [00:00<?, ?B/s]\rspecial_tokens_map.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 588/588 [00:00<00:00, 4.97MB/s]\r\n",
            "\rconfig.json:   0%|                                    | 0.00/718 [00:00<?, ?B/s]\rconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 718/718 [00:00<00:00, 7.55MB/s]\r\n",
            "\rvae/diffusion_pytorch_model.safetensors:   0%|       | 0.00/986M [00:00<?, ?B/s]\rvae/diffusion_pytorch_model.safetensors:   7%| | 67.0M/986M [00:03<00:42, 21.6MB\rvae/diffusion_pytorch_model.safetensors:  12%| | 114M/986M [00:03<00:22, 38.9MB/\rvae/diffusion_pytorch_model.safetensors:  18%|\u258f| 181M/986M [00:03<00:11, 69.3MB/\rvae/diffusion_pytorch_model.safetensors:  25%|\u258e| 248M/986M [00:03<00:07, 105MB/s\rvae/diffusion_pytorch_model.safetensors:  39%|\u258d| 382M/986M [00:03<00:02, 208MB/s\rvae/diffusion_pytorch_model.safetensors:  52%|\u258c| 516M/986M [00:04<00:01, 284MB/s\rvae/diffusion_pytorch_model.safetensors:  66%|\u258b| 650M/986M [00:04<00:00, 398MB/s\rvae/diffusion_pytorch_model.safetensors:  80%|\u258a| 785M/986M [00:04<00:00, 444MB/s\rvae/diffusion_pytorch_model.safetensors: 100%|\u2588| 986M/986M [00:04<00:00, 596MB/s\rvae/diffusion_pytorch_model.safetensors: 100%|\u2588| 986M/986M [00:04<00:00, 211MB/s\r\n",
            "\rpreprocessor_config.json:   0%|                       | 0.00/394 [00:00<?, ?B/s]\rpreprocessor_config.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 394/394 [00:00<00:00, 2.92MB/s]\r\n",
            "\rconfig.json:   0%|                                    | 0.00/585 [00:00<?, ?B/s]\rconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 585/585 [00:00<00:00, 8.37MB/s]\r\n",
            "\rmodel.safetensors:   0%|                             | 0.00/857M [00:00<?, ?B/s]\rmodel.safetensors:   2%|\u258c                    | 21.0M/857M [00:00<00:05, 146MB/s]\rmodel.safetensors:   5%|\u2588                    | 41.9M/857M [00:00<00:05, 155MB/s]\rmodel.safetensors:   7%|\u2588\u258c                   | 62.9M/857M [00:00<00:04, 160MB/s]\rmodel.safetensors:  10%|\u2588\u2588                   | 83.9M/857M [00:00<00:04, 164MB/s]\rmodel.safetensors:  12%|\u2588\u2588\u258b                   | 105M/857M [00:00<00:04, 168MB/s]\rmodel.safetensors:  15%|\u2588\u2588\u2588\u258f                  | 126M/857M [00:00<00:04, 170MB/s]\rmodel.safetensors:  17%|\u2588\u2588\u2588\u258a                  | 147M/857M [00:00<00:04, 163MB/s]\rmodel.safetensors:  20%|\u2588\u2588\u2588\u2588\u258e                 | 168M/857M [00:01<00:04, 167MB/s]\rmodel.safetensors:  22%|\u2588\u2588\u2588\u2588\u258a                 | 189M/857M [00:01<00:03, 169MB/s]\rmodel.safetensors:  24%|\u2588\u2588\u2588\u2588\u2588\u258d                | 210M/857M [00:01<00:03, 173MB/s]\rmodel.safetensors:  27%|\u2588\u2588\u2588\u2588\u2588\u2589                | 231M/857M [00:01<00:03, 172MB/s]\rmodel.safetensors:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d               | 252M/857M [00:01<00:03, 172MB/s]\rmodel.safetensors:  32%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588               | 273M/857M [00:01<00:03, 168MB/s]\rmodel.safetensors:  34%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c              | 294M/857M [00:01<00:03, 169MB/s]\rmodel.safetensors:  37%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588              | 315M/857M [00:01<00:03, 169MB/s]\rmodel.safetensors:  39%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 336M/857M [00:01<00:03, 170MB/s]\rmodel.safetensors:  42%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f            | 357M/857M [00:02<00:02, 167MB/s]\rmodel.safetensors:  44%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b            | 377M/857M [00:02<00:02, 166MB/s]\rmodel.safetensors:  47%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f           | 398M/857M [00:02<00:02, 168MB/s]\rmodel.safetensors:  49%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a           | 419M/857M [00:02<00:02, 166MB/s]\rmodel.safetensors:  51%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e          | 440M/857M [00:02<00:02, 170MB/s]\rmodel.safetensors:  54%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a          | 461M/857M [00:02<00:02, 170MB/s]\rmodel.safetensors:  56%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d         | 482M/857M [00:02<00:02, 171MB/s]\rmodel.safetensors:  59%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589         | 503M/857M [00:02<00:02, 172MB/s]\rmodel.safetensors:  61%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d        | 524M/857M [00:03<00:01, 172MB/s]\rmodel.safetensors:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588        | 545M/857M [00:03<00:01, 173MB/s]\rmodel.safetensors:  66%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c       | 566M/857M [00:03<00:01, 174MB/s]\rmodel.safetensors:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588       | 587M/857M [00:03<00:01, 174MB/s]\rmodel.safetensors:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c      | 608M/857M [00:03<00:01, 173MB/s]\rmodel.safetensors:  73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f     | 629M/857M [00:03<00:01, 173MB/s]\rmodel.safetensors:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b     | 650M/857M [00:03<00:01, 174MB/s]\rmodel.safetensors:  78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f    | 671M/857M [00:03<00:01, 176MB/s]\rmodel.safetensors:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a    | 692M/857M [00:04<00:00, 175MB/s]\rmodel.safetensors:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 713M/857M [00:04<00:00, 176MB/s]\rmodel.safetensors:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 734M/857M [00:04<00:00, 179MB/s]\rmodel.safetensors:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 755M/857M [00:04<00:00, 180MB/s]\rmodel.safetensors:  91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 776M/857M [00:04<00:00, 183MB/s]\rmodel.safetensors:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 797M/857M [00:04<00:00, 183MB/s]\rmodel.safetensors:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 818M/857M [00:04<00:00, 179MB/s]\rmodel.safetensors:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 839M/857M [00:04<00:00, 178MB/s]\rmodel.safetensors: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 857M/857M [00:04<00:00, 172MB/s]\r\n",
            "Scanning for LoRAs in: /root/FramePack-Studio/loras\r\n",
            "Found LoRAs: []\r\n",
            "* Running on local URL:  http://0.0.0.0:7860\r\n",
            "* Running on public URL: https://368f1f955465f77e50.gradio.live\r\n",
            "\r\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\r\n",
            "Teacache parameters: use_teacache=False, teacache_num_steps=25, teacache_rel_l1_thresh=0.15\r\n",
            "Adding job c5fe0a42-a603-43c4-814b-90276ae1771e (type: single) to queue.\r\n",
            "Starting job c5fe0a42-a603-43c4-814b-90276ae1771e, current job was None\r\n",
            "Starting worker function for job c5fe0a42-a603-43c4-814b-90276ae1771e\r\n",
            "Worker function started for job c5fe0a42-a603-43c4-814b-90276ae1771e\r\n",
            "Florence-2 model unloaded successfully.\r\n",
            "Worker: Selected LoRAs for this worker: []\r\n",
            "Pushing initial progress update to main stream for job 250814_125325_559_3268\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Worker starting for model type: Original\r\n",
            "Worker: Before model assignment, studio_module.current_generator is <class 'NoneType'>, id: 46882627416032\r\n",
            "Worker: AFTER model assignment, studio_module.current_generator is <class 'modules.generators.original_generator.OriginalModelGenerator'>, id: 46891162101680\r\n",
            "Worker: studio_module.current_generator.transformer is <class 'NoneType'>\r\n",
            "Loading Original Transformer...\r\n",
            "\rconfig.json:   0%|                                    | 0.00/658 [00:00<?, ?B/s]\rconfig.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 658/658 [00:00<00:00, 4.16MB/s]\r\n",
            "\r(\u2026)ion_pytorch_model.safetensors.index.json: 0.00B [00:00, ?B/s]\r(\u2026)ion_pytorch_model.safetensors.index.json: 134kB [00:00, 113MB/s]\r\n",
            "\rFetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   0%|  | 0.00/5.79G [00:00<?, ?B/s]\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   0%|  | 0.00/9.99G [00:00<?, ?B/s]\u001b[A\u001b[ASaved input image for job c5fe0a42-a603-43c4-814b-90276ae1771e to queue_images/c5fe0a42-a603-43c4-814b-90276ae1771e_input.png\r\n",
            "Saved 1 jobs to queue.json\r\n",
            "Added job c5fe0a42-a603-43c4-814b-90276ae1771e to queue\r\n",
            "Generated new seed for next job: 16841\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   0%| | 21.0M/5.79G [00:00<00:44, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   0%|  | 0.00/9.97G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   0%| | 21.0M/9.99G [00:00<01:31, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   0%| | 10.5M/9.97G [00:00<01:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   1%| | 41.9M/5.79G [00:00<00:48, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   0%| | 41.9M/9.99G [00:00<01:36, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   0%| | 21.0M/9.97G [00:00<01:54, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   0%| | 31.5M/9.97G [00:00<01:50, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 52.4M/9.99G [00:00<01:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   1%| | 62.9M/5.79G [00:00<00:53, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   0%| | 41.9M/9.97G [00:00<01:50, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 62.9M/9.99G [00:00<01:45, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 52.4M/9.97G [00:00<01:45, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 73.4M/9.99G [00:00<01:45, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   1%| | 83.9M/5.79G [00:00<00:54, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 62.9M/9.97G [00:00<01:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 83.9M/9.99G [00:00<01:43, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 73.4M/9.97G [00:00<01:46, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 94.4M/9.99G [00:00<01:43, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   2%| | 105M/5.79G [00:01<00:57, 98\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 83.9M/9.97G [00:00<01:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 105M/9.99G [00:01<01:46, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   2%| | 115M/5.79G [00:01<00:59, 94\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 94.4M/9.97G [00:01<01:46, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 115M/9.99G [00:01<01:46, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   2%| | 126M/5.79G [00:01<01:02, 90\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 105M/9.97G [00:01<01:45, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 126M/9.99G [00:01<01:46, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   2%| | 136M/5.79G [00:01<01:04, 88\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 115M/9.97G [00:01<01:43, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 136M/9.99G [00:01<01:45, 93\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 147M/5.79G [00:01<01:02, 89\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 126M/9.97G [00:01<01:40, 97\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   1%| | 147M/9.99G [00:01<01:44, 93\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 157M/5.79G [00:01<01:03, 88\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 136M/9.97G [00:01<01:44, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 157M/9.99G [00:01<01:46, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 168M/5.79G [00:01<01:01, 91\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   1%| | 147M/9.97G [00:01<01:42, 96\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 168M/9.99G [00:01<01:47, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 178M/5.79G [00:01<01:00, 93\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 157M/9.97G [00:01<01:40, 97\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 178M/9.99G [00:01<01:52, 86\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 189M/5.79G [00:01<01:01, 91\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 168M/9.97G [00:01<01:45, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 189M/9.99G [00:02<01:54, 85\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   3%| | 199M/5.79G [00:02<01:01, 91\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 178M/9.97G [00:01<01:44, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 199M/9.99G [00:02<01:51, 87\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   4%| | 210M/5.79G [00:02<00:59, 93\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 189M/9.97G [00:02<01:43, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 210M/9.99G [00:02<01:48, 90\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   4%| | 220M/5.79G [00:02<00:59, 93\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 199M/9.97G [00:02<01:42, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 220M/9.99G [00:02<01:47, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   4%| | 231M/5.79G [00:02<00:57, 96\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 210M/9.97G [00:02<01:41, 96\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   4%| | 241M/5.79G [00:02<00:59, 92\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 220M/9.97G [00:02<01:46, 91\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   2%| | 241M/9.99G [00:02<01:48, 89\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   2%| | 231M/9.97G [00:02<01:47, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 252M/9.99G [00:02<01:46, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 262M/5.79G [00:02<00:56, 97\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 262M/9.99G [00:02<01:43, 93\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 273M/5.79G [00:02<00:56, 97\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 252M/9.97G [00:02<01:41, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 273M/9.99G [00:02<01:41, 95\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 283M/5.79G [00:02<00:56, 97\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 262M/9.97G [00:02<01:42, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 283M/9.99G [00:03<01:45, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 294M/5.79G [00:03<00:58, 93\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 273M/9.97G [00:02<01:43, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 304M/5.79G [00:03<01:00, 90\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 283M/9.97G [00:03<01:51, 86\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 304M/9.99G [00:03<01:41, 95\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   5%| | 315M/5.79G [00:03<01:03, 86\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 294M/9.97G [00:03<01:53, 85\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 315M/9.99G [00:03<01:43, 93\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   6%| | 325M/5.79G [00:03<01:04, 84\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 304M/9.97G [00:03<01:51, 86\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 325M/9.99G [00:03<01:46, 90\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   6%| | 336M/5.79G [00:03<01:01, 89\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 336M/9.99G [00:03<01:49, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 325M/9.97G [00:03<01:45, 91\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   6%| | 346M/5.79G [00:03<01:03, 85\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   3%| | 346M/9.99G [00:03<01:51, 86\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 336M/9.97G [00:03<01:43, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   6%| | 357M/5.79G [00:03<01:02, 86\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 357M/9.99G [00:03<01:50, 86\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   3%| | 346M/9.97G [00:03<01:43, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   6%| | 367M/5.79G [00:03<01:04, 84\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 367M/9.99G [00:04<01:51, 86\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 357M/9.97G [00:03<01:46, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 377M/5.79G [00:04<01:01, 88\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 377M/9.99G [00:04<01:47, 89\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 367M/9.97G [00:03<01:46, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 388M/5.79G [00:04<01:00, 89\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 388M/9.99G [00:04<01:49, 87\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 377M/9.97G [00:04<01:46, 89\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 398M/5.79G [00:04<01:00, 88\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 398M/9.99G [00:04<01:46, 89\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 388M/9.97G [00:04<01:46, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 409M/5.79G [00:04<01:00, 89\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 398M/9.97G [00:04<01:45, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 419M/5.79G [00:04<00:58, 91\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 419M/9.99G [00:04<01:41, 94\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 409M/9.97G [00:04<01:46, 89\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   7%| | 430M/5.79G [00:04<00:59, 90\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 430M/9.99G [00:04<01:44, 91\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 419M/9.97G [00:04<01:48, 87\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   8%| | 440M/5.79G [00:04<01:00, 88\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   4%| | 440M/9.99G [00:04<01:47, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 430M/9.97G [00:04<01:46, 89\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   8%| | 451M/5.79G [00:04<00:59, 90\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 451M/9.99G [00:04<01:48, 87\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   4%| | 440M/9.97G [00:04<01:51, 85\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   8%| | 461M/5.79G [00:04<01:01, 86\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 461M/9.99G [00:05<01:48, 88\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   8%| | 472M/5.79G [00:05<00:58, 90\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 451M/9.97G [00:04<01:47, 88\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 472M/9.99G [00:05<01:49, 87\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   8%| | 482M/5.79G [00:05<01:01, 86\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 461M/9.97G [00:05<01:54, 83\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 482M/9.99G [00:05<01:47, 88\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   9%| | 493M/5.79G [00:05<00:58, 90\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 472M/9.97G [00:05<01:52, 84\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 493M/9.99G [00:05<01:45, 89\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   9%| | 503M/5.79G [00:05<01:01, 86\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 482M/9.97G [00:05<01:48, 87\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 503M/9.99G [00:05<01:47, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 493M/9.97G [00:05<01:48, 87\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 514M/9.99G [00:05<01:48, 87\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   9%| | 524M/5.79G [00:05<00:58, 89\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 503M/9.97G [00:05<01:48, 87\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 524M/9.99G [00:05<01:46, 88\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   9%| | 535M/5.79G [00:05<00:56, 92\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 535M/9.99G [00:05<01:42, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:   9%| | 545M/5.79G [00:05<00:55, 95\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 524M/9.97G [00:05<01:41, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   5%| | 545M/9.99G [00:05<01:39, 94\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  10%| | 556M/5.79G [00:06<00:54, 96\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   5%| | 535M/9.97G [00:05<01:40, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 556M/9.99G [00:06<01:37, 96\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  10%| | 566M/5.79G [00:06<00:53, 97\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 566M/9.99G [00:06<01:38, 96\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  10%| | 577M/5.79G [00:06<00:53, 97\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 556M/9.97G [00:06<01:35, 98\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 577M/9.99G [00:06<01:37, 97\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  10%| | 587M/5.79G [00:06<00:53, 98\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 566M/9.97G [00:06<01:37, 97\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 587M/9.99G [00:06<01:43, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  10%| | 598M/5.79G [00:06<00:55, 94\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 577M/9.97G [00:06<01:37, 96\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 598M/9.99G [00:06<01:41, 92\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 608M/5.79G [00:06<00:55, 93\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 587M/9.97G [00:06<01:39, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 608M/9.99G [00:06<01:44, 89\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 619M/5.79G [00:06<00:56, 92\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 598M/9.97G [00:06<01:40, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 629M/5.79G [00:06<00:54, 95\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 619M/9.99G [00:06<01:45, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 608M/9.97G [00:06<01:39, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 640M/5.79G [00:06<00:54, 94\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 619M/9.97G [00:06<01:39, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 629M/9.99G [00:06<01:52, 83\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 650M/5.79G [00:06<00:53, 96\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 629M/9.97G [00:06<01:37, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   6%| | 640M/9.99G [00:07<01:47, 86\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  11%| | 661M/5.79G [00:07<00:52, 98\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   6%| | 640M/9.97G [00:06<01:35, 98\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 650M/9.99G [00:07<01:48, 86\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  12%| | 671M/5.79G [00:07<00:52, 97\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 650M/9.97G [00:07<01:35, 97\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 661M/9.99G [00:07<01:45, 88\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  12%| | 682M/5.79G [00:07<00:52, 98\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 671M/9.99G [00:07<01:44, 89\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 671M/9.97G [00:07<01:32, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 682M/9.99G [00:07<01:42, 91\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  12%| | 703M/5.79G [00:07<00:51, 99\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 692M/9.99G [00:07<01:40, 92\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 692M/9.97G [00:07<01:29, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  12%| | 713M/5.79G [00:07<00:51, 99\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 703M/9.99G [00:07<01:44, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 703M/9.97G [00:07<01:31, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 713M/9.97G [00:07<01:34, 98\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  13%|\u258f| 734M/5.79G [00:07<00:53, 94\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 713M/9.99G [00:07<01:48, 85\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 724M/9.97G [00:07<01:37, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  13%|\u258f| 744M/5.79G [00:07<00:53, 93\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 724M/9.99G [00:07<01:46, 86\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 734M/9.97G [00:07<01:37, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  13%|\u258f| 755M/5.79G [00:08<00:53, 93\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 734M/9.99G [00:08<01:44, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   7%| | 744M/9.97G [00:08<01:35, 96\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  13%|\u258f| 765M/5.79G [00:08<00:54, 92\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   7%| | 744M/9.99G [00:08<01:44, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 755M/9.97G [00:08<01:36, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  13%|\u258f| 776M/5.79G [00:08<00:53, 94\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 755M/9.99G [00:08<01:40, 91\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 765M/9.97G [00:08<01:36, 95\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 765M/9.99G [00:08<01:38, 93\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  14%|\u258f| 786M/5.79G [00:08<00:54, 92\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 776M/9.97G [00:08<01:37, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 776M/9.99G [00:08<01:36, 95\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  14%|\u258f| 797M/5.79G [00:08<00:54, 92\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 786M/9.99G [00:08<01:36, 95\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 786M/9.97G [00:08<01:40, 91\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  14%|\u258f| 807M/5.79G [00:08<00:55, 89\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 797M/9.99G [00:08<01:35, 96\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 797M/9.97G [00:08<01:37, 94\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 807M/9.97G [00:08<01:38, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  14%|\u258f| 828M/5.79G [00:08<00:53, 92\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 818M/9.99G [00:08<01:27, 10\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 818M/9.97G [00:08<01:38, 93\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  14%|\u258f| 839M/5.79G [00:09<00:54, 90\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 828M/9.99G [00:09<01:34, 96\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 828M/9.97G [00:08<01:44, 87\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  15%|\u258f| 849M/5.79G [00:09<00:57, 86\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   8%| | 839M/9.99G [00:09<01:38, 93\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   8%| | 839M/9.97G [00:09<01:42, 88\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  15%|\u258f| 860M/5.79G [00:09<00:54, 90\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 849M/9.99G [00:09<01:44, 87\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 849M/9.97G [00:09<01:38, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  15%|\u258f| 870M/5.79G [00:09<00:53, 91\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 860M/9.99G [00:09<01:41, 89\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 860M/9.97G [00:09<01:42, 89\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  15%|\u258f| 881M/5.79G [00:09<00:54, 90\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 870M/9.99G [00:09<01:39, 91\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 870M/9.97G [00:09<01:38, 92\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  15%|\u258f| 891M/5.79G [00:09<00:52, 92\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 881M/9.99G [00:09<01:42, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 881M/9.97G [00:09<01:39, 91\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  16%|\u258f| 902M/5.79G [00:09<00:55, 88\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 891M/9.99G [00:09<01:42, 88\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 891M/9.97G [00:09<01:38, 91\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  16%|\u258f| 912M/5.79G [00:09<00:57, 85\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 902M/9.97G [00:09<01:44, 86\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 902M/9.99G [00:09<01:51, 81\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  16%|\u258f| 923M/5.79G [00:10<01:00, 80\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 912M/9.97G [00:09<01:40, 90\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  16%|\u258f| 944M/5.79G [00:10<00:48, 99\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:   9%| | 933M/9.97G [00:10<01:26, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 912M/9.99G [00:10<02:39, 56\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  17%|\u258f| 965M/5.79G [00:10<00:47, 10\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 954M/9.97G [00:10<01:24, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 923M/9.99G [00:10<02:26, 61\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 933M/9.99G [00:10<02:18, 65\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  17%|\u258f| 986M/5.79G [00:10<00:48, 98\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 975M/9.97G [00:10<01:25, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:   9%| | 944M/9.99G [00:10<02:13, 68\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  17%|\u258f| 996M/5.79G [00:10<00:49, 95\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 954M/9.99G [00:10<02:06, 71\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 996M/9.97G [00:10<01:27, 10\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  17%|\u258f| 1.01G/5.79G [00:10<00:50, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 965M/9.99G [00:10<02:06, 71\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 1.02G/9.97G [00:10<01:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  18%|\u258f| 1.03G/5.79G [00:11<00:47, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 975M/9.99G [00:11<02:01, 74\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 1.03G/9.97G [00:10<01:29, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  18%|\u258f| 1.04G/5.79G [00:11<00:49, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 986M/9.99G [00:11<01:56, 77\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  10%| | 1.04G/9.97G [00:11<01:30, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  18%|\u258f| 1.05G/5.79G [00:11<00:49, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 996M/9.99G [00:11<01:55, 77\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  18%|\u258f| 1.06G/5.79G [00:11<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 1.01G/9.99G [00:11<01:49, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.06G/9.97G [00:11<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  18%|\u258f| 1.07G/5.79G [00:11<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 1.02G/9.99G [00:11<01:43, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  19%|\u258f| 1.08G/5.79G [00:11<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.08G/9.97G [00:11<01:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 1.03G/9.99G [00:11<01:39, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  19%|\u258f| 1.09G/5.79G [00:11<00:48, 9\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  19%|\u258f| 1.10G/5.79G [00:11<00:47, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.10G/9.97G [00:11<01:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  10%| | 1.05G/9.99G [00:11<01:35, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  19%|\u258f| 1.11G/5.79G [00:11<00:50, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.11G/9.97G [00:11<01:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  11%| | 1.06G/9.99G [00:11<01:33, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  19%|\u258f| 1.12G/5.79G [00:12<00:49, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.12G/9.97G [00:11<01:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  11%| | 1.07G/9.99G [00:12<01:32, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  11%| | 1.09G/9.99G [00:12<01:21, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  20%|\u258f| 1.13G/5.79G [00:12<01:13, 6\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.13G/9.97G [00:12<02:02, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  11%| | 1.11G/9.99G [00:12<01:19, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  11%| | 1.14G/9.97G [00:12<01:56, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  20%|\u258f| 1.15G/5.79G [00:12<01:00, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.15G/9.97G [00:12<01:48, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  11%| | 1.13G/9.99G [00:12<01:23, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  20%|\u258f| 1.16G/5.79G [00:12<00:59, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.16G/9.97G [00:12<01:44, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  20%|\u258f| 1.17G/5.79G [00:12<00:57, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.17G/9.97G [00:12<01:39, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.15G/9.99G [00:12<01:27, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  20%|\u258f| 1.18G/5.79G [00:12<00:54, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.18G/9.97G [00:12<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.16G/9.99G [00:12<01:30, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  21%|\u258f| 1.20G/5.79G [00:12<00:54, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.20G/9.97G [00:12<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.17G/9.99G [00:13<01:31, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  21%|\u258f| 1.21G/5.79G [00:13<00:52, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.21G/9.97G [00:12<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  21%|\u258f| 1.22G/5.79G [00:13<00:52, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.18G/9.99G [00:13<01:35, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.22G/9.97G [00:13<01:37, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  21%|\u258f| 1.23G/5.79G [00:13<00:51, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.20G/9.99G [00:13<01:37, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.23G/9.97G [00:13<01:35, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  21%|\u258f| 1.24G/5.79G [00:13<00:52, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.21G/9.99G [00:13<01:39, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  12%| | 1.24G/9.97G [00:13<01:37, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.25G/5.79G [00:13<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.22G/9.99G [00:13<01:36, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.25G/9.97G [00:13<01:35, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.23G/9.99G [00:13<01:37, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.26G/5.79G [00:13<00:52, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.26G/9.97G [00:13<01:41, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.27G/5.79G [00:13<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.24G/9.99G [00:13<01:36, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.27G/9.97G [00:13<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.28G/5.79G [00:13<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  12%| | 1.25G/9.99G [00:13<01:38, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.28G/9.97G [00:13<01:40, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.29G/5.79G [00:14<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.26G/9.99G [00:14<01:39, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.29G/9.97G [00:13<01:39, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  22%|\u258f| 1.30G/5.79G [00:14<00:51, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.27G/9.99G [00:14<01:41, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.30G/9.97G [00:14<01:40, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  23%|\u258f| 1.31G/5.79G [00:14<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.28G/9.99G [00:14<01:37, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.31G/9.97G [00:14<01:37, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  23%|\u258f| 1.32G/5.79G [00:14<00:49, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.29G/9.99G [00:14<01:36, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.32G/9.97G [00:14<01:37, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  23%|\u258f| 1.33G/5.79G [00:14<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.30G/9.99G [00:14<01:35, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.33G/9.97G [00:14<01:37, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  23%|\u258f| 1.34G/5.79G [00:14<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.31G/9.99G [00:14<01:37, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  13%|\u258f| 1.34G/9.97G [00:14<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  23%|\u258f| 1.35G/5.79G [00:14<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.32G/9.99G [00:14<01:37, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.35G/9.97G [00:14<01:36, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.36G/5.79G [00:14<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.33G/9.99G [00:14<01:36, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.36G/9.97G [00:14<01:33, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.37G/5.79G [00:14<00:47, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  13%|\u258f| 1.34G/9.99G [00:14<01:32, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.37G/9.97G [00:14<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.38G/5.79G [00:15<00:46, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.35G/9.99G [00:15<01:30, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.38G/9.97G [00:14<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.39G/5.79G [00:15<00:47, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.36G/9.99G [00:15<01:34, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.39G/9.97G [00:15<01:33, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.41G/5.79G [00:15<00:48, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.41G/9.97G [00:15<01:33, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.37G/9.99G [00:15<01:40, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  24%|\u258f| 1.42G/5.79G [00:15<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.42G/9.97G [00:15<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.38G/9.99G [00:15<01:42, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  25%|\u258f| 1.43G/5.79G [00:15<00:48, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.43G/9.97G [00:15<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.39G/9.99G [00:15<01:41, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  25%|\u258f| 1.44G/5.79G [00:15<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  14%|\u258f| 1.44G/9.97G [00:15<01:35, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.41G/9.99G [00:15<01:38, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  25%|\u258f| 1.45G/5.79G [00:15<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.45G/9.97G [00:15<01:33, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.42G/9.99G [00:15<01:39, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.46G/9.97G [00:15<01:35, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  25%|\u258e| 1.46G/5.79G [00:15<00:51, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.43G/9.99G [00:15<01:39, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.47G/9.97G [00:15<01:34, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  25%|\u258e| 1.47G/5.79G [00:16<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.44G/9.99G [00:16<01:38, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.48G/9.97G [00:15<01:33, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  26%|\u258e| 1.48G/5.79G [00:16<00:51, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  14%|\u258f| 1.45G/9.99G [00:16<01:36, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.49G/9.97G [00:16<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  26%|\u258e| 1.49G/5.79G [00:16<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.46G/9.99G [00:16<01:32, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.50G/9.97G [00:16<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.47G/9.99G [00:16<01:32, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  26%|\u258e| 1.50G/5.79G [00:16<00:50, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.51G/9.97G [00:16<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.48G/9.99G [00:16<01:33, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  26%|\u258e| 1.51G/5.79G [00:16<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.52G/9.97G [00:16<01:30, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.49G/9.99G [00:16<01:32, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  26%|\u258e| 1.52G/5.79G [00:16<00:48, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  15%|\u258f| 1.53G/9.97G [00:16<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.51G/9.99G [00:16<01:25, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  27%|\u258e| 1.54G/5.79G [00:16<00:45, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.55G/9.97G [00:16<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.52G/9.99G [00:16<01:27, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  27%|\u258e| 1.55G/5.79G [00:16<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.56G/9.97G [00:16<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.53G/9.99G [00:17<01:25, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  27%|\u258e| 1.56G/5.79G [00:17<00:43, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  15%|\u258f| 1.54G/9.99G [00:17<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  27%|\u258e| 1.57G/5.79G [00:17<00:43, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.58G/9.97G [00:17<01:21, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  27%|\u258e| 1.58G/5.79G [00:17<00:43, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.55G/9.99G [00:17<01:29, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.59G/9.97G [00:17<01:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.56G/9.99G [00:17<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.59G/5.79G [00:17<00:43, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.60G/9.97G [00:17<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.57G/9.99G [00:17<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.60G/5.79G [00:17<00:43, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.61G/9.97G [00:17<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.58G/9.99G [00:17<01:32, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.61G/5.79G [00:17<00:45, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.63G/9.97G [00:17<01:38, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.59G/9.99G [00:17<01:30, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.63G/5.79G [00:17<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  16%|\u258f| 1.64G/9.97G [00:17<01:34, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.60G/9.99G [00:17<01:30, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.64G/5.79G [00:17<00:45, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.65G/9.97G [00:17<01:33, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.61G/9.99G [00:17<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  28%|\u258e| 1.65G/5.79G [00:17<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.66G/9.97G [00:17<01:32, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.63G/9.99G [00:18<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  29%|\u258e| 1.66G/5.79G [00:18<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.67G/9.97G [00:17<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  29%|\u258e| 1.67G/5.79G [00:18<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.64G/9.99G [00:18<01:32, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.68G/9.97G [00:18<01:30, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  16%|\u258f| 1.65G/9.99G [00:18<01:31, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  29%|\u258e| 1.68G/5.79G [00:18<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.69G/9.97G [00:18<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.66G/9.99G [00:18<01:30, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  29%|\u258e| 1.69G/5.79G [00:18<00:44, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.70G/9.97G [00:18<01:30, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.67G/9.99G [00:18<01:31, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  29%|\u258e| 1.70G/5.79G [00:18<00:45, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.71G/9.97G [00:18<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.68G/9.99G [00:18<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.71G/5.79G [00:18<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.72G/9.97G [00:18<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.69G/9.99G [00:18<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.72G/5.79G [00:18<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.73G/9.97G [00:18<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.70G/9.99G [00:18<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.73G/5.79G [00:18<00:46, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  17%|\u258f| 1.74G/9.97G [00:18<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.71G/9.99G [00:18<01:27, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.74G/5.79G [00:19<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.75G/9.97G [00:18<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.72G/9.99G [00:19<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.75G/5.79G [00:19<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.76G/9.97G [00:19<01:31, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  17%|\u258f| 1.73G/9.99G [00:19<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  30%|\u258e| 1.76G/5.79G [00:19<00:51, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.78G/9.97G [00:19<01:25, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.75G/9.99G [00:19<01:26, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  31%|\u258e| 1.77G/5.79G [00:19<00:51, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.79G/9.97G [00:19<01:27, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.76G/9.99G [00:19<01:25, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  31%|\u258e| 1.78G/5.79G [00:19<00:49, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.80G/9.97G [00:19<01:26, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  31%|\u258e| 1.79G/5.79G [00:19<00:47, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.81G/9.97G [00:19<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.78G/9.99G [00:19<01:25, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  31%|\u258e| 1.80G/5.79G [00:19<00:47, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.82G/9.97G [00:19<01:27, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.79G/9.99G [00:19<01:25, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  31%|\u258e| 1.81G/5.79G [00:19<00:47, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  18%|\u258f| 1.84G/9.97G [00:19<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.80G/9.99G [00:19<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.82G/5.79G [00:20<00:47, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.85G/9.97G [00:19<01:29, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.81G/9.99G [00:20<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.84G/5.79G [00:20<00:46, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.86G/9.97G [00:20<01:30, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.82G/9.99G [00:20<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.85G/5.79G [00:20<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.87G/9.97G [00:20<01:27, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.84G/9.99G [00:20<01:26, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.86G/5.79G [00:20<00:44, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  18%|\u258f| 1.85G/9.99G [00:20<01:24, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.89G/9.97G [00:20<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.87G/5.79G [00:20<00:44, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.86G/9.99G [00:20<01:25, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.90G/9.97G [00:20<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.87G/9.99G [00:20<01:23, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  32%|\u258e| 1.88G/5.79G [00:20<00:44, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.91G/9.97G [00:20<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.88G/9.99G [00:20<01:24, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  33%|\u258e| 1.89G/5.79G [00:20<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.92G/9.97G [00:20<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.89G/9.99G [00:20<01:24, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  33%|\u258e| 1.90G/5.79G [00:20<00:44, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.93G/9.97G [00:20<01:26, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.90G/9.99G [00:20<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  33%|\u258e| 1.91G/5.79G [00:21<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  19%|\u258f| 1.94G/9.97G [00:20<01:26, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.91G/9.99G [00:21<01:29, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  33%|\u258e| 1.92G/5.79G [00:21<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 1.95G/9.97G [00:21<01:26, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.92G/9.99G [00:21<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  33%|\u258e| 1.93G/5.79G [00:21<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 1.96G/9.97G [00:21<01:28, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.93G/9.99G [00:21<01:28, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  34%|\u258e| 1.94G/5.79G [00:21<00:42, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  19%|\u258f| 1.94G/9.99G [00:21<01:25, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 1.97G/9.97G [00:21<01:37, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  34%|\u258e| 1.95G/5.79G [00:21<00:42, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 1.95G/9.99G [00:21<01:26, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  34%|\u258e| 1.97G/5.79G [00:21<00:38, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 1.98G/9.97G [00:21<02:05, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 1.97G/9.99G [00:21<01:20, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  34%|\u258e| 1.98G/5.79G [00:21<00:38, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 1.98G/9.99G [00:21<01:29, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 1.99G/9.97G [00:21<02:09, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  35%|\u258e| 2.00G/5.79G [00:21<00:36, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 2.00G/9.97G [00:21<01:58, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 1.99G/9.99G [00:22<01:34, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  35%|\u258e| 2.01G/5.79G [00:22<00:38, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 2.01G/9.97G [00:21<01:49, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 2.00G/9.99G [00:22<01:33, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  35%|\u258e| 2.02G/5.79G [00:22<00:38, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  20%|\u258f| 2.02G/9.97G [00:22<01:43, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 2.01G/9.99G [00:22<01:31, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 2.02G/9.99G [00:22<01:35, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  35%|\u258e| 2.03G/5.79G [00:22<00:56, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 2.03G/9.99G [00:22<01:38, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.04G/9.97G [00:22<01:56, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  35%|\u258e| 2.06G/5.79G [00:22<00:45, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  20%|\u258f| 2.04G/9.99G [00:22<01:46, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.07G/9.97G [00:22<01:40, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.06G/9.99G [00:22<01:46, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  36%|\u258e| 2.08G/5.79G [00:22<00:41, 9\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  36%|\u258e| 2.09G/5.79G [00:22<00:40, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.07G/9.99G [00:22<01:44, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.09G/9.97G [00:22<01:30, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.08G/9.99G [00:23<01:36, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  36%|\u258e| 2.10G/5.79G [00:23<00:40, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.10G/9.97G [00:22<01:28, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  36%|\u258e| 2.11G/5.79G [00:23<00:41, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.11G/9.97G [00:23<01:27, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.09G/9.99G [00:23<01:44, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.12G/5.79G [00:23<00:39, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.10G/9.99G [00:23<01:44, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.13G/5.79G [00:23<00:39, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.13G/9.97G [00:23<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.11G/9.99G [00:23<01:40, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  21%|\u258f| 2.14G/9.97G [00:23<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.14G/5.79G [00:23<00:39, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.12G/9.99G [00:23<01:40, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.15G/5.79G [00:23<00:39, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.16G/9.97G [00:23<01:21, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.13G/9.99G [00:23<01:36, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.16G/5.79G [00:23<00:40, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.17G/9.97G [00:23<01:20, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  21%|\u258f| 2.14G/9.99G [00:23<01:35, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  37%|\u258e| 2.17G/5.79G [00:23<00:41, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.18G/9.97G [00:23<01:26, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.15G/9.99G [00:24<01:38, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  38%|\u258d| 2.18G/5.79G [00:24<00:42, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.19G/9.97G [00:23<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.16G/9.99G [00:24<01:34, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  38%|\u258d| 2.19G/5.79G [00:24<00:40, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.20G/9.97G [00:24<01:24, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.17G/9.99G [00:24<01:31, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  38%|\u258d| 2.20G/5.79G [00:24<00:40, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.21G/9.97G [00:24<01:21, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.18G/9.99G [00:24<01:30, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  38%|\u258d| 2.21G/5.79G [00:24<00:39, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.22G/9.97G [00:24<01:21, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  38%|\u258d| 2.22G/5.79G [00:24<00:38, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  22%|\u258f| 2.23G/9.97G [00:24<01:19, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.20G/9.99G [00:24<01:23, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.23G/5.79G [00:24<00:37, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  23%|\u258f| 2.25G/9.97G [00:24<01:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.24G/5.79G [00:24<00:39, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.22G/9.99G [00:24<01:17, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.25G/5.79G [00:24<00:43, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  23%|\u258f| 2.28G/9.97G [00:24<01:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  22%|\u258f| 2.24G/9.99G [00:24<01:19, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.26G/5.79G [00:25<00:48, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  23%|\u258f| 2.30G/9.97G [00:24<01:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.26G/9.99G [00:25<01:15, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.28G/5.79G [00:25<00:46, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.28G/9.99G [00:25<01:17, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  23%|\u258f| 2.32G/9.97G [00:25<01:13, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  39%|\u258d| 2.29G/5.79G [00:25<00:45, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.29G/9.99G [00:25<01:18, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  40%|\u258d| 2.30G/5.79G [00:25<00:45, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.30G/9.99G [00:25<01:21, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  23%|\u258f| 2.34G/9.97G [00:25<01:20, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  40%|\u258d| 2.31G/5.79G [00:25<00:43, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.31G/9.99G [00:25<01:24, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.35G/9.97G [00:25<01:22, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  40%|\u258d| 2.32G/5.79G [00:25<00:42, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.32G/9.99G [00:25<01:24, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.36G/9.97G [00:25<01:22, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  40%|\u258d| 2.33G/5.79G [00:25<00:42, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.33G/9.99G [00:25<01:25, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.37G/9.97G [00:25<01:21, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  40%|\u258d| 2.34G/5.79G [00:25<00:43, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  23%|\u258f| 2.34G/9.99G [00:26<01:26, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.38G/9.97G [00:25<01:26, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.35G/5.79G [00:26<00:40, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.35G/9.99G [00:26<01:25, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.39G/9.97G [00:25<01:26, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.36G/5.79G [00:26<00:39, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.36G/9.99G [00:26<01:23, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.40G/9.97G [00:26<01:24, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.37G/5.79G [00:26<00:38, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.37G/9.99G [00:26<01:25, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.41G/9.97G [00:26<01:22, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.38G/5.79G [00:26<00:42, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.38G/9.99G [00:26<01:24, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.42G/9.97G [00:26<01:23, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.39G/5.79G [00:26<00:40, 8\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  41%|\u258d| 2.40G/5.79G [00:26<00:38, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.40G/9.99G [00:26<01:18, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  42%|\u258d| 2.41G/5.79G [00:26<00:37, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.41G/9.99G [00:26<01:17, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  24%|\u258f| 2.43G/9.97G [00:26<01:57, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.42G/9.99G [00:26<01:17, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  42%|\u258d| 2.42G/5.79G [00:26<00:37, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258f| 2.44G/9.97G [00:26<01:48, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.43G/9.99G [00:27<01:29, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  42%|\u258d| 2.43G/5.79G [00:27<00:41, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258f| 2.45G/9.97G [00:26<01:49, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258f| 2.46G/9.97G [00:26<01:39, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  24%|\u258f| 2.44G/9.99G [00:27<01:28, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  42%|\u258d| 2.44G/5.79G [00:27<00:41, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258f| 2.47G/9.97G [00:27<01:36, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  42%|\u258d| 2.45G/5.79G [00:27<00:40, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258f| 2.45G/9.99G [00:27<01:30, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258f| 2.49G/9.97G [00:27<01:30, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258f| 2.46G/9.99G [00:27<01:25, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  43%|\u258d| 2.46G/5.79G [00:27<00:39, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258f| 2.47G/9.99G [00:27<01:22, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258e| 2.50G/9.97G [00:27<01:30, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258f| 2.49G/9.99G [00:27<01:21, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  43%|\u258d| 2.49G/5.79G [00:27<00:36, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258e| 2.51G/9.97G [00:27<01:27, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258f| 2.50G/9.99G [00:27<01:23, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  43%|\u258d| 2.50G/5.79G [00:27<00:36, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258e| 2.52G/9.97G [00:27<01:27, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258e| 2.51G/9.99G [00:27<01:20, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258e| 2.53G/9.97G [00:27<01:27, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  43%|\u258d| 2.52G/5.79G [00:27<00:34, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258e| 2.53G/9.99G [00:28<01:14, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  44%|\u258d| 2.53G/5.79G [00:28<00:35, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  25%|\u258e| 2.54G/9.97G [00:27<01:53, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  44%|\u258d| 2.55G/5.79G [00:28<00:30, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.55G/9.97G [00:28<01:44, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  25%|\u258e| 2.54G/9.99G [00:28<01:44, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.56G/9.97G [00:28<01:34, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  44%|\u258d| 2.57G/5.79G [00:28<00:29, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.55G/9.99G [00:28<01:45, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  45%|\u258d| 2.59G/5.79G [00:28<00:29, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.57G/9.99G [00:28<01:28, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.58G/9.97G [00:28<01:46, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.58G/9.99G [00:28<01:26, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  45%|\u258d| 2.61G/5.79G [00:28<00:30, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.60G/9.97G [00:28<01:32, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  45%|\u258d| 2.62G/5.79G [00:28<00:30, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.60G/9.99G [00:28<01:19, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.61G/9.97G [00:28<01:29, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  45%|\u258d| 2.63G/5.79G [00:29<00:30, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.61G/9.99G [00:29<01:22, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.62G/9.97G [00:28<01:26, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  46%|\u258d| 2.64G/5.79G [00:29<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.62G/9.99G [00:29<01:23, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.63G/9.97G [00:29<01:26, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  46%|\u258d| 2.65G/5.79G [00:29<00:33, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.63G/9.99G [00:29<01:23, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  26%|\u258e| 2.64G/9.97G [00:29<01:24, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  46%|\u258d| 2.66G/5.79G [00:29<00:34, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  26%|\u258e| 2.64G/9.99G [00:29<01:20, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.65G/9.97G [00:29<01:20, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  46%|\u258d| 2.67G/5.79G [00:29<00:33, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.65G/9.99G [00:29<01:17, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.66G/9.97G [00:29<01:19, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  46%|\u258d| 2.68G/5.79G [00:29<00:33, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.66G/9.99G [00:29<01:17, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.69G/5.79G [00:29<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.68G/9.97G [00:29<01:14, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.71G/5.79G [00:29<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.69G/9.97G [00:29<01:14, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.68G/9.99G [00:29<01:17, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.72G/5.79G [00:29<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.71G/9.97G [00:29<01:14, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.69G/9.99G [00:30<01:23, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.73G/5.79G [00:30<00:31, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.72G/9.97G [00:29<01:15, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.71G/9.99G [00:30<01:25, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.74G/5.79G [00:30<00:33, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.73G/9.97G [00:30<01:17, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.72G/9.99G [00:30<01:24, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  47%|\u258d| 2.75G/5.79G [00:30<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  27%|\u258e| 2.74G/9.97G [00:30<01:16, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.73G/9.99G [00:30<01:21, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  48%|\u258d| 2.76G/5.79G [00:30<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.75G/9.97G [00:30<01:16, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  27%|\u258e| 2.74G/9.99G [00:30<01:17, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  48%|\u258d| 2.77G/5.79G [00:30<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.76G/9.97G [00:30<01:15, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.75G/9.99G [00:30<01:18, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  48%|\u258d| 2.78G/5.79G [00:30<00:31, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.77G/9.97G [00:30<01:14, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.76G/9.99G [00:30<01:17, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.78G/9.97G [00:30<01:16, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.77G/9.99G [00:30<01:21, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  48%|\u258d| 2.80G/5.79G [00:30<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.79G/9.97G [00:30<01:21, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.78G/9.99G [00:30<01:18, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.81G/5.79G [00:30<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.80G/9.97G [00:30<01:19, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.79G/9.99G [00:31<01:20, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.82G/5.79G [00:31<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.81G/9.97G [00:30<01:18, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.80G/9.99G [00:31<01:19, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.83G/5.79G [00:31<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.82G/9.97G [00:31<01:18, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.81G/9.99G [00:31<01:19, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.84G/5.79G [00:31<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.83G/9.97G [00:31<01:17, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.82G/9.99G [00:31<01:18, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.85G/5.79G [00:31<00:32, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  28%|\u258e| 2.84G/9.97G [00:31<01:19, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.83G/9.99G [00:31<01:15, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  49%|\u258d| 2.86G/5.79G [00:31<00:31, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  28%|\u258e| 2.84G/9.99G [00:31<01:16, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.86G/9.97G [00:31<01:12, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  50%|\u258d| 2.87G/5.79G [00:31<00:31, 9\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  50%|\u258d| 2.88G/5.79G [00:31<00:33, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  29%|\u258e| 2.86G/9.99G [00:31<01:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.88G/9.97G [00:31<01:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  50%|\u258d| 2.89G/5.79G [00:31<00:32, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  29%|\u258e| 2.88G/9.99G [00:31<01:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.90G/9.97G [00:31<01:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  50%|\u258c| 2.92G/5.79G [00:32<00:28, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.92G/9.97G [00:31<01:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  29%|\u258e| 2.90G/9.99G [00:32<01:05, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  51%|\u258c| 2.93G/5.79G [00:32<00:30, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.93G/9.97G [00:32<01:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  51%|\u258c| 2.94G/5.79G [00:32<00:29, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  29%|\u258e| 2.94G/9.97G [00:32<01:11, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  29%|\u258e| 2.93G/9.99G [00:32<01:11, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  51%|\u258c| 2.95G/5.79G [00:32<00:30, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  30%|\u258e| 2.95G/9.99G [00:32<01:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 2.95G/9.97G [00:32<01:45, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  51%|\u258c| 2.96G/5.79G [00:32<00:44, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  30%|\u258e| 2.97G/9.99G [00:32<01:03, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  51%|\u258c| 2.98G/5.79G [00:32<00:36, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  30%|\u258e| 2.99G/9.99G [00:32<01:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 2.96G/9.97G [00:32<02:24, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  52%|\u258c| 3.00G/5.79G [00:33<00:31, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  30%|\u258e| 3.01G/9.99G [00:33<01:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 2.97G/9.97G [00:33<02:28, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  52%|\u258c| 3.02G/5.79G [00:33<00:30, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  30%|\u258e| 3.03G/9.99G [00:33<01:05, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 2.98G/9.97G [00:33<02:35, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  53%|\u258c| 3.04G/5.79G [00:33<00:29, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.05G/9.99G [00:33<01:08, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  53%|\u258c| 3.06G/5.79G [00:33<00:28, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.07G/9.99G [00:33<01:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 2.99G/9.97G [00:33<02:54, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  53%|\u258c| 3.08G/5.79G [00:33<00:26, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 3.00G/9.97G [00:33<02:26, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.09G/9.99G [00:34<01:09, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  53%|\u258c| 3.09G/5.79G [00:34<00:26, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.10G/9.99G [00:34<01:12, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  54%|\u258c| 3.11G/5.79G [00:34<00:23, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 3.01G/9.97G [00:34<02:31, 4\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.11G/9.99G [00:34<01:19, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  54%|\u258c| 3.14G/5.79G [00:34<00:23, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.12G/9.99G [00:34<01:20, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 3.03G/9.97G [00:34<01:52, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  30%|\u258e| 3.04G/9.97G [00:34<01:41, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.14G/9.99G [00:34<01:19, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  55%|\u258c| 3.16G/5.79G [00:34<00:24, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  31%|\u258e| 3.15G/9.99G [00:34<01:16, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.05G/9.97G [00:34<01:37, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.16G/9.99G [00:34<01:13, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.06G/9.97G [00:34<01:33, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  55%|\u258c| 3.18G/5.79G [00:34<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.17G/9.99G [00:34<01:13, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.07G/9.97G [00:34<01:27, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  55%|\u258c| 3.19G/5.79G [00:34<00:27, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.18G/9.99G [00:35<01:13, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  55%|\u258c| 3.21G/5.79G [00:35<00:25, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.20G/9.99G [00:35<01:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.08G/9.97G [00:35<01:57, 5\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  56%|\u258c| 3.22G/5.79G [00:35<00:25, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.21G/9.99G [00:35<01:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.09G/9.97G [00:35<01:44, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  56%|\u258c| 3.23G/5.79G [00:35<00:25, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.22G/9.99G [00:35<01:10, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.10G/9.97G [00:35<01:34, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  56%|\u258c| 3.24G/5.79G [00:35<00:25, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.23G/9.99G [00:35<01:09, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.11G/9.97G [00:35<01:28, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  56%|\u258c| 3.25G/5.79G [00:35<00:25, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  32%|\u258e| 3.24G/9.99G [00:35<01:09, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.12G/9.97G [00:35<01:24, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  56%|\u258c| 3.26G/5.79G [00:35<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.25G/9.99G [00:35<01:12, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  31%|\u258e| 3.14G/9.97G [00:35<01:21, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.27G/5.79G [00:35<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.26G/9.99G [00:35<01:12, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.15G/9.97G [00:35<01:18, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.28G/5.79G [00:35<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.27G/9.99G [00:35<01:14, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.16G/9.97G [00:35<01:16, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.29G/5.79G [00:36<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.28G/9.99G [00:36<01:13, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.17G/9.97G [00:35<01:13, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.30G/5.79G [00:36<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.29G/9.99G [00:36<01:13, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.18G/9.97G [00:36<01:12, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.31G/5.79G [00:36<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.30G/9.99G [00:36<01:11, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.19G/9.97G [00:36<01:12, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  57%|\u258c| 3.32G/5.79G [00:36<00:25, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.31G/9.99G [00:36<01:15, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  58%|\u258c| 3.33G/5.79G [00:36<00:24, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.20G/9.97G [00:36<01:23, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.32G/9.99G [00:36<01:14, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  58%|\u258c| 3.34G/5.79G [00:36<00:25, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.21G/9.97G [00:36<01:20, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.33G/9.99G [00:36<01:13, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  58%|\u258c| 3.36G/5.79G [00:36<00:26, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.22G/9.97G [00:36<01:19, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  33%|\u258e| 3.34G/9.99G [00:36<01:10, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  58%|\u258c| 3.37G/5.79G [00:36<00:25, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.23G/9.97G [00:36<01:42, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.37G/9.99G [00:36<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  58%|\u258c| 3.39G/5.79G [00:37<00:24, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  32%|\u258e| 3.24G/9.97G [00:36<01:34, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  59%|\u258c| 3.40G/5.79G [00:37<00:24, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.38G/9.99G [00:37<01:13, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.25G/9.97G [00:37<01:30, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  59%|\u258c| 3.41G/5.79G [00:37<00:24, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.39G/9.99G [00:37<01:15, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.26G/9.97G [00:37<01:23, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  59%|\u258c| 3.42G/5.79G [00:37<00:24, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.40G/9.99G [00:37<01:14, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.27G/9.97G [00:37<01:27, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  59%|\u258c| 3.44G/5.79G [00:37<00:22, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.42G/9.99G [00:37<01:09, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.28G/9.97G [00:37<01:24, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  60%|\u258c| 3.45G/5.79G [00:37<00:22, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.43G/9.99G [00:37<01:08, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.29G/9.97G [00:37<01:19, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  60%|\u258c| 3.46G/5.79G [00:37<00:22, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  34%|\u258e| 3.44G/9.99G [00:37<01:08, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.30G/9.97G [00:37<01:16, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  60%|\u258c| 3.47G/5.79G [00:37<00:22, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.45G/9.99G [00:37<01:07, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.31G/9.97G [00:37<01:14, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  60%|\u258c| 3.48G/5.79G [00:37<00:23, 9\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  60%|\u258c| 3.49G/5.79G [00:38<00:23, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  33%|\u258e| 3.32G/9.97G [00:37<01:21, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  61%|\u258c| 3.51G/5.79G [00:38<00:19, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.34G/9.97G [00:38<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.47G/9.99G [00:38<01:33, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.36G/9.97G [00:38<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  61%|\u258c| 3.53G/5.79G [00:38<00:18, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.48G/9.99G [00:38<01:28, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.37G/9.97G [00:38<01:11, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.49G/9.99G [00:38<01:25, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.38G/9.97G [00:38<01:10, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  61%|\u258c| 3.55G/5.79G [00:38<00:21, 1\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.51G/9.99G [00:38<01:12, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.40G/9.97G [00:38<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.53G/9.99G [00:38<01:05, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  35%|\u258e| 3.54G/9.99G [00:39<01:04, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.42G/9.97G [00:38<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  62%|\u258c| 3.58G/5.79G [00:39<00:29, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.55G/9.99G [00:39<01:05, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.43G/9.97G [00:38<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  62%|\u258c| 3.59G/5.79G [00:39<00:28, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.57G/9.99G [00:39<01:05, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  34%|\u258e| 3.44G/9.97G [00:39<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  62%|\u258c| 3.60G/5.79G [00:39<00:27, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.58G/9.99G [00:39<01:06, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.45G/9.97G [00:39<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  62%|\u258c| 3.61G/5.79G [00:39<00:25, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.59G/9.99G [00:39<01:06, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.46G/9.97G [00:39<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  62%|\u258c| 3.62G/5.79G [00:39<00:25, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.47G/9.97G [00:39<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.60G/9.99G [00:39<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  63%|\u258b| 3.63G/5.79G [00:39<00:24, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.48G/9.97G [00:39<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.61G/9.99G [00:39<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  63%|\u258b| 3.64G/5.79G [00:39<00:23, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.49G/9.97G [00:39<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.62G/9.99G [00:39<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  63%|\u258b| 3.65G/5.79G [00:39<00:23, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.50G/9.97G [00:39<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.63G/9.99G [00:39<01:06, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  63%|\u258b| 3.66G/5.79G [00:39<00:23, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.51G/9.97G [00:39<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  36%|\u258e| 3.64G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  63%|\u258b| 3.67G/5.79G [00:40<00:24, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.52G/9.97G [00:39<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.65G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.68G/5.79G [00:40<00:23, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  35%|\u258e| 3.53G/9.97G [00:40<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.66G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.69G/5.79G [00:40<00:23, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.54G/9.97G [00:40<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.67G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.70G/5.79G [00:40<00:23, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.55G/9.97G [00:40<01:06, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.68G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.71G/5.79G [00:40<00:22, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.57G/9.97G [00:40<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.69G/9.99G [00:40<01:06, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.72G/5.79G [00:40<00:22, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.58G/9.97G [00:40<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.70G/9.99G [00:40<01:04, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  64%|\u258b| 3.73G/5.79G [00:40<00:22, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.59G/9.97G [00:40<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.71G/9.99G [00:40<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  65%|\u258b| 3.74G/5.79G [00:40<00:22, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.60G/9.97G [00:40<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.72G/9.99G [00:40<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  65%|\u258b| 3.75G/5.79G [00:40<00:21, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.61G/9.97G [00:40<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.73G/9.99G [00:41<01:07, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  65%|\u258b| 3.76G/5.79G [00:41<00:21, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.62G/9.97G [00:40<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  37%|\u258e| 3.74G/9.99G [00:41<01:11, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  65%|\u258b| 3.77G/5.79G [00:41<00:22, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.63G/9.97G [00:41<01:11, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.75G/9.99G [00:41<01:10, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  65%|\u258b| 3.79G/5.79G [00:41<00:22, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  36%|\u258e| 3.64G/9.97G [00:41<01:09, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.76G/9.99G [00:41<01:08, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.65G/9.97G [00:41<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  66%|\u258b| 3.80G/5.79G [00:41<00:22, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.77G/9.99G [00:41<01:10, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.66G/9.97G [00:41<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  66%|\u258b| 3.81G/5.79G [00:41<00:22, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.79G/9.99G [00:41<01:09, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  66%|\u258b| 3.83G/5.79G [00:41<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.81G/9.99G [00:41<01:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.67G/9.97G [00:41<01:40, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.82G/9.99G [00:41<01:00, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  66%|\u258b| 3.85G/5.79G [00:41<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.68G/9.97G [00:41<01:31, 6\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.83G/9.99G [00:42<01:02, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  38%|\u258d| 3.84G/9.99G [00:42<01:02, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.69G/9.97G [00:41<01:27, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  67%|\u258b| 3.87G/5.79G [00:42<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.85G/9.99G [00:42<01:02, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.70G/9.97G [00:42<01:20, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  67%|\u258b| 3.88G/5.79G [00:42<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.71G/9.97G [00:42<01:16, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.86G/9.99G [00:42<01:06, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  67%|\u258b| 3.89G/5.79G [00:42<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.72G/9.97G [00:42<01:13, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.87G/9.99G [00:42<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  67%|\u258b| 3.90G/5.79G [00:42<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  37%|\u258e| 3.73G/9.97G [00:42<01:10, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.88G/9.99G [00:42<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.91G/5.79G [00:42<00:20, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.74G/9.97G [00:42<01:08, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.92G/5.79G [00:42<00:20, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.75G/9.97G [00:42<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.90G/9.99G [00:42<01:02, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.93G/5.79G [00:42<00:20, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.76G/9.97G [00:42<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.91G/9.99G [00:42<01:03, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.94G/5.79G [00:42<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.77G/9.97G [00:42<01:07, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.92G/9.99G [00:43<01:03, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.95G/5.79G [00:43<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.79G/9.97G [00:42<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.93G/9.99G [00:43<01:06, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  68%|\u258b| 3.96G/5.79G [00:43<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.80G/9.97G [00:43<01:04, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  39%|\u258d| 3.94G/9.99G [00:43<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  69%|\u258b| 3.97G/5.79G [00:43<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.81G/9.97G [00:43<01:05, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 3.95G/9.99G [00:43<01:04, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  69%|\u258b| 3.98G/5.79G [00:43<00:20, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  38%|\u258d| 3.83G/9.97G [00:43<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  69%|\u258b| 4.00G/5.79G [00:43<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 3.97G/9.99G [00:43<01:01, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  69%|\u258b| 4.01G/5.79G [00:43<00:19, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 3.98G/9.99G [00:43<01:01, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.85G/9.97G [00:43<00:59, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.86G/9.97G [00:43<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.03G/5.79G [00:43<00:18, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 4.01G/9.99G [00:43<01:02, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.87G/9.97G [00:43<01:02, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.04G/5.79G [00:43<00:18, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 4.02G/9.99G [00:43<01:01, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.88G/9.97G [00:43<01:03, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 4.03G/9.99G [00:44<01:05, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.89G/9.97G [00:43<01:02, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.05G/5.79G [00:44<00:23, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  40%|\u258d| 4.04G/9.99G [00:44<01:03, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.05G/9.99G [00:44<01:05, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.91G/9.97G [00:44<00:59, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.06G/5.79G [00:44<00:26, 6\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.92G/9.97G [00:44<01:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.06G/9.99G [00:44<01:07, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.07G/5.79G [00:44<00:24, 6\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  39%|\u258d| 3.93G/9.97G [00:44<01:02, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.07G/9.99G [00:44<01:07, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  70%|\u258b| 4.08G/5.79G [00:44<00:22, 7\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 3.94G/9.97G [00:44<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.08G/9.99G [00:44<01:05, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  71%|\u258b| 4.09G/5.79G [00:44<00:21, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 3.95G/9.97G [00:44<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.09G/9.99G [00:44<01:07, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  71%|\u258b| 4.10G/5.79G [00:44<00:19, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 3.96G/9.97G [00:44<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.10G/9.99G [00:44<01:05, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  71%|\u258b| 4.11G/5.79G [00:44<00:19, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 3.97G/9.97G [00:44<01:02, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.11G/9.99G [00:45<01:05, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  71%|\u258b| 4.12G/5.79G [00:45<00:18, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 3.98G/9.97G [00:44<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  71%|\u258b| 4.13G/5.79G [00:45<00:17, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.12G/9.99G [00:45<01:12, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 4.00G/9.97G [00:45<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  72%|\u258b| 4.14G/5.79G [00:45<00:17, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.13G/9.99G [00:45<01:09, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  72%|\u258b| 4.15G/5.79G [00:45<00:17, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 4.02G/9.97G [00:45<00:59, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  72%|\u258b| 4.16G/5.79G [00:45<00:18, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  40%|\u258d| 4.04G/9.97G [00:45<00:51, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  41%|\u258d| 4.14G/9.99G [00:45<01:41, 5\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  72%|\u258b| 4.17G/5.79G [00:45<00:17, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.06G/9.97G [00:45<00:52, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  72%|\u258b| 4.19G/5.79G [00:45<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.15G/9.99G [00:45<01:49, 5\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.08G/9.97G [00:45<00:54, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  73%|\u258b| 4.20G/5.79G [00:45<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.16G/9.99G [00:46<01:37, 5\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.17G/9.99G [00:46<01:29, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.10G/9.97G [00:46<00:56, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  73%|\u258b| 4.23G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.18G/9.99G [00:46<01:23, 6\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  73%|\u258b| 4.24G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.11G/9.97G [00:46<00:58, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.19G/9.99G [00:46<01:21, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.12G/9.97G [00:46<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  73%|\u258b| 4.25G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  41%|\u258d| 4.13G/9.97G [00:46<00:58, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.20G/9.99G [00:46<01:18, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.26G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.14G/9.97G [00:46<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.22G/9.99G [00:46<01:11, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.27G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.23G/9.99G [00:46<01:09, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.15G/9.97G [00:46<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.28G/5.79G [00:46<00:16, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  42%|\u258d| 4.24G/9.99G [00:46<01:09, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.16G/9.97G [00:46<01:04, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.29G/5.79G [00:46<00:18, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.25G/9.99G [00:47<01:11, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.17G/9.97G [00:46<01:07, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.30G/5.79G [00:47<00:18, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.26G/9.99G [00:47<01:08, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.18G/9.97G [00:46<01:05, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  74%|\u258b| 4.31G/5.79G [00:47<00:17, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.19G/9.97G [00:47<01:03, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  75%|\u258b| 4.32G/5.79G [00:47<00:16, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.28G/9.99G [00:47<01:00, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.20G/9.97G [00:47<01:01, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  75%|\u258b| 4.33G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.29G/9.99G [00:47<01:01, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.22G/9.97G [00:47<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  75%|\u258b| 4.34G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.30G/9.99G [00:47<01:01, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.23G/9.97G [00:47<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  75%|\u258a| 4.35G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.31G/9.99G [00:47<01:00, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  42%|\u258d| 4.24G/9.97G [00:47<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  75%|\u258a| 4.36G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.32G/9.99G [00:47<01:00, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.25G/9.97G [00:47<00:58, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.37G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.26G/9.97G [00:47<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.33G/9.99G [00:47<01:01, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.38G/5.79G [00:47<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.27G/9.97G [00:47<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  43%|\u258d| 4.34G/9.99G [00:48<01:00, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.39G/5.79G [00:48<00:14, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.28G/9.97G [00:47<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.35G/9.99G [00:48<01:00, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.40G/5.79G [00:48<00:15, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.29G/9.97G [00:48<01:05, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.36G/9.99G [00:48<01:06, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.41G/5.79G [00:48<00:17, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.30G/9.97G [00:48<01:08, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  76%|\u258a| 4.42G/5.79G [00:48<00:17, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.31G/9.97G [00:48<01:09, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  77%|\u258a| 4.44G/5.79G [00:48<00:16, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.37G/9.99G [00:48<01:41, 5\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.32G/9.97G [00:48<01:08, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  77%|\u258a| 4.45G/5.79G [00:48<00:15, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  43%|\u258d| 4.33G/9.97G [00:48<01:08, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.39G/9.99G [00:48<01:18, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  77%|\u258a| 4.46G/5.79G [00:48<00:15, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.34G/9.97G [00:48<01:06, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.40G/9.99G [00:48<01:14, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  77%|\u258a| 4.47G/5.79G [00:48<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.35G/9.97G [00:48<01:06, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.41G/9.99G [00:49<01:10, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  77%|\u258a| 4.48G/5.79G [00:49<00:14, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.36G/9.97G [00:48<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.42G/9.99G [00:49<01:08, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.49G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.37G/9.97G [00:49<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  44%|\u258d| 4.44G/9.99G [00:49<01:05, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.50G/5.79G [00:49<00:15, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.38G/9.97G [00:49<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.45G/9.99G [00:49<01:02, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.51G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.39G/9.97G [00:49<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.46G/9.99G [00:49<01:01, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.52G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.40G/9.97G [00:49<01:00, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.47G/9.99G [00:49<01:01, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.53G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.48G/9.99G [00:49<00:59, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.41G/9.97G [00:49<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  78%|\u258a| 4.54G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.49G/9.99G [00:49<00:58, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.42G/9.97G [00:49<01:02, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  79%|\u258a| 4.55G/5.79G [00:49<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.50G/9.99G [00:49<00:58, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  44%|\u258d| 4.44G/9.97G [00:49<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  79%|\u258a| 4.56G/5.79G [00:50<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.51G/9.99G [00:50<01:01, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.45G/9.97G [00:49<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.52G/9.99G [00:50<00:59, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  79%|\u258a| 4.57G/5.79G [00:50<00:14, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.46G/9.97G [00:50<01:03, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.53G/9.99G [00:50<00:59, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  79%|\u258a| 4.58G/5.79G [00:50<00:13, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.47G/9.97G [00:50<01:01, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  45%|\u258d| 4.54G/9.99G [00:50<00:58, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  79%|\u258a| 4.59G/5.79G [00:50<00:13, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.48G/9.97G [00:50<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  46%|\u258d| 4.56G/9.99G [00:50<00:53, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.50G/9.97G [00:50<00:53, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  46%|\u258d| 4.58G/9.99G [00:50<00:47, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  80%|\u258a| 4.60G/5.79G [00:50<00:24, 4\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  45%|\u258d| 4.52G/9.97G [00:50<00:59, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  46%|\u258d| 4.60G/9.99G [00:50<00:46, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  80%|\u258a| 4.61G/5.79G [00:50<00:21, 5\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.54G/9.97G [00:50<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  80%|\u258a| 4.62G/5.79G [00:51<00:18, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  46%|\u258d| 4.62G/9.99G [00:51<00:48, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  80%|\u258a| 4.63G/5.79G [00:51<00:16, 6\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.56G/9.97G [00:51<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  80%|\u258a| 4.65G/5.79G [00:51<00:15, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.65G/9.99G [00:51<00:50, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.57G/9.97G [00:51<01:01, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.67G/9.99G [00:51<00:50, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  81%|\u258a| 4.67G/5.79G [00:51<00:13, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.58G/9.97G [00:51<01:02, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  81%|\u258a| 4.68G/5.79G [00:51<00:13, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.59G/9.97G [00:51<01:02, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.69G/9.99G [00:51<00:52, 1\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  81%|\u258a| 4.69G/5.79G [00:51<00:12, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.60G/9.97G [00:51<01:01, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.70G/9.99G [00:51<00:58, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  81%|\u258a| 4.70G/5.79G [00:51<00:13, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.61G/9.97G [00:51<01:05, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.71G/9.99G [00:52<00:58, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.72G/5.79G [00:52<00:11, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  46%|\u258d| 4.63G/9.97G [00:51<00:58, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  47%|\u258d| 4.73G/9.99G [00:52<00:55, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.73G/5.79G [00:52<00:11, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.65G/9.97G [00:52<00:57, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.74G/5.79G [00:52<00:11, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.66G/9.97G [00:52<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.75G/9.99G [00:52<00:52, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.75G/5.79G [00:52<00:11, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.67G/9.97G [00:52<00:54, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.76G/9.99G [00:52<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.76G/5.79G [00:52<00:11, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.68G/9.97G [00:52<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.77G/9.99G [00:52<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  82%|\u258a| 4.77G/5.79G [00:52<00:11, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.69G/9.97G [00:52<00:56, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.78G/9.99G [00:52<00:53, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.78G/5.79G [00:52<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.70G/9.97G [00:52<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.79G/9.99G [00:52<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.79G/5.79G [00:52<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.71G/9.97G [00:52<00:54, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.80G/9.99G [00:52<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.80G/5.79G [00:53<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.72G/9.97G [00:52<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.81G/9.99G [00:53<00:56, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.81G/5.79G [00:53<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  47%|\u258d| 4.73G/9.97G [00:52<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.74G/9.97G [00:53<00:54, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.82G/9.99G [00:53<00:56, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.82G/5.79G [00:53<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  48%|\u258d| 4.83G/9.99G [00:53<00:56, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.75G/9.97G [00:53<00:57, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  83%|\u258a| 4.83G/5.79G [00:53<00:11, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.84G/9.99G [00:53<00:57, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.76G/9.97G [00:53<00:59, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  84%|\u258a| 4.84G/5.79G [00:53<00:10, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.85G/9.99G [00:53<00:56, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.77G/9.97G [00:53<00:59, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  84%|\u258a| 4.85G/5.79G [00:53<00:10, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.87G/9.99G [00:53<00:57, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.78G/9.97G [00:53<00:57, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  84%|\u258a| 4.87G/5.79G [00:53<00:10, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.88G/9.99G [00:53<00:55, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.79G/9.97G [00:53<00:56, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.89G/9.99G [00:53<00:53, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  84%|\u258a| 4.89G/5.79G [00:53<00:09, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.80G/9.97G [00:53<00:55, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  85%|\u258a| 4.90G/5.79G [00:54<00:09, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.90G/9.99G [00:54<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  85%|\u258a| 4.91G/5.79G [00:54<00:09, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.91G/9.99G [00:54<00:53, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.82G/9.97G [00:53<00:54, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  48%|\u258d| 4.83G/9.97G [00:54<00:53, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  85%|\u258a| 4.92G/5.79G [00:54<00:09, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.92G/9.99G [00:54<00:55, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.93G/9.99G [00:54<00:53, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.85G/9.97G [00:54<00:49, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  49%|\u258d| 4.94G/9.99G [00:54<00:52, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  85%|\u258a| 4.93G/5.79G [00:54<00:13, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258d| 4.96G/9.99G [00:54<00:47, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.87G/9.97G [00:54<01:10, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  85%|\u258a| 4.95G/5.79G [00:54<00:11, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258d| 4.97G/9.99G [00:54<00:51, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.88G/9.97G [00:54<01:06, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  86%|\u258a| 4.96G/5.79G [00:54<00:10, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258d| 4.98G/9.99G [00:54<00:52, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.89G/9.97G [00:54<01:03, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  86%|\u258a| 4.97G/5.79G [00:54<00:10, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258d| 4.99G/9.99G [00:55<00:54, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.90G/9.97G [00:54<01:01, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  86%|\u258a| 4.98G/5.79G [00:55<00:09, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.91G/9.97G [00:54<00:58, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  86%|\u258a| 4.99G/5.79G [00:55<00:09, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258c| 5.01G/9.99G [00:55<00:51, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.92G/9.97G [00:55<00:56, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  86%|\u258a| 5.00G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258c| 5.02G/9.99G [00:55<00:52, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  49%|\u258d| 4.93G/9.97G [00:55<00:53, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  50%|\u258c| 5.03G/9.99G [00:55<00:51, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.01G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258d| 4.94G/9.97G [00:55<00:53, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.04G/9.99G [00:55<00:52, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.02G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258d| 4.95G/9.97G [00:55<00:57, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.03G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.05G/9.99G [00:55<00:54, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258d| 4.96G/9.97G [00:55<00:56, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.06G/9.99G [00:55<00:53, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.04G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258d| 4.97G/9.97G [00:55<00:57, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.08G/9.99G [00:55<00:52, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.05G/5.79G [00:55<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258d| 4.98G/9.97G [00:55<00:56, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.09G/9.99G [00:56<00:54, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  87%|\u258a| 5.06G/5.79G [00:56<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258c| 4.99G/9.97G [00:55<00:57, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.10G/9.99G [00:56<00:53, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  88%|\u2589| 5.08G/5.79G [00:56<00:08, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258c| 5.00G/9.97G [00:56<00:55, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.11G/9.99G [00:56<00:55, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  88%|\u2589| 5.09G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258c| 5.01G/9.97G [00:56<00:54, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.12G/9.99G [00:56<00:54, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  88%|\u2589| 5.10G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258c| 5.02G/9.97G [00:56<00:55, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.13G/9.99G [00:56<00:54, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  88%|\u2589| 5.11G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  50%|\u258c| 5.03G/9.97G [00:56<00:56, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  51%|\u258c| 5.14G/9.99G [00:56<00:52, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  88%|\u2589| 5.12G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.04G/9.97G [00:56<00:57, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.15G/9.99G [00:56<00:53, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  89%|\u2589| 5.13G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.05G/9.97G [00:56<00:56, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.16G/9.99G [00:56<00:53, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  89%|\u2589| 5.14G/5.79G [00:56<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.06G/9.97G [00:56<00:54, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.17G/9.99G [00:56<00:53, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  89%|\u2589| 5.15G/5.79G [00:57<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.08G/9.97G [00:56<00:54, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.18G/9.99G [00:57<00:58, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  89%|\u2589| 5.16G/5.79G [00:57<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.09G/9.97G [00:56<00:52, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.10G/9.97G [00:57<00:51, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  89%|\u2589| 5.17G/5.79G [00:57<00:07, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.19G/9.99G [00:57<01:11, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.12G/9.97G [00:57<00:48, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  90%|\u2589| 5.19G/5.79G [00:57<00:06, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.20G/9.99G [00:57<01:12, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  51%|\u258c| 5.13G/9.97G [00:57<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  90%|\u2589| 5.20G/5.79G [00:57<00:06, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.21G/9.99G [00:57<01:05, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.14G/9.97G [00:57<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  90%|\u2589| 5.21G/5.79G [00:57<00:06, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.22G/9.99G [00:57<01:07, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.16G/9.97G [00:57<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  90%|\u2589| 5.23G/5.79G [00:57<00:05, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.23G/9.99G [00:57<01:10, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.17G/9.97G [00:57<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.24G/5.79G [00:58<00:05, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  52%|\u258c| 5.24G/9.99G [00:58<01:13, 6\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.25G/5.79G [00:58<00:05, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.19G/9.97G [00:58<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.26G/5.79G [00:58<00:05, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.25G/9.99G [00:58<01:09, 6\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.20G/9.97G [00:58<00:51, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.27G/5.79G [00:58<00:05, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.26G/9.99G [00:58<01:05, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.21G/9.97G [00:58<00:53, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.27G/9.99G [00:58<01:02, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.28G/5.79G [00:58<00:06, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.22G/9.97G [00:58<00:53, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.28G/9.99G [00:58<00:59, 7\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  91%|\u2589| 5.30G/5.79G [00:58<00:06, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  52%|\u258c| 5.23G/9.97G [00:58<00:52, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.30G/9.99G [00:58<00:55, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.31G/9.99G [00:58<00:53, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.25G/9.97G [00:58<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  92%|\u2589| 5.31G/5.79G [00:58<00:07, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.32G/9.99G [00:58<00:54, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.26G/9.97G [00:58<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  92%|\u2589| 5.32G/5.79G [00:59<00:06, 6\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.33G/9.99G [00:59<00:52, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.27G/9.97G [00:58<00:50, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  92%|\u2589| 5.33G/5.79G [00:59<00:06, 7\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  53%|\u258c| 5.34G/9.99G [00:59<00:53, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.28G/9.97G [00:59<00:50, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  92%|\u2589| 5.34G/5.79G [00:59<00:05, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.35G/9.99G [00:59<00:52, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.30G/9.97G [00:59<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  92%|\u2589| 5.35G/5.79G [00:59<00:05, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.36G/9.99G [00:59<00:53, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.31G/9.97G [00:59<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.36G/5.79G [00:59<00:05, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.37G/9.99G [00:59<00:51, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.32G/9.97G [00:59<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.37G/5.79G [00:59<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.38G/9.99G [00:59<00:50, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  53%|\u258c| 5.33G/9.97G [00:59<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.38G/5.79G [00:59<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.39G/9.99G [00:59<00:49, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.34G/9.97G [00:59<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.39G/5.79G [00:59<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.40G/9.99G [00:59<00:50, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.35G/9.97G [00:59<00:51, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.40G/5.79G [00:59<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.41G/9.99G [01:00<00:50, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.36G/9.97G [00:59<00:51, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  93%|\u2589| 5.41G/5.79G [01:00<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.42G/9.99G [01:00<00:51, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.37G/9.97G [00:59<00:51, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  94%|\u2589| 5.42G/5.79G [01:00<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.43G/9.99G [01:00<00:51, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.38G/9.97G [01:00<00:52, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  94%|\u2589| 5.43G/5.79G [01:00<00:04, 8\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  54%|\u258c| 5.44G/9.99G [01:00<00:53, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.39G/9.97G [01:00<00:50, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  94%|\u2589| 5.44G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.40G/9.97G [01:00<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.45G/9.99G [01:00<00:52, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  94%|\u2589| 5.45G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.41G/9.97G [01:00<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.46G/9.99G [01:00<00:51, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  94%|\u2589| 5.46G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.42G/9.97G [01:00<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.47G/9.99G [01:00<00:50, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.47G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  54%|\u258c| 5.43G/9.97G [01:00<00:49, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.48G/9.99G [01:00<00:50, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.48G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.44G/9.97G [01:00<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.49G/9.99G [01:00<00:49, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.49G/5.79G [01:00<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.45G/9.97G [01:00<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.51G/9.99G [01:01<00:49, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.51G/5.79G [01:01<00:03, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.46G/9.97G [01:01<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.52G/9.99G [01:01<00:48, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.52G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.53G/9.99G [01:01<00:47, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.47G/9.97G [01:01<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  95%|\u2589| 5.53G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.48G/9.97G [01:01<00:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  55%|\u258c| 5.54G/9.99G [01:01<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  96%|\u2589| 5.54G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.55G/9.99G [01:01<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  96%|\u2589| 5.55G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.51G/9.97G [01:01<00:45, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.56G/9.99G [01:01<00:47, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  96%|\u2589| 5.56G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  96%|\u2589| 5.57G/5.79G [01:01<00:02, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  55%|\u258c| 5.53G/9.97G [01:01<00:43, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.58G/9.99G [01:01<00:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  97%|\u2589| 5.59G/5.79G [01:01<00:01, 1\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.54G/9.97G [01:01<00:52, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.60G/9.99G [01:02<00:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  97%|\u2589| 5.60G/5.79G [01:02<00:01, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.55G/9.97G [01:01<00:52, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.61G/9.99G [01:02<00:45, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  97%|\u2589| 5.61G/5.79G [01:02<00:01, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.56G/9.97G [01:02<00:59, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.63G/9.99G [01:02<00:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  97%|\u2589| 5.63G/5.79G [01:02<00:01, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.57G/9.97G [01:02<00:58, 7\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  56%|\u258c| 5.64G/9.99G [01:02<00:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  97%|\u2589| 5.64G/5.79G [01:02<00:01, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.58G/9.97G [01:02<00:54, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.65G/9.99G [01:02<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  98%|\u2589| 5.65G/5.79G [01:02<00:01, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.59G/9.97G [01:02<00:53, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.66G/9.99G [01:02<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  98%|\u2589| 5.66G/5.79G [01:02<00:01, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.60G/9.97G [01:02<00:51, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.67G/9.99G [01:02<00:45, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  98%|\u2589| 5.67G/5.79G [01:02<00:01, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.61G/9.97G [01:02<00:51, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.68G/9.99G [01:02<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  98%|\u2589| 5.68G/5.79G [01:03<00:01, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.62G/9.97G [01:02<00:50, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.69G/9.99G [01:03<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  98%|\u2589| 5.69G/5.79G [01:03<00:01, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  56%|\u258c| 5.63G/9.97G [01:02<00:48, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.70G/9.99G [01:03<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.70G/5.79G [01:03<00:00, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.64G/9.97G [01:03<00:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.71G/9.99G [01:03<00:44, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.71G/5.79G [01:03<00:00, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.65G/9.97G [01:03<00:48, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.73G/9.99G [01:03<00:46, 9\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.73G/5.79G [01:03<00:00, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.66G/9.97G [01:03<00:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  57%|\u258c| 5.74G/9.99G [01:03<00:47, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.74G/5.79G [01:03<00:00, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.67G/9.97G [01:03<00:46, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.75G/9.99G [01:03<00:47, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.75G/5.79G [01:03<00:00, 9\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.68G/9.97G [01:03<00:46, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.76G/9.99G [01:03<00:47, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors:  99%|\u2589| 5.76G/5.79G [01:03<00:00, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.69G/9.97G [01:03<00:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.77G/9.99G [01:03<00:46, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors: 100%|\u2589| 5.77G/5.79G [01:03<00:00, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.70G/9.97G [01:03<00:47, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.78G/9.99G [01:03<00:48, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors: 100%|\u2589| 5.78G/5.79G [01:04<00:00, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.71G/9.97G [01:03<00:49, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.79G/9.99G [01:04<00:47, 8\u001b[A\u001b[A\r\n",
            "\r(\u2026)pytorch_model-00003-of-00003.safetensors: 100%|\u2589| 5.79G/5.79G [01:04<00:00, 8\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  57%|\u258c| 5.73G/9.97G [01:04<00:47, 8\u001b[A\u001b[A\u001b[A\r(\u2026)pytorch_model-00003-of-00003.safetensors: 100%|\u2588| 5.79G/5.79G [01:04<00:00, 9\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.80G/9.99G [01:04<00:46, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  58%|\u258c| 5.75G/9.97G [01:04<00:42, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.82G/9.99G [01:04<00:40, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  58%|\u258c| 5.76G/9.97G [01:04<00:42, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  58%|\u258c| 5.78G/9.97G [01:04<00:36, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  58%|\u258c| 5.83G/9.99G [01:04<00:56, 7\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  59%|\u258c| 5.85G/9.99G [01:04<00:45, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  59%|\u258c| 5.87G/9.99G [01:04<00:38, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  58%|\u258c| 5.80G/9.97G [01:04<00:50, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  59%|\u258c| 5.89G/9.99G [01:05<00:37, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  58%|\u258c| 5.82G/9.97G [01:04<00:44, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  59%|\u258c| 5.91G/9.99G [01:05<00:35, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  59%|\u258c| 5.84G/9.97G [01:05<00:41, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  59%|\u258c| 5.93G/9.99G [01:05<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  59%|\u258c| 5.86G/9.97G [01:05<00:38, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  60%|\u258c| 5.96G/9.99G [01:05<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  59%|\u258c| 5.88G/9.97G [01:05<00:37, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  60%|\u258c| 5.98G/9.99G [01:05<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  59%|\u258c| 5.90G/9.97G [01:05<00:37, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  60%|\u258c| 6.00G/9.99G [01:06<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  59%|\u258c| 5.92G/9.97G [01:05<00:37, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  60%|\u258c| 6.02G/9.99G [01:06<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  60%|\u258c| 5.95G/9.97G [01:06<00:36, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  60%|\u258c| 6.04G/9.99G [01:06<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  60%|\u258c| 5.97G/9.97G [01:06<00:35, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  61%|\u258c| 6.06G/9.99G [01:06<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  60%|\u258c| 5.99G/9.97G [01:06<00:34, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  61%|\u258c| 6.08G/9.99G [01:06<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  60%|\u258c| 6.01G/9.97G [01:06<00:34, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  61%|\u258c| 6.10G/9.99G [01:06<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  60%|\u258c| 6.03G/9.97G [01:06<00:33, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  61%|\u258c| 6.12G/9.99G [01:07<00:32, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  61%|\u258c| 6.05G/9.97G [01:06<00:33, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  62%|\u258c| 6.14G/9.99G [01:07<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  61%|\u258c| 6.07G/9.97G [01:07<00:33, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  62%|\u258c| 6.17G/9.99G [01:07<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  61%|\u258c| 6.09G/9.97G [01:07<00:32, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  62%|\u258c| 6.19G/9.99G [01:07<00:32, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  61%|\u258c| 6.11G/9.97G [01:07<00:33, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  62%|\u258c| 6.21G/9.99G [01:07<00:31, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  62%|\u258c| 6.13G/9.97G [01:07<00:32, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  62%|\u258c| 6.23G/9.99G [01:07<00:32, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  62%|\u258c| 6.16G/9.97G [01:07<00:32, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  62%|\u258c| 6.18G/9.97G [01:08<00:30, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  63%|\u258b| 6.25G/9.99G [01:08<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  62%|\u258c| 6.20G/9.97G [01:08<00:30, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  63%|\u258b| 6.27G/9.99G [01:08<00:35, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  62%|\u258c| 6.22G/9.97G [01:08<00:29, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  63%|\u258b| 6.29G/9.99G [01:08<00:34, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  63%|\u258b| 6.24G/9.97G [01:08<00:29, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  63%|\u258b| 6.26G/9.97G [01:08<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  63%|\u258b| 6.31G/9.99G [01:08<00:41, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  63%|\u258b| 6.28G/9.97G [01:08<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  63%|\u258b| 6.30G/9.97G [01:08<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  63%|\u258b| 6.33G/9.99G [01:09<00:38, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  63%|\u258b| 6.32G/9.97G [01:09<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.34G/9.99G [01:09<00:41, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.35G/9.99G [01:09<00:41, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  64%|\u258b| 6.34G/9.97G [01:09<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.36G/9.99G [01:09<00:40, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  64%|\u258b| 6.36G/9.97G [01:09<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.39G/9.99G [01:09<00:37, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  64%|\u258b| 6.39G/9.97G [01:09<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  64%|\u258b| 6.41G/9.97G [01:09<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.41G/9.99G [01:09<00:36, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.42G/9.99G [01:10<00:35, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  64%|\u258b| 6.43G/9.97G [01:09<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  64%|\u258b| 6.44G/9.99G [01:10<00:33, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  65%|\u258b| 6.45G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  65%|\u258b| 6.46G/9.99G [01:10<00:32, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  65%|\u258b| 6.47G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  65%|\u258b| 6.48G/9.99G [01:10<00:31, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  65%|\u258b| 6.49G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  65%|\u258b| 6.50G/9.99G [01:10<00:30, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  65%|\u258b| 6.51G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  65%|\u258b| 6.52G/9.99G [01:10<00:29, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  66%|\u258b| 6.53G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  66%|\u258b| 6.54G/9.99G [01:11<00:29, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  66%|\u258b| 6.55G/9.97G [01:10<00:28, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  66%|\u258b| 6.56G/9.99G [01:11<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  66%|\u258b| 6.57G/9.97G [01:11<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  66%|\u258b| 6.59G/9.99G [01:11<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  66%|\u258b| 6.60G/9.97G [01:11<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  66%|\u258b| 6.61G/9.99G [01:11<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  66%|\u258b| 6.62G/9.97G [01:11<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  66%|\u258b| 6.63G/9.99G [01:11<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  67%|\u258b| 6.64G/9.97G [01:11<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  67%|\u258b| 6.65G/9.99G [01:11<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  67%|\u258b| 6.66G/9.97G [01:11<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  67%|\u258b| 6.67G/9.99G [01:12<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  67%|\u258b| 6.68G/9.97G [01:12<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  67%|\u258b| 6.69G/9.99G [01:12<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  67%|\u258b| 6.70G/9.97G [01:12<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  67%|\u258b| 6.71G/9.99G [01:12<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  67%|\u258b| 6.72G/9.97G [01:12<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  67%|\u258b| 6.73G/9.99G [01:12<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  68%|\u258b| 6.74G/9.97G [01:12<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  68%|\u258b| 6.75G/9.99G [01:12<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  68%|\u258b| 6.76G/9.97G [01:12<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  68%|\u258b| 6.77G/9.99G [01:13<00:28, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  68%|\u258b| 6.78G/9.97G [01:12<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  68%|\u258b| 6.79G/9.99G [01:13<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  68%|\u258b| 6.81G/9.97G [01:13<00:27, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  68%|\u258b| 6.82G/9.99G [01:13<00:27, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  68%|\u258b| 6.83G/9.97G [01:13<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  68%|\u258b| 6.84G/9.99G [01:13<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  69%|\u258b| 6.85G/9.97G [01:13<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  69%|\u258b| 6.86G/9.99G [01:13<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  69%|\u258b| 6.87G/9.97G [01:13<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  69%|\u258b| 6.88G/9.99G [01:13<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  69%|\u258b| 6.89G/9.97G [01:13<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  69%|\u258b| 6.90G/9.99G [01:14<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  69%|\u258b| 6.91G/9.97G [01:13<00:26, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  69%|\u258b| 6.92G/9.99G [01:14<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  70%|\u258b| 6.93G/9.97G [01:14<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  70%|\u258b| 6.94G/9.99G [01:14<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  70%|\u258b| 6.95G/9.97G [01:14<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  70%|\u258b| 6.96G/9.99G [01:14<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  70%|\u258b| 6.97G/9.97G [01:14<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  70%|\u258b| 6.98G/9.99G [01:14<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  70%|\u258b| 6.99G/9.97G [01:14<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  70%|\u258b| 7.01G/9.97G [01:14<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  70%|\u258b| 7.00G/9.99G [01:15<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  71%|\u258b| 7.04G/9.97G [01:15<00:25, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  70%|\u258b| 7.03G/9.99G [01:15<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  71%|\u258b| 7.06G/9.97G [01:15<00:24, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  71%|\u258b| 7.05G/9.99G [01:15<00:26, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  71%|\u258b| 7.08G/9.97G [01:15<00:24, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  71%|\u258b| 7.07G/9.99G [01:15<00:25, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  71%|\u258b| 7.10G/9.97G [01:15<00:24, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  71%|\u258b| 7.09G/9.99G [01:15<00:25, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  71%|\u258b| 7.12G/9.97G [01:15<00:24, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  71%|\u258b| 7.11G/9.99G [01:15<00:25, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  72%|\u258b| 7.14G/9.97G [01:15<00:23, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  71%|\u258b| 7.13G/9.99G [01:16<00:24, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  72%|\u258b| 7.16G/9.97G [01:16<00:23, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  72%|\u258b| 7.15G/9.99G [01:16<00:24, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  72%|\u258b| 7.18G/9.97G [01:16<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  72%|\u258b| 7.17G/9.99G [01:16<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  72%|\u258b| 7.20G/9.97G [01:16<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  72%|\u258b| 7.19G/9.99G [01:16<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  72%|\u258b| 7.22G/9.97G [01:16<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  72%|\u258b| 7.21G/9.99G [01:16<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  73%|\u258b| 7.25G/9.97G [01:16<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  72%|\u258b| 7.24G/9.99G [01:17<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  73%|\u258b| 7.27G/9.97G [01:16<00:23, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  73%|\u258b| 7.26G/9.99G [01:17<00:25, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  73%|\u258b| 7.29G/9.97G [01:17<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  73%|\u258b| 7.28G/9.99G [01:17<00:24, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  73%|\u258b| 7.31G/9.97G [01:17<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  73%|\u258b| 7.30G/9.99G [01:17<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  74%|\u258b| 7.33G/9.97G [01:17<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  73%|\u258b| 7.32G/9.99G [01:17<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  74%|\u258b| 7.35G/9.97G [01:17<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  73%|\u258b| 7.34G/9.99G [01:17<00:23, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  74%|\u258b| 7.37G/9.97G [01:17<00:22, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  74%|\u258b| 7.36G/9.99G [01:18<00:22, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  74%|\u258b| 7.39G/9.97G [01:18<00:21, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  74%|\u258b| 7.38G/9.99G [01:18<00:22, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  74%|\u258b| 7.41G/9.97G [01:18<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  74%|\u258b| 7.40G/9.99G [01:18<00:22, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  75%|\u258b| 7.43G/9.97G [01:18<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  74%|\u258b| 7.42G/9.99G [01:18<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  75%|\u258b| 7.46G/9.97G [01:18<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  75%|\u258b| 7.44G/9.99G [01:18<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  75%|\u258b| 7.48G/9.97G [01:18<00:21, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  75%|\u258b| 7.47G/9.99G [01:19<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  75%|\u258a| 7.50G/9.97G [01:18<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  75%|\u258b| 7.49G/9.99G [01:19<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  75%|\u258a| 7.52G/9.97G [01:19<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  75%|\u258a| 7.51G/9.99G [01:19<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  76%|\u258a| 7.54G/9.97G [01:19<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  75%|\u258a| 7.53G/9.99G [01:19<00:20, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  76%|\u258a| 7.56G/9.97G [01:19<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.55G/9.99G [01:19<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  76%|\u258a| 7.58G/9.97G [01:19<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.57G/9.99G [01:19<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  76%|\u258a| 7.60G/9.97G [01:19<00:20, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  76%|\u258a| 7.62G/9.97G [01:19<00:19, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.59G/9.99G [01:20<00:25, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  77%|\u258a| 7.64G/9.97G [01:20<00:18, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.60G/9.99G [01:20<00:25, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  77%|\u258a| 7.67G/9.97G [01:20<00:18, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.61G/9.99G [01:20<00:26, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  77%|\u258a| 7.69G/9.97G [01:20<00:18, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  76%|\u258a| 7.63G/9.99G [01:20<00:24, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  77%|\u258a| 7.71G/9.97G [01:20<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  77%|\u258a| 7.64G/9.99G [01:20<00:26, 8\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  77%|\u258a| 7.73G/9.97G [01:20<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  77%|\u258a| 7.67G/9.99G [01:21<00:25, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  78%|\u258a| 7.75G/9.97G [01:20<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  77%|\u258a| 7.69G/9.99G [01:21<00:22, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  78%|\u258a| 7.77G/9.97G [01:21<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  77%|\u258a| 7.71G/9.99G [01:21<00:23, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  78%|\u258a| 7.79G/9.97G [01:21<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  78%|\u258a| 7.81G/9.97G [01:21<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  77%|\u258a| 7.73G/9.99G [01:21<00:23, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  79%|\u258a| 7.83G/9.97G [01:21<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  78%|\u258a| 7.75G/9.99G [01:21<00:21, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  79%|\u258a| 7.85G/9.97G [01:21<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  78%|\u258a| 7.77G/9.99G [01:22<00:20, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  79%|\u258a| 7.87G/9.97G [01:22<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  78%|\u258a| 7.79G/9.99G [01:22<00:19, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  79%|\u258a| 7.90G/9.97G [01:22<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  78%|\u258a| 7.81G/9.99G [01:22<00:19, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  79%|\u258a| 7.92G/9.97G [01:22<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  78%|\u258a| 7.83G/9.99G [01:22<00:18, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  80%|\u258a| 7.94G/9.97G [01:22<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  79%|\u258a| 7.85G/9.99G [01:22<00:18, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  80%|\u258a| 7.96G/9.97G [01:22<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  79%|\u258a| 7.87G/9.99G [01:22<00:18, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  80%|\u258a| 7.98G/9.97G [01:22<00:16, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  79%|\u258a| 7.90G/9.99G [01:23<00:17, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  80%|\u258a| 8.00G/9.97G [01:23<00:16, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  79%|\u258a| 7.92G/9.99G [01:23<00:17, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  80%|\u258a| 8.02G/9.97G [01:23<00:16, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  79%|\u258a| 7.94G/9.99G [01:23<00:17, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  81%|\u258a| 8.04G/9.97G [01:23<00:15, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  80%|\u258a| 7.96G/9.99G [01:23<00:17, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  80%|\u258a| 7.98G/9.99G [01:23<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  80%|\u258a| 8.00G/9.99G [01:23<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  81%|\u258a| 8.06G/9.97G [01:23<00:21, 8\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  80%|\u258a| 8.02G/9.99G [01:24<00:16, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  81%|\u258a| 8.08G/9.97G [01:23<00:19, 9\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  81%|\u258a| 8.11G/9.97G [01:24<00:17, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  81%|\u258a| 8.13G/9.97G [01:24<00:15, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  81%|\u258a| 8.04G/9.99G [01:24<00:21, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  82%|\u258a| 8.15G/9.97G [01:24<00:15, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  81%|\u258a| 8.06G/9.99G [01:24<00:19, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  82%|\u258a| 8.17G/9.97G [01:24<00:15, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  81%|\u258a| 8.08G/9.99G [01:24<00:18, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  82%|\u258a| 8.19G/9.97G [01:24<00:15, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  81%|\u258a| 8.11G/9.99G [01:25<00:17, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  82%|\u258a| 8.21G/9.97G [01:24<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  81%|\u258a| 8.13G/9.99G [01:25<00:16, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  83%|\u258a| 8.23G/9.97G [01:25<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  82%|\u258a| 8.15G/9.99G [01:25<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  83%|\u258a| 8.25G/9.97G [01:25<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  82%|\u258a| 8.17G/9.99G [01:25<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  83%|\u258a| 8.27G/9.97G [01:25<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  82%|\u258a| 8.19G/9.99G [01:25<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  83%|\u258a| 8.29G/9.97G [01:25<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  82%|\u258a| 8.21G/9.99G [01:25<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  83%|\u258a| 8.32G/9.97G [01:25<00:14, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  82%|\u258a| 8.23G/9.99G [01:26<00:15, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  84%|\u258a| 8.34G/9.97G [01:26<00:13, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  83%|\u258a| 8.25G/9.99G [01:26<00:14, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  84%|\u258a| 8.36G/9.97G [01:26<00:13, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  83%|\u258a| 8.27G/9.99G [01:26<00:14, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  84%|\u258a| 8.38G/9.97G [01:26<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  83%|\u258a| 8.29G/9.99G [01:26<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  84%|\u258a| 8.40G/9.97G [01:26<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  83%|\u258a| 8.32G/9.99G [01:26<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  84%|\u258a| 8.42G/9.97G [01:26<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  83%|\u258a| 8.34G/9.99G [01:26<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  85%|\u258a| 8.44G/9.97G [01:26<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  84%|\u258a| 8.36G/9.99G [01:27<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  85%|\u258a| 8.46G/9.97G [01:27<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  84%|\u258a| 8.38G/9.99G [01:27<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  85%|\u258a| 8.48G/9.97G [01:27<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  84%|\u258a| 8.40G/9.99G [01:27<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  85%|\u258a| 8.50G/9.97G [01:27<00:12, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  84%|\u258a| 8.42G/9.99G [01:27<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  85%|\u258a| 8.52G/9.97G [01:27<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  85%|\u258a| 8.44G/9.99G [01:27<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  86%|\u258a| 8.55G/9.97G [01:27<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  85%|\u258a| 8.46G/9.99G [01:27<00:13, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  86%|\u258a| 8.57G/9.97G [01:27<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  85%|\u258a| 8.48G/9.99G [01:28<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  86%|\u258a| 8.59G/9.97G [01:28<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  85%|\u258a| 8.50G/9.99G [01:28<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  86%|\u258a| 8.61G/9.97G [01:28<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  85%|\u258a| 8.52G/9.99G [01:28<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  87%|\u258a| 8.63G/9.97G [01:28<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  86%|\u258a| 8.55G/9.99G [01:28<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  87%|\u258a| 8.65G/9.97G [01:28<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  86%|\u258a| 8.57G/9.99G [01:28<00:12, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  87%|\u258a| 8.67G/9.97G [01:28<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  86%|\u258a| 8.59G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  87%|\u258a| 8.69G/9.97G [01:28<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  86%|\u258a| 8.61G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  87%|\u258a| 8.71G/9.97G [01:29<00:11, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  86%|\u258a| 8.63G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  88%|\u2589| 8.73G/9.97G [01:29<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  87%|\u258a| 8.65G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  88%|\u2589| 8.76G/9.97G [01:29<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  87%|\u258a| 8.67G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  88%|\u2589| 8.78G/9.97G [01:29<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  87%|\u258a| 8.69G/9.99G [01:29<00:11, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  88%|\u2589| 8.80G/9.97G [01:29<00:10, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  87%|\u258a| 8.71G/9.99G [01:30<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  88%|\u2589| 8.82G/9.97G [01:30<00:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  87%|\u258a| 8.73G/9.99G [01:30<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  89%|\u2589| 8.84G/9.97G [01:30<00:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  88%|\u2589| 8.76G/9.99G [01:30<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  89%|\u2589| 8.86G/9.97G [01:30<00:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  88%|\u2589| 8.78G/9.99G [01:30<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  89%|\u2589| 8.88G/9.97G [01:30<00:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  88%|\u2589| 8.80G/9.99G [01:30<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  89%|\u2589| 8.90G/9.97G [01:30<00:09, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  88%|\u2589| 8.82G/9.99G [01:31<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  89%|\u2589| 8.92G/9.97G [01:30<00:08, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  89%|\u2589| 8.84G/9.99G [01:31<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  90%|\u2589| 8.94G/9.97G [01:31<00:08, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  89%|\u2589| 8.86G/9.99G [01:31<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  90%|\u2589| 8.97G/9.97G [01:31<00:08, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  89%|\u2589| 8.88G/9.99G [01:31<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  90%|\u2589| 8.99G/9.97G [01:31<00:08, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  89%|\u2589| 8.90G/9.99G [01:31<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  90%|\u2589| 9.01G/9.97G [01:31<00:08, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  89%|\u2589| 8.92G/9.99G [01:31<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  91%|\u2589| 9.03G/9.97G [01:31<00:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  91%|\u2589| 9.05G/9.97G [01:31<00:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  90%|\u2589| 8.94G/9.99G [01:32<00:10, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  91%|\u2589| 9.07G/9.97G [01:32<00:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  90%|\u2589| 8.97G/9.99G [01:32<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  91%|\u2589| 9.09G/9.97G [01:32<00:07, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  90%|\u2589| 8.99G/9.99G [01:32<00:10, 9\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  91%|\u2589| 9.11G/9.97G [01:32<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  90%|\u2589| 9.01G/9.99G [01:32<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  92%|\u2589| 9.13G/9.97G [01:32<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  90%|\u2589| 9.03G/9.99G [01:33<00:09, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  92%|\u2589| 9.15G/9.97G [01:32<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  91%|\u2589| 9.05G/9.99G [01:33<00:08, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  92%|\u2589| 9.18G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  91%|\u2589| 9.07G/9.99G [01:33<00:08, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  92%|\u2589| 9.20G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  91%|\u2589| 9.09G/9.99G [01:33<00:08, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  92%|\u2589| 9.22G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  93%|\u2589| 9.24G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  91%|\u2589| 9.11G/9.99G [01:33<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  93%|\u2589| 9.26G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  91%|\u2589| 9.13G/9.99G [01:33<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  93%|\u2589| 9.28G/9.97G [01:33<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  92%|\u2589| 9.15G/9.99G [01:34<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  92%|\u2589| 9.18G/9.99G [01:34<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  93%|\u2589| 9.30G/9.97G [01:34<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  92%|\u2589| 9.20G/9.99G [01:34<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  93%|\u2589| 9.32G/9.97G [01:34<00:06, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  94%|\u2589| 9.34G/9.97G [01:34<00:05, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  92%|\u2589| 9.22G/9.99G [01:34<00:07, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  94%|\u2589| 9.36G/9.97G [01:34<00:05, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  92%|\u2589| 9.24G/9.99G [01:34<00:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  94%|\u2589| 9.38G/9.97G [01:34<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  93%|\u2589| 9.26G/9.99G [01:35<00:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  94%|\u2589| 9.41G/9.97G [01:35<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  93%|\u2589| 9.28G/9.99G [01:35<00:06, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  95%|\u2589| 9.43G/9.97G [01:35<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  93%|\u2589| 9.30G/9.99G [01:35<00:05, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  95%|\u2589| 9.45G/9.97G [01:35<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  93%|\u2589| 9.32G/9.99G [01:35<00:05, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  95%|\u2589| 9.47G/9.97G [01:35<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  94%|\u2589| 9.34G/9.99G [01:35<00:05, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  95%|\u2589| 9.49G/9.97G [01:35<00:04, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  94%|\u2589| 9.36G/9.99G [01:35<00:05, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  95%|\u2589| 9.51G/9.97G [01:35<00:03, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  94%|\u2589| 9.38G/9.99G [01:36<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  96%|\u2589| 9.53G/9.97G [01:36<00:03, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  94%|\u2589| 9.41G/9.99G [01:36<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  96%|\u2589| 9.55G/9.97G [01:36<00:03, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  94%|\u2589| 9.43G/9.99G [01:36<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  96%|\u2589| 9.57G/9.97G [01:36<00:03, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  95%|\u2589| 9.45G/9.99G [01:36<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  96%|\u2589| 9.59G/9.97G [01:36<00:03, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  95%|\u2589| 9.47G/9.99G [01:36<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  96%|\u2589| 9.62G/9.97G [01:36<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  95%|\u2589| 9.49G/9.99G [01:37<00:04, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  97%|\u2589| 9.64G/9.97G [01:36<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  95%|\u2589| 9.51G/9.99G [01:37<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  97%|\u2589| 9.66G/9.97G [01:37<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  95%|\u2589| 9.53G/9.99G [01:37<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  97%|\u2589| 9.68G/9.97G [01:37<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  96%|\u2589| 9.55G/9.99G [01:37<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  97%|\u2589| 9.70G/9.97G [01:37<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  96%|\u2589| 9.57G/9.99G [01:37<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  97%|\u2589| 9.72G/9.97G [01:37<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  96%|\u2589| 9.59G/9.99G [01:37<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  98%|\u2589| 9.74G/9.97G [01:37<00:02, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  96%|\u2589| 9.62G/9.99G [01:38<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  98%|\u2589| 9.76G/9.97G [01:38<00:01, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  96%|\u2589| 9.64G/9.99G [01:38<00:03, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  98%|\u2589| 9.78G/9.97G [01:38<00:01, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  97%|\u2589| 9.66G/9.99G [01:38<00:02, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  98%|\u2589| 9.80G/9.97G [01:38<00:01, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  97%|\u2589| 9.68G/9.99G [01:38<00:02, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  99%|\u2589| 9.83G/9.97G [01:38<00:01, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  97%|\u2589| 9.70G/9.99G [01:38<00:02, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  99%|\u2589| 9.85G/9.97G [01:38<00:01, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  97%|\u2589| 9.72G/9.99G [01:38<00:02, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  99%|\u2589| 9.87G/9.97G [01:38<00:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  98%|\u2589| 9.74G/9.99G [01:39<00:02, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  99%|\u2589| 9.89G/9.97G [01:39<00:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  98%|\u2589| 9.76G/9.99G [01:39<00:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors:  99%|\u2589| 9.91G/9.97G [01:39<00:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  98%|\u2589| 9.78G/9.99G [01:39<00:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors: 100%|\u2589| 9.93G/9.97G [01:39<00:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  98%|\u2589| 9.80G/9.99G [01:39<00:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors: 100%|\u2589| 9.95G/9.97G [01:39<00:00, 1\u001b[A\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  98%|\u2589| 9.83G/9.99G [01:39<00:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00001-of-00003.safetensors: 100%|\u2589| 9.97G/9.97G [01:39<00:00, 1\u001b[A\u001b[A\u001b[A\r(\u2026)pytorch_model-00001-of-00003.safetensors: 100%|\u2588| 9.97G/9.97G [01:39<00:00, 9\r\n",
            "\rFetching 3 files:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                 | 1/3 [01:40<03:20, 100.22s/it]\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  99%|\u2589| 9.85G/9.99G [01:40<00:01, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  99%|\u2589| 9.87G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  99%|\u2589| 9.89G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  99%|\u2589| 9.91G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors:  99%|\u2589| 9.93G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors: 100%|\u2589| 9.95G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors: 100%|\u2589| 9.97G/9.99G [01:40<00:00, 1\u001b[A\u001b[A\r\n",
            "\r\n",
            "\r(\u2026)pytorch_model-00002-of-00003.safetensors: 100%|\u2588| 9.99G/9.99G [01:41<00:00, 1\u001b[A\u001b[A\r(\u2026)pytorch_model-00002-of-00003.safetensors: 100%|\u2588| 9.99G/9.99G [01:41<00:00, 9\r\n",
            "\rFetching 3 files:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588         | 2/3 [01:41<00:41, 41.86s/it]\rFetching 3 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [01:41<00:00, 33.75s/it]\r\n",
            "\rLoading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 24.76it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 24.72it/s]\r\n",
            "Original Transformer Loaded from lllyasviel/FramePackI2V_HY.\r\n",
            "Ensuring Original model has no LoRAs loaded\r\n",
            "Unloading all LoRAs from Original model\r\n",
            "Model doesn't have any LoRA adapters or peft_config.\r\n",
            "[After unloading LoRAs] Transformer has no peft_config attribute\r\n",
            "[After unloading LoRAs] No LoRA components found in transformer\r\n",
            "Saved metadata and starting image for job 250814_125325_559_3268\r\n",
            "Loaded CLIPTextModel to cuda:0 as complete.\r\n",
            "Cache miss for prompt: The person does a dance...\r\n",
            "Override system prompt is disabled, using default template\r\n",
            "Cache miss for prompt: The person jumps up and down...\r\n",
            "Override system prompt is disabled, using default template\r\n",
            "Cache miss for prompt: The person waves hello...\r\n",
            "Override system prompt is disabled, using default template\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Loaded SiglipVisionModel to cuda:0 as complete.\r\n",
            "Offloading AutoencoderKLHunyuanVideo from cuda:0 to preserve memory: 6 GB\r\n",
            "Offloading SiglipVisionModel from cuda:0 to preserve memory: 6 GB\r\n",
            "Setting Up MagCache\r\n",
            "MagCache: Using ratios from Original, resolution group 640 (640x640), 25 steps and interpolating to 17 steps.\r\n",
            "latent_padding_size = 27, is_last_section = False, time position: 0.01s (original: 5.99s), using prompt: The person does a dance...\r\n",
            "Original model section 1/5, latent_padding=3\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:59,  3.74s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:54,  3.66s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:11<00:54,  3.88s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:15<00:49,  3.78s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:30,  2.74s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:22<00:15,  1.93s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:26<00:08,  1.62s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.57s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.96s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 9, 80, 80]); pixel shape torch.Size([1, 3, 33, 640, 640])\r\n",
            "Blending prompts: 'The person does a dance...' -> 'The person jumps up and down...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 1.10s (original: 4.90s), using prompt: The person jumps up and down...\r\n",
            "Original model section 2/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:58,  3.69s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:55,  3.69s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:11<00:51,  3.70s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:47,  3.69s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:29,  2.71s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:22<00:15,  1.92s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:08,  1.62s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.56s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.95s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 2/5, history_pixels shape: torch.Size([1, 3, 69, 640, 640])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 18, 80, 80]); pixel shape torch.Size([1, 3, 69, 640, 640])\r\n",
            "Blending prompts: 'The person jumps up and down...' -> 'The person waves hello...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 2.30s (original: 3.70s), using prompt: The person jumps up and down...\r\n",
            "Original model section 3/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:58,  3.64s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:54,  3.64s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:51,  3.64s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:47,  3.64s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:29,  2.68s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.90s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:08,  1.61s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.46s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.56s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.93s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 3/5, history_pixels shape: torch.Size([1, 3, 105, 640, 640])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 27, 80, 80]); pixel shape torch.Size([1, 3, 105, 640, 640])\r\n",
            "latent_padding_size = 9, is_last_section = False, time position: 3.50s (original: 2.50s), using prompt: The person waves hello...\r\n",
            "Original model section 4/5, latent_padding=1\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:58,  3.65s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:54,  3.65s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:51,  3.65s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:47,  3.65s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:29,  2.68s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.91s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:08,  1.61s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.46s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.56s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.94s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 4/5, history_pixels shape: torch.Size([1, 3, 141, 640, 640])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 36, 80, 80]); pixel shape torch.Size([1, 3, 141, 640, 640])\r\n",
            "latent_padding_size = 0, is_last_section = True, time position: 4.70s (original: 1.30s), using prompt: The person waves hello...\r\n",
            "Original model section 5/5, latent_padding=0\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:58,  3.64s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:54,  3.65s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:51,  3.65s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:47,  3.66s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:29,  2.69s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.91s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:08,  1.62s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.57s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:33<00:00,  1.94s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 5/5, history_pixels shape: torch.Size([1, 3, 181, 640, 640])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 46, 80, 80]); pixel shape torch.Size([1, 3, 181, 640, 640])\r\n",
            "MagCache (47.06%) skipped 40 of 85 steps.\r\n",
            "Video files found for cleanup: ['250814_125325_559_3268_9.mp4', '250814_125325_559_3268_18.mp4', '250814_125325_559_3268_27.mp4', '250814_125325_559_3268_36.mp4', '250814_125325_559_3268_46.mp4']\r\n",
            "Sorted video files: ['250814_125325_559_3268_9.mp4', '250814_125325_559_3268_18.mp4', '250814_125325_559_3268_27.mp4', '250814_125325_559_3268_36.mp4', '250814_125325_559_3268_46.mp4']\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_125325_559_3268_9.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_125325_559_3268_18.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_125325_559_3268_27.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_125325_559_3268_36.mp4\r\n",
            "Transformer has no peft_config attribute\r\n",
            "No LoRA components found in transformer\r\n",
            "Received end signal for job c5fe0a42-a603-43c4-814b-90276ae1771e\r\n",
            "Finishing job c5fe0a42-a603-43c4-814b-90276ae1771e with status JobStatus.COMPLETED\r\n",
            "Saved 1 jobs to queue.json\r\n",
            "Teacache parameters: use_teacache=False, teacache_num_steps=25, teacache_rel_l1_thresh=0.15\r\n",
            "Adding job 2e26f3a6-9d1d-42d5-927e-99a32f267640 (type: single) to queue.\r\n",
            "Starting job 2e26f3a6-9d1d-42d5-927e-99a32f267640, current job was None\r\n",
            "Starting worker function for job 2e26f3a6-9d1d-42d5-927e-99a32f267640\r\n",
            "Worker function started for job 2e26f3a6-9d1d-42d5-927e-99a32f267640\r\n",
            "Florence-2 model unloaded successfully.\r\n",
            "Worker: Selected LoRAs for this worker: []\r\n",
            "Worker: Unloading LoRAs from studio_module.current_generator\r\n",
            "Unloading all LoRAs from Original model\r\n",
            "Model doesn't have any LoRA adapters or peft_config.\r\n",
            "[After unloading LoRAs] Transformer has no peft_config attribute\r\n",
            "[After unloading LoRAs] No LoRA components found in transformer\r\n",
            "Pushing initial progress update to main stream for job 250814_130009_365_8994\r\n",
            "Saved input image for job 2e26f3a6-9d1d-42d5-927e-99a32f267640 to queue_images/2e26f3a6-9d1d-42d5-927e-99a32f267640_input.png\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Saved 2 jobs to queue.json\r\n",
            "Added job 2e26f3a6-9d1d-42d5-927e-99a32f267640 to queue\r\n",
            "Generated new seed for next job: 6642\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Worker starting for model type: Original\r\n",
            "Worker: Before model assignment, studio_module.current_generator is <class 'modules.generators.original_generator.OriginalModelGenerator'>, id: 46891162101680\r\n",
            "Worker: AFTER model assignment, studio_module.current_generator is <class 'modules.generators.original_generator.OriginalModelGenerator'>, id: 46891158065984\r\n",
            "Worker: studio_module.current_generator.transformer is <class 'NoneType'>\r\n",
            "Loading Original Transformer...\r\n",
            "\rFetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\rFetching 3 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 44462.59it/s]\r\n",
            "\rLoading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 26.28it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 26.22it/s]\r\n",
            "Original Transformer Loaded from lllyasviel/FramePackI2V_HY.\r\n",
            "Ensuring Original model has no LoRAs loaded\r\n",
            "Unloading all LoRAs from Original model\r\n",
            "Model doesn't have any LoRA adapters or peft_config.\r\n",
            "[After unloading LoRAs] Transformer has no peft_config attribute\r\n",
            "[After unloading LoRAs] No LoRA components found in transformer\r\n",
            "Saved metadata and starting image for job 250814_130009_365_8994\r\n",
            "Loaded CLIPTextModel to cuda:0 as complete.\r\n",
            "Cache hit for prompt: The person does a dance...\r\n",
            "Cache hit for prompt: The person jumps up and down...\r\n",
            "Cache hit for prompt: The person waves hello...\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Loaded SiglipVisionModel to cuda:0 as complete.\r\n",
            "Offloading AutoencoderKLHunyuanVideo from cuda:0 to preserve memory: 6 GB\r\n",
            "Offloading SiglipVisionModel from cuda:0 to preserve memory: 6 GB\r\n",
            "Setting Up MagCache\r\n",
            "MagCache: Using ratios from Original, resolution group 640 (544x704), 25 steps and interpolating to 17 steps.\r\n",
            "latent_padding_size = 27, is_last_section = False, time position: 0.01s (original: 5.99s), using prompt: The person does a dance...\r\n",
            "Original model section 1/5, latent_padding=3\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:53,  3.35s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:06<00:50,  3.36s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:47,  3.37s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:13<00:44,  3.39s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:16<00:27,  2.50s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:20<00:14,  1.78s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:23<00:07,  1.51s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:27<00:02,  1.37s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.46s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.80s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 9, 88, 68]); pixel shape torch.Size([1, 3, 33, 704, 544])\r\n",
            "Blending prompts: 'The person does a dance...' -> 'The person jumps up and down...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 1.10s (original: 4.90s), using prompt: The person jumps up and down...\r\n",
            "Original model section 2/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:54,  3.40s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:06<00:51,  3.41s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:47,  3.42s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:13<00:44,  3.42s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:27,  2.52s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:20<00:14,  1.79s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:24<00:07,  1.52s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:27<00:02,  1.38s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.47s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.82s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 2/5, history_pixels shape: torch.Size([1, 3, 69, 704, 544])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 18, 88, 68]); pixel shape torch.Size([1, 3, 69, 704, 544])\r\n",
            "Blending prompts: 'The person jumps up and down...' -> 'The person waves hello...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 2.30s (original: 3.70s), using prompt: The person jumps up and down...\r\n",
            "Original model section 3/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:55,  3.46s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:06<00:52,  3.47s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:48,  3.48s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:13<00:45,  3.47s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:27,  2.54s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:20<00:14,  1.80s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:24<00:07,  1.51s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:27<00:02,  1.37s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.45s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.82s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 3/5, history_pixels shape: torch.Size([1, 3, 105, 704, 544])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 27, 88, 68]); pixel shape torch.Size([1, 3, 105, 704, 544])\r\n",
            "latent_padding_size = 9, is_last_section = False, time position: 3.50s (original: 2.50s), using prompt: The person waves hello...\r\n",
            "Original model section 4/5, latent_padding=1\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:53,  3.36s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:06<00:50,  3.35s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:47,  3.36s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:13<00:43,  3.35s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:16<00:27,  2.47s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:20<00:14,  1.75s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:23<00:07,  1.48s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:26<00:02,  1.34s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.43s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:30<00:00,  1.78s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 4/5, history_pixels shape: torch.Size([1, 3, 141, 704, 544])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 36, 88, 68]); pixel shape torch.Size([1, 3, 141, 704, 544])\r\n",
            "latent_padding_size = 0, is_last_section = True, time position: 4.70s (original: 1.30s), using prompt: The person waves hello...\r\n",
            "Original model section 5/5, latent_padding=0\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:53,  3.33s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:06<00:49,  3.33s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:09<00:46,  3.33s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:13<00:43,  3.32s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:16<00:26,  2.44s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:19<00:13,  1.74s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:23<00:07,  1.47s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:26<00:02,  1.33s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:29<00:00,  1.42s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:29<00:00,  1.76s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 5/5, history_pixels shape: torch.Size([1, 3, 181, 704, 544])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 46, 88, 68]); pixel shape torch.Size([1, 3, 181, 704, 544])\r\n",
            "MagCache (47.06%) skipped 40 of 85 steps.\r\n",
            "Video files found for cleanup: ['250814_130009_365_8994_9.mp4', '250814_130009_365_8994_18.mp4', '250814_130009_365_8994_27.mp4', '250814_130009_365_8994_36.mp4', '250814_130009_365_8994_46.mp4']\r\n",
            "Sorted video files: ['250814_130009_365_8994_9.mp4', '250814_130009_365_8994_18.mp4', '250814_130009_365_8994_27.mp4', '250814_130009_365_8994_36.mp4', '250814_130009_365_8994_46.mp4']\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130009_365_8994_9.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130009_365_8994_18.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130009_365_8994_27.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130009_365_8994_36.mp4\r\n",
            "Transformer has no peft_config attribute\r\n",
            "No LoRA components found in transformer\r\n",
            "Received end signal for job 2e26f3a6-9d1d-42d5-927e-99a32f267640\r\n",
            "Finishing job 2e26f3a6-9d1d-42d5-927e-99a32f267640 with status JobStatus.COMPLETED\r\n",
            "Saved 2 jobs to queue.json\r\n",
            "Teacache parameters: use_teacache=False, teacache_num_steps=25, teacache_rel_l1_thresh=0.15\r\n",
            "Adding job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6 (type: single) to queue.\r\n",
            "Starting job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6, current job was None\r\n",
            "Starting worker function for job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6\r\n",
            "Worker function started for job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6\r\n",
            "Florence-2 model unloaded successfully.\r\n",
            "Worker: Selected LoRAs for this worker: []\r\n",
            "Worker: Unloading LoRAs from studio_module.current_generator\r\n",
            "Unloading all LoRAs from Original model\r\n",
            "Model doesn't have any LoRA adapters or peft_config.\r\n",
            "[After unloading LoRAs] Transformer has no peft_config attribute\r\n",
            "[After unloading LoRAs] No LoRA components found in transformer\r\n",
            "Pushing initial progress update to main stream for job 250814_130421_606_3125\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Worker starting for model type: Original\r\n",
            "Worker: Before model assignment, studio_module.current_generator is <class 'modules.generators.original_generator.OriginalModelGenerator'>, id: 46891158065984\r\n",
            "Worker: AFTER model assignment, studio_module.current_generator is <class 'modules.generators.original_generator.OriginalModelGenerator'>, id: 46888494950464\r\n",
            "Worker: studio_module.current_generator.transformer is <class 'NoneType'>\r\n",
            "Loading Original Transformer...\r\n",
            "\rFetching 3 files:   0%|                                   | 0/3 [00:00<?, ?it/s]\rFetching 3 files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 40459.52it/s]\r\n",
            "\rLoading checkpoint shards:   0%|                          | 0/3 [00:00<?, ?it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 27.19it/s]\rLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00<00:00, 27.14it/s]\r\n",
            "Original Transformer Loaded from lllyasviel/FramePackI2V_HY.\r\n",
            "Ensuring Original model has no LoRAs loaded\r\n",
            "Unloading all LoRAs from Original model\r\n",
            "Model doesn't have any LoRA adapters or peft_config.\r\n",
            "Saved input image for job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6 to queue_images/80d0bcc7-a84f-4d10-817b-ae014e3f50a6_input.png\r\n",
            "Saved 3 jobs to queue.json\r\n",
            "Added job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6 to queue\r\n",
            "Generated new seed for next job: 2651\r\n",
            "[After unloading LoRAs] Transformer has no peft_config attribute\r\n",
            "[After unloading LoRAs] No LoRA components found in transformer\r\n",
            "Saved metadata and starting image for job 250814_130421_606_3125\r\n",
            "Loaded CLIPTextModel to cuda:0 as complete.\r\n",
            "Cache hit for prompt: The person does a dance...\r\n",
            "Cache hit for prompt: The person jumps up and down...\r\n",
            "Cache hit for prompt: The person waves hello...\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Loaded SiglipVisionModel to cuda:0 as complete.\r\n",
            "Offloading AutoencoderKLHunyuanVideo from cuda:0 to preserve memory: 6 GB\r\n",
            "Offloading SiglipVisionModel from cuda:0 to preserve memory: 6 GB\r\n",
            "Setting Up MagCache\r\n",
            "MagCache: Using ratios from Original, resolution group 640 (832x480), 25 steps and interpolating to 17 steps.\r\n",
            "latent_padding_size = 27, is_last_section = False, time position: 0.01s (original: 5.99s), using prompt: The person does a dance...\r\n",
            "Original model section 1/5, latent_padding=3\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:56,  3.50s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:52,  3.51s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:49,  3.52s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:45,  3.52s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:28,  2.60s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:14,  1.85s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:24<00:07,  1.56s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:28<00:02,  1.42s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:31<00:00,  1.51s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:31<00:00,  1.87s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 9, 60, 104]); pixel shape torch.Size([1, 3, 33, 480, 832])\r\n",
            "Blending prompts: 'The person does a dance...' -> 'The person jumps up and down...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 1.10s (original: 4.90s), using prompt: The person jumps up and down...\r\n",
            "Original model section 2/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:57,  3.57s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:53,  3.56s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:49,  3.57s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:46,  3.57s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:28,  2.63s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:14,  1.87s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:07,  1.58s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:28<00:02,  1.43s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.53s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.90s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 2/5, history_pixels shape: torch.Size([1, 3, 69, 480, 832])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 18, 60, 104]); pixel shape torch.Size([1, 3, 69, 480, 832])\r\n",
            "Blending prompts: 'The person jumps up and down...' -> 'The person waves hello...', alpha=0.25\r\n",
            "latent_padding_size = 18, is_last_section = False, time position: 2.30s (original: 3.70s), using prompt: The person jumps up and down...\r\n",
            "Original model section 3/5, latent_padding=2\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:57,  3.58s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:53,  3.58s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:50,  3.58s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:46,  3.58s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:29,  2.64s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.88s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:07,  1.59s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:28<00:02,  1.45s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.55s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.91s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 3/5, history_pixels shape: torch.Size([1, 3, 105, 480, 832])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 27, 60, 104]); pixel shape torch.Size([1, 3, 105, 480, 832])\r\n",
            "latent_padding_size = 9, is_last_section = False, time position: 3.50s (original: 2.50s), using prompt: The person waves hello...\r\n",
            "Original model section 4/5, latent_padding=1\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:58,  3.64s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:54,  3.63s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:50,  3.63s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:47,  3.63s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:18<00:29,  2.67s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.90s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:08,  1.60s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:29<00:02,  1.46s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.55s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.93s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 4/5, history_pixels shape: torch.Size([1, 3, 141, 480, 832])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 36, 60, 104]); pixel shape torch.Size([1, 3, 141, 480, 832])\r\n",
            "latent_padding_size = 0, is_last_section = True, time position: 4.70s (original: 1.30s), using prompt: The person waves hello...\r\n",
            "Original model section 5/5, latent_padding=0\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "Unloaded DynamicSwap_LlamaModel as complete.\r\n",
            "Unloaded CLIPTextModel as complete.\r\n",
            "Unloaded SiglipVisionModel as complete.\r\n",
            "Moving DynamicSwap_HunyuanVideoTransformer3DModelPacked to cuda:0 with preserved memory: 6 GB\r\n",
            "\r  0%|                                                    | 0/17 [00:00<?, ?it/s]\r  6%|\u2588\u2588\u258c                                         | 1/17 [00:03<00:57,  3.58s/it]\r 12%|\u2588\u2588\u2588\u2588\u2588\u258f                                      | 2/17 [00:07<00:53,  3.59s/it]\r 18%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                    | 3/17 [00:10<00:50,  3.58s/it]\r 24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                 | 4/17 [00:14<00:46,  3.58s/it]\r 35%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                            | 6/17 [00:17<00:29,  2.64s/it]\r 53%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                    | 9/17 [00:21<00:15,  1.88s/it]\r 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e            | 12/17 [00:25<00:07,  1.59s/it]\r 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589     | 15/17 [00:28<00:02,  1.44s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.54s/it]\r100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:32<00:00,  1.91s/it]\r\n",
            "Offloading DynamicSwap_HunyuanVideoTransformer3DModelPacked from cuda:0 to preserve memory: 8 GB\r\n",
            "Loaded AutoencoderKLHunyuanVideo to cuda:0 as complete.\r\n",
            "Original model section 5/5, history_pixels shape: torch.Size([1, 3, 181, 480, 832])\r\n",
            "Unloaded AutoencoderKLHunyuanVideo as complete.\r\n",
            "/usr/local/lib/python3.12/site-packages/torchvision/io/_video_deprecation_warning.py:5: UserWarning: The video decoding and encoding capabilities of torchvision are deprecated from version 0.22 and will be removed in version 0.24. We recommend that you migrate to TorchCodec, where we'll consolidate the future decoding/encoding capabilities of PyTorch: https://github.com/pytorch/torchcodec\r\n",
            "  warnings.warn(\r\n",
            "Decoded. Current latent shape torch.Size([1, 16, 46, 60, 104]); pixel shape torch.Size([1, 3, 181, 480, 832])\r\n",
            "MagCache (47.06%) skipped 40 of 85 steps.\r\n",
            "Video files found for cleanup: ['250814_130421_606_3125_9.mp4', '250814_130421_606_3125_18.mp4', '250814_130421_606_3125_27.mp4', '250814_130421_606_3125_36.mp4', '250814_130421_606_3125_46.mp4']\r\n",
            "Sorted video files: ['250814_130421_606_3125_9.mp4', '250814_130421_606_3125_18.mp4', '250814_130421_606_3125_27.mp4', '250814_130421_606_3125_36.mp4', '250814_130421_606_3125_46.mp4']\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130421_606_3125_9.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130421_606_3125_18.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130421_606_3125_27.mp4\r\n",
            "Deleted intermediate video: /root/FramePack-Studio/outputs/250814_130421_606_3125_36.mp4\r\n",
            "Transformer has no peft_config attribute\r\n",
            "No LoRA components found in transformer\r\n",
            "Received end signal for job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6\r\n",
            "Finishing job 80d0bcc7-a84f-4d10-817b-ae014e3f50a6 with status JobStatus.COMPLETED\r\n",
            "Saved 3 jobs to queue.json\r\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}